## Table of Contents
- [Artificial Intelligence & Machine Learning](#artificial-intelligence--machine-learning)
- [Analytics](#analytics)
- [Application Integration](#application-integration)
- [Architecture](#architecture)
- [AR/VR](#ar-vr)
- [Automotive](#automotive)
- [Blockchain](#blockchain)
- [International](#international)
- [Compute](#compute)

# Artificial Intelligence & Machine Learning

## [AIM201-S: Hot paths to anomaly detection with TIBCO data science, streaming on AWS](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Hot_paths_to_anomaly_detection_with_TIBCO_data_science%2C_streaming_on_AWS_AIM201-S.pdf)   

> Sensor data on the event stream can be voluminous. In NAND manufacturing, there are millions of columns of data that represent many measured and virtual metrics. These sensor data can arrive with considerable velocity. In this session, learn about developing cross-sectional and longitudinal analyses for anomaly detection and yield optimization using deep learning methods, as well as super-fast subsequence signature search on accumulated time-series data and methods for handling very wide data in Apache Spark on Amazon EMR. The trained models are developed in TIBCO Data Science and Amazon SageMaker and applied to event streams using services such as Amazon Kinesis to identify hot paths to anomaly detection. This presentation is brought to you by TIBCO Software, an APN Partner.

-  [Slides](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Hot_paths_to_anomaly_detection_with_TIBCO_data_science%2C_streaming_on_AWS_AIM201-S.pdf) , [Videos](https://www.youtube.com/watch?v=ZTI76iJCRjc)

## [AIM202-S: Artificial intelligence in Healthcare](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Artificial_intelligence_in_Healthcare_AIM202-S.pdf)

> SENTRI is an intelligent automation application platform built leveraging native AWS components to facilitate case processing in the Healthcare industry. PwC built an engine that can take in an adverse healthcare/level of service (HC/LS) event case, extract key information, provide an initial interpretation of severity, and triage the case for review. PwC performed analysis using a user-centric experience, which allowed the case processor to easily verify outputs and helped build trust and confidence in the machine's interpretation. In this session, learn how a PwC customer has been successfully using this system for over nine months. It used to take two hours to process a case. Now, it takes three seconds. This presentation is brought to you by PwC, an APN Partner.

-  [Slides](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Artificial_intelligence_in_Healthcare_AIM202-S.pdf)

## AIM203-SR1: Take AI/ML from theory to practice with Intel technologies on AWS 

> The challenges associated with scalability have been removed in the cloud. Today, organizations deploy tons of artificial intelligence/machine learning (AI/ML) workloads on AWS. Learn about how easy and cost-effective it is to build customized, intelligent data models leveraging the full power of Intel Xeon Scalable processors. Additionally, learn how Footasylum, a leading UK leisurewear retailer, is globally optimizing its value chain. By utilizing the Peak AI ML solution powered by Intel on AWS, Footasylum is leveraging ML for long-term success in the modern retail climate. This presentation is brought to you by Intel, an APN Partner.

## AIM204-S: Discovering the value of a cloud data platform   

> In this session, Discover Financial Services and Accenture discuss their work with moving Discover from an on-premises data infrastructure to the AWS Cloud, which offers advanced analytics. With an intelligent data strategy and fully optimized AWS Cloud data solution, Discover is transforming the customer experience and increasing shareholder value. Today, the bank leverages data from many sources-structured and unstructured, streaming and batch-and analyzes the data for insights. This strategy required a bold pivot from a legacy, on-premises architecture to a fully integrated data platform on the cloud. Learn how Discover is also successfully navigating the cultural changes of this type of transformation. This presentation is brought to you by Accenture, an APN Partner.

## AIM205-R1: Starting the enterprise ML journey, featuring ProSiebenSat.1 Media SE   

> Amazon has been investing in machine learning for more than 20 years, innovating in areas such as fulfillment and logistics, personalization and recommendations, forecasting, fraud prevention, and supply chain optimization. During this session, we take this expertise and show you how to identify business problems that can be solved with machine learning. We discuss considerations including selecting the right use case for a machine learning pilot, nurturing skills, and measuring the success of such pilots. We dive into success stories from the Amazon ML Solutions Lab, and you can hear from ProSiebenSat.1 Media SE about how it moved from idea to production with machine learning.

## AIM207-R9: Get started with AWS DeepRacer 

> Get behind the keyboard for an immersive experience with AWS DeepRacer. Developers with no prior machine learning experience learn new skills and apply their knowledge in a fun and exciting way. With the help of the AWS pit crew, build and train a reinforcement learning model that you can race on the tracks in the MGM Grand Garden Arena and win special AWS prizes!

## AIM208-R1: Transform the way you search and interact with enterprise data using AI   

> How can you get the most intuitive and specific answer to a search query when the answer may be hidden within various enterprise filing or information systems? This session teaches you how to use natural language processing, a machine learning technique, to build an enterprise search solution that will give you straightforward answers to questions like,"How much is the cash reward on the corporate credit card?" Learn how this can improve cross-team knowledge sharing, enhance sales and customer support services, and make it much easier for end customers to find the information they need.

## AIM211-R1: AI document processing for business automation 

> Millions of times per day, customers from the Finance, Healthcare, public, and other sectors rely on information that is locked in documents. Amazon Textract uses artificial intelligence to 'read' such documents as a person would, to extract not only text but also tables, forms, and other structured data without configuration, training, or custom code. In this session, we demonstrate how you can use Amazon Textract to automate business processes with AI. You also hear directly from our customers about how they accelerated their own business processes with Amazon Textract.

## AIM214-R1: [NEW LAUNCH!] Introducing Amazon SageMaker Studio, the first full IDE for ML   

> Machine learning (ML) is a complex, iterative, often time-consuming process. One difficult aspect is the lack of integration between the workflow steps and the tools to accomplish them. Join us as we introduce Amazon SageMaker Studio, the first full integrated development environment (IDE) for ML that makes it easy to build, train, tune, debug, deploy, and monitor ML models at scale. It pulls together the ML workflow steps in a unified, visual interface-since they're performed and tracked within one environment, the non-linear and iterative nature of ML development is greatly simplified. You can quickly move between steps, compare results and adjust inputs and parameters, and iterate faster with Amazon SageMaker Studio.

## AIM215: [NEW LAUNCH!] Intro to Amazon SageMaker Autopilot: Auto-generate ML models 

> Typical approaches to automatic ML don't provide insights into the data or logic used to create models, forcing you to compromise on accuracy. Join us as we introduce Amazon SageMaker Autopilot, an automated capability that generates ML models and provides complete control and visibility of them. Learn how Autopilot automatically inspects raw data, picks the best set of algorithms, trains multiple models, tunes them, and ranks them based on performance. The result is a recommendation for the best performing model and visibility into the logic and code for how the model was created and what's in it. Autopilot offers the best combination of automatic model creation with control and visibility.

## AIM216-R1: [NEW LAUNCH!] Intro to Amazon SageMaker Debugger: Get insights into ML model training 

> During ML model training, it's challenging to ensure that models are progressively learning the correct values for different parameters and to analyze and debug model characteristics without building additional tools, making the process time-consuming and cumbersome. Come learn about Amazon SageMaker Debugger, a new capability that provides complete insights into the training process by automating data capture and analysis from training runs without code changes. Learn how you can analyze data using the Amazon SageMaker Studio visual interface and be alerted when anomalies and errors are detected, reducing the time needed to debug models from days to minutes. Amazon SageMaker Debugger helps you solve problems quickly, reduce troubleshooting time during training, and build high-quality models.

## AIM220-S: Farmers Insurance elevating customer experience with conversational AI 

> As part of its digital transformation journey, Farmers, one of America's largest insurers, envisioned digitizing its customer and agent service experience. Join Farmers for this insightful session, and learn how it leveraged conversational artificial intelligence (AI), chatbots, and other next-generation AWS technologies to offer a seamless, personalized, and contextualized experience for agents and customers. Learn how Farmers improved customer experience and optimized resources while encouraging self-service with cloud-based services, automation, and AI. Also, gain insights on how to design, architect, and build a scalable conversational AI solution that caters to growing business demands. This presentation is brought to you by Cognizant, an APN Partner.

## AIM222-R1: Monetizing text-to-speech AI 

> In this interactive session, we look at different options to monetize text-to-voice applications. We focus on Amazon Polly, a machine learning-powered service that produces lifelike speech. You learn to monetize this capability and generate a positive ROI when creating Amazon Polly applications. This chalk talk covers both business and technical considerations.

## AIM223-R12: [NEW LAUNCH!] AWS DeepComposer: Get started with generative AI 

> Generative AI is one of the most fascinating advancements in artificial intelligence technology, and until now, developers interested in growing skills in this area haven't had an easy way to get started. In this workshop, you learn about generative AI and get hands-on with AWS DeepComposer, the world's first machine learning-enabled musical keyboard for developers, to create an original composition. You are also introduced to concepts that you can use in Amazon SageMaker to do even more with generative AI. Developers, make some noise!

## AIM224-R1: Use pretrained models and algorithms in AWS Marketplace 

> You can cut down on development time for machine learning projects with third-party algorithms and models in a secure environment using Amazon SageMaker. Learn how in this chalk talk, as we walk through the subscription, evaluation, and deployment process for algorithms as well as pretrained models from AWS Marketplace.

## AIM225: How to build a car that does an 8.64-second lap with AWS DeepRacer 

> Deep dive on AWS DeepRacer! In this chalk talk, learn how to build a race-winning model from a 2019 AWS Summit Circuit race winner and get tips on how you can excel in the AWS DeepRacer league in 2020.

## AIM226: How to successfully become a machine learning developer 

> In this chalk talk, learn how to get started building, training, and deploying your first machine learning model. We then discuss tips, tricks, and best practices on starting your machine learning journey.

## AIM227-S: Powering global-scale predictive intelligence using HPC on AWS 

> Learn how Maxar and Descartes Labs run complex, global-scale models on Amazon EC2 instances powered by Intel Xeon Scalable processors. Maxar discusses its experience setting up an operational HPC cluster to run global numerical weather prediction models, obtaining performance that eclipses the speed of the NOAA bare-metal supercomputer. Descartes Labs shows how its platform enables hyper-scale object detection on satellite imagery accelerated by Intel AVX-512 instructions. It also shares its experience deploying tightly coupled HPC applications that use spot blocks at many-thousand processor scale, using HPC clusters built on AWS instances and powered by Intel Xeon Scalable processors. This presentation is brought to you by Intel, an APN Partner.

## AIM229: Start using computer vision with AWS DeepLens 

> If you're new to deep learning, this workshop is for you. Learn how to build and deploy computer-vision models using the AWS DeepLens deep-learning-enabled video camera. Also learn how to build a machine learning application and a model from scratch using Amazon SageMaker. Finally, learn to extend that model to Amazon SageMaker to build an end-to-end AI application.

## AIM230-R1: [NEW LAUNCH!] New Amazon SageMaker notebook experience: Share & collaborate at scale   

> Typically, starting notebooks requires spinning up compute instances, and there was previously no easy way to share and collaborate without tracking dependencies and other restrictions. Join us as we introduce the new Amazon SageMaker notebooks experience, which allows you to access notebooks in seconds without spinning up compute instances. The elastic notebooks allow you to easily scale compute up or down, and the changes take place automatically without interrupting your work. You can share notebooks by automatically reproducing the environment and library dependencies without manually tracking them so others can reproduce the results with the same data. With this new experience, you can build models faster and collaborate at scale.

## AIM231-S: Think Forward Initiative: 100M people making better financial decisions 

Want to learn more about using technology to impact society? Join this session! Currently, 42 percent of Europeans face financial difficulties. As lead partners of the Think Forward Initiative (TFI), Deloitte, AWS, and ING aim to empower 100 million Europeans to make better financial decisions by translating the latest consumer behavior insights into easy applicable tools. In this session, you learn how TFI supports early stage scale-ups by using Amazon S3, Amazon API Gateway, AWS Lambda, Amazon Aurora, AWS CloudFormation, AWS Cloud9, Amazon Textract, and Amazon Personalize in an accelerator program. You also learn about the AWS Well-Architected Review and AWS Activate programs. This presentation is brought to you by Deloitte, an APN Partner.

## AIM232: Media discovery and compliance with Amazon Rekognition   

> Searching through hundreds of hours of media assets and reviewing them for compliance daily is a tedious manual task in most media workflows today. Amazon Rekognition is a service that helps you add intelligent video and image analysis to your applications. In this session, learn how Amazon Rekognition and AWS media solutions can help you generate and manage rich video metadata for people, objects, and scenes, as well as detect any inappropriate content. Hear from our customers about how they achieved time and cost savings by using Amazon Rekognition and other AWS services.

## AIM301-R1: Creating high-quality training datasets with data labeling 

> Amazon SageMaker Ground Truth makes it easy to quickly label high-quality, accurate training datasets. In this workshop, we set up labeling jobs for text and images to help you understand how to make the most of Amazon SageMaker Ground Truth. You learn how to explore and prepare the dataset and label it with object bounding boxes. Then, we use Amazon SageMaker to train a Single Shot MultiBox Detector (SSD) object-detection model based on the labeled dataset, use hyperparameter optimization to find the best model for deployment, and deploy the model to an endpoint for use in an application.

## AIM302-R1: Create a Q&A bot with Amazon Lex and Amazon Alexa 

> A recent poll showed that 44 percent of customers would rather talk to a chatbot than to a human for customer support. In this workshop, we show you how to deploy a question-and-answer bot using two open-source projects: QnABot and Lex-Web-UI. You get started quickly using Amazon Lex, Amazon Alexa, and Amazon Elasticsearch Service (Amazon ES) to provide a conversational chatbot interface. You enhance this solution using AWS Lambda and integrate it with Amazon Connect.

## AIM303-R1: Stop guessing: Use AI to understand customer conversations 

> You don't need to be a data scientist to build an AI application. In this workshop, we show you how to use AWS AI services to build a serverless application that you can use to understand your customer interactions. Analyze call-center recordings with the help of automatic speech recognition, translation, and natural language processing (NLP). Get hands-on by producing your own call recordings using Amazon Connect. In the last step of this workshop, set up a processing pipeline to automate transcription and NLP analysis, and run analytics and visualizations on the results.

## AIM304-R1: Build a content-recommendation engine with Amazon Personalize 

> Machine learning is being used increasingly to improve customer engagement by powering personalized product and content recommendations. Amazon Personalize lets you easily build sophisticated personalization capabilities into your applications, using machine learning technology perfected from years of use on Amazon.com. In this workshop, you build your own recommendation engine by providing training data, building a model based on the algorithm of your choice, testing the model by deploying your Amazon Personalize campaign, and integrating it into your own application.

## AIM305-R1: Automate content moderation and compliance with AI 

> Brand safety is a major concern as advertising becomes more automated. Issues with ad adjacency arise, contracts with brands or celebrities run out, and user-generated content can be difficult to manage. In this workshop, you learn how to use Amazon Rekognition, Amazon Textract, and Amazon Comprehend to detect inappropriate content or noncompliant use of content such as logos or celebrity faces. You leave with a scalable architecture that will save days of manual review in media moderation and compliance workflows.

## AIM306-R: How to build high-performance ML solutions at low cost, featuring Aramex   

> Amazon SageMaker helps provide the best model performance for less cost. In this session, we walk through a TCO analysis of Amazon SageMaker, exploring its three modules-build, train, and deploy. Learn how Amazon SageMaker automatically configures and optimizes ML frameworks such as TensorFlow, MXNet, and PyTorch, and see how to use pre-built algorithms that are tuned for scale, speed, and accuracy. We explain how the automatic model tuning feature performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. Learn how to deploy your model with one click and how to lower inference costs using Amazon Elastic Inference. We end by showing how Aramex uses Amazon SageMaker.

## AIM306-R1: How to build high-performance ML solutions at low cost, featuring Siemens 

> Amazon SageMaker helps provide the best model performance for less cost. In this session, we walk through a TCO analysis of Amazon SageMaker, exploring its three modules-build, train, and deploy. Learn how Amazon SageMaker automatically configures and optimizes ML frameworks such as TensorFlow, MXNet, and PyTorch, and see how to use pre-built algorithms that are tuned for scale, speed, and accuracy. We explain how the automatic model tuning feature performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. Learn how to deploy your model with one click and how to lower inference costs using Amazon Elastic Inference. We end by showing how Siemens uses Amazon SageMaker to manage costs.

## AIM307: Amazon SageMaker deep dive: A modular solution for machine learning   

> Amazon SageMaker is a fully managed service that offers developers and data scientists the flexibility to build, train, and deploy machine learning models through modular capabilities. In this session, we dive deep into the technical details of each module so you understand how to label and prepare your data, choose an algorithm, train and optimize the model, and make predictions. We also discuss practical deployments of Amazon SageMaker through real-world customer examples.

## AIM308: Build accurate training datasets with Amazon SageMaker Ground Truth   

> Successful machine learning models are built on high-quality training datasets. Typically, the task of data labeling is distributed across a large number of humans, adding significant overhead and cost. This session explains how Amazon SageMaker Ground Truth reduces cost and complexity using techniques designed to improve labeling accuracy and reduce human effort. We walk through best practices for building highly accurate training datasets and discuss how you can use Amazon SageMaker Ground Truth to implement them.

## AIM310-S: Why observability requires the marriage of AI, metrics, and logs 

> The new digital world presents great opportunity as workloads move to the cloud and containers and companies benefit from serverless computing and an agile application delivery chain. However, these opportunities come with significant challenges. Site reliability engineers have been tasked with knitting together disparate platforms to build an observable stack, which is imperative for early detection of service degradation issues. We demonstrate a novel alternative that combines metrics, logs, and alerts into a comprehensive AIOps approach. Learn how to deliver an AI-enabled service that provides instant observability of your cloud application stack and how to combine logs and metrics into a single pane of glass. This presentation is brought to you by Moogsoft, an APN Partner.

## AIM311-R1: Choose the right instance type in Amazon SageMaker, with Texas Instruments   

> Amazon SageMaker, a fully managed service for machine learning, offers several compute capabilities and instance types to meet the needs of your use case. In this session, we review the compute options available to you, including GPUs, CPUs, AWS Inferentia, Amazon SageMaker Neo, and Amazon Elastic Inference. We discuss best practices and key criteria to choose the right capabilities that meet the specific needs of your machine learning workload.

## AIM312: Predict future business outcomes using Amazon Forecast   

> Based on the same technology used at Amazon.com, Amazon Forecast uses machine learning and time-series data to build accurate business forecasts. In this session, learn how machine learning can improve accuracy in demand forecasting, financial planning, and resource allocation while reducing your forecasting time from months to hours.

## AIM318-R2: Amazon SageMaker: Automatically tune hyperparameters 

> Amazon SageMaker offers automatic model tuning so you can use machine learning to quickly tune your model to be as accurate as possible. This capability lets you skip the tedious trial-and-error process of manually adjusting model parameters. Instead, over multiple training runs, automatic model tuning performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. In this builders session, we show you how to configure and launch a hyperparameter tuning job. Please bring your laptop.

## AIM319-R2: Amazon SageMaker: Use prebuilt Jupyter notebooks 

> In this builders session, we show you how to bring an existing Jupyter notebook from your local environment to Amazon SageMaker. Learn how to automate repository and package operations. Using script mode, you also learn how to migrate your code to built-in algorithms and frameworks in order to easily train and deploy at any scale on managed infrastructure. Please bring your laptop.

## AIM322-R1: Fraud: How to detect and prevent it using ML   

> Looking to protect your company from anonymous activity and prevent bad-actor behavior? This session details how to implement a customized fraud detection and prevention solution using machine learning services, how to proactively identify these use cases, and how to implement changes to protect your enterprise and your customers.

## AIM325-R1: [NEW LAUNCH!] Intro to Amazon Augmented AI for human review of ML predictions, featuring Ripcord 

> Many machine learning (ML) applications require humans to review for labeling or moderation of nuanced content, which can result in low confidence predictions to ensure the correct results. But building human review systems can be time-consuming and expensive. Amazon Augmented AI (A2I) makes it easy to build and manage human reviews for ML applications through built-in workflows for common ML use cases, such as content moderation (with Amazon Rekognition) and text extraction (with Amazon Textract). You can create workflows for custom ML models or those built on Amazon SageMaker. In this session, learn about Amazon A2I and how to use it. Then hear from Ripcord about how they plan to use Amazon A2I built-in integration with Amazon Textract to reduce the initial set up time for large and complex digitization projects.

## AIM326-R: Implement ML workflows with Kubernetes and Amazon SageMaker 

> Until recently, data scientists have spent much time performing operational tasks, such as ensuring that frameworks, runtimes, and drivers for CPUs and GPUs work well together. In addition, data scientists needed to design and build end-to-end machine learning (ML) pipelines to orchestrate complex ML workflows for deploying ML models in production. With Amazon SageMaker, data scientists can now focus on creating the best possible models while enabling organizations to easily build and automate end-to-end ML pipelines. In this session, we dive deep into Amazon SageMaker and container technologies, and we discuss how easy it is to integrate such tasks as model training and deployment into Kubernetes and Kubeflow-based ML pipelines.

## AIM326-R1: Implement ML workflows with Kubernetes and Amazon SageMaker   

> Until recently, data scientists have spent much time performing operational tasks, such as ensuring that frameworks, runtimes, and drivers for CPUs and GPUs work well together. In addition, data scientists needed to design and build end-to-end machine learning (ML) pipelines to orchestrate complex ML workflows for deploying ML models in production. With Amazon SageMaker, data scientists can now focus on creating the best possible models while enabling organizations to easily build and automate end-to-end ML pipelines. In this session, we dive deep into Amazon SageMaker and container technologies, and we discuss how easy it is to integrate such tasks as model training and deployment into Kubernetes and Kubeflow-based ML pipelines.

## AIM328: Build predictive maintenance systems with Amazon SageMaker 

Across a wide spectrum of industries, customers are starting to utilize prediction maintenance models to proactively fix problems before they impact production. The result is an optimized supply chain and improved working conditions. In this session, learn how to use data from equipment to build, train, and deploy predictive models. We dive deep into the architecture for using the turbofan degradation simulation dataset to train the model to recognize potential equipment failures and also how to provide recommended actions. Finally, we walk through an AWS CloudFormation template so you can get started quickly.

## AIM329: Using deep learning to track wildfires and air quality 

ALERTWildfire is a camera-based network infrastructure that captures satellite imagery of wildfires. In this chalk talk, we discuss deep-learning techniques that use this satellite imagery along with meteorological data to track wildfires and predict air quality in real time.

## AIM330: Build custom data labeling workflows with Amazon SageMaker 

> In this chalk talk, we explain how to use customer pre- and post-Lambda functions to extend the functionality of Amazon SageMaker Ground Truth. We show you how to make a custom annotator UI and use AWS Lambda to provide custom pre- and post-processing of annotations.

## AIM331-R1: Choose the proper algorithm in Amazon SageMaker 

> Amazon SageMaker gives you choices for the best algorithm to use to train your model. You get a 10x improvement in algorithm performance when using one of the build-in algorithms with Amazon SageMaker. However, it can be confusing to pick between the options. Commonly used ML algorithms are built-in and there are over 200 additional pre-trained models and algorithms available in AWS Marketplace. Plus you can also bring any other algorithm or framework by building it into a Docker container. During this chalk talk, we help you make sense of these choices to optimize performance.

## AIM333: How to design high-quality data-labeling pipelines 

> Amazon SageMaker Ground Truth is a fully managed service for data labeling. In this chalk talk, we explore the tools and techniques available in Ground Truth to help generate high-quality labels, from audit and verification workflows to annotation consolidation and active learning. We also discuss how the structured output format lends itself to generating hierarchical taxonomies of data.

## AIM334-R1: Preparing data for use in AutoML scenarios 

> AutoML takes care of the heavy lifting of selecting the most optimal algorithm, but as the saying goes 'garbage in, garbage out.' Prepping data for use in AutoML scenarios is one of the most challenging components, and the most prohibitive to a successful proof of concept. Join us to discuss best practices for data prep, and walk through examples of how to do this for sample datasets.

## AIM335-R1: Accelerate time-series forecasting with Amazon Forecast 

> Based on the same technology used at Amazon.com, Amazon Forecast uses machine learning to combine time-series data with additional variables to build up to 50% more accurate forecasts. In this workshop, prepare a dataset, build models based on that dataset, evaluate a model's performance based on real observations, and learn how to evaluate the value of a forecast compared with another. Gain the skills to make decisions that will impact the bottom line of your business.

## AIM337-R1: Deep dive into Amazon SageMaker security features 

> Customers manage highly sensitive data on behalf of their clients and customers. To apply machine learning techniques to highly sensitive data, they must maintain a high security bar to guard against data exfiltration or abuse of sensitive datasets. Join us for this chalk talk as we dive into the many features of Amazon SageMaker that enable customers to build highly secure data science environments and support stringent security requirements.

## AIM338: Machine learning with containers and Amazon SageMaker 

> Data scientists and machine learning engineers use containers to create custom, lightweight environments to train and serve models at scale with deep learning frameworks, such as TensorFlow, Apache MXNet, and PyTorch, achieving consistency across development and deployment. In this chalk talk, we discuss how to use AWS Deep Learning Containers to train and serve models with Amazon SageMaker.

## AIM340-R1: Next-gen video: Transcription, translation & search, powered by ML 

> Come discuss how machine learning can enhance your video files and generate searchable metadata in this chalk talk. The Media Analysis Solution on AWS uses Amazon Rekognition for facial recognition, Amazon Transcribe to create transcripts, Amazon Comprehend to run sentiment analysis on the transcripts, and Amazon Translate to make content available in multiple languages. By the end of this session, you will know how to upload your media files and work with the metadata that is automatically extracted through these services.

## AIM341: Deep learning on graphs 

> Graph databases are being adopted in a wide range of business domains and can be used with deep learning to tackle many common business problems. In this chalk talk, we explain how to do deep learning on graphs with Amazon SageMaker. We explore three use cases, including how to detect fraudulent accounts on social networks, how to identify social groups for marketing, and how to judge the creditworthiness of individuals.

## AIM342-R1: Large-scale document processing with Amazon Textract 

> Millions of mortgage applications and hundreds of millions of W-2 tax forms are processed each year-many times using manual data entry. In this chalk talk, we discuss how to architect a solution to extract text and data from these types of documents at scale for automatic processing. Learn how to build a serverless, highly available, highly scalable architecture that can easily handle spiky workloads.

## AIM343-R1: Build computer vision models with Amazon SageMaker 

> Implementing computer vision (CV) models just got simpler and faster. In this chalk talk, learn how to implement CV models using Apache MXNet and the Gluon CV Toolkit, which provide implementations of state-of-the-art deep learning algorithms in computer vision to help engineers, researchers, and students quickly prototype products, validate new ideas, and learn computer vision.

## AIM344-R1: Crafting a conversational platform strategy 

> In this chalk talk, we discuss how to build an Amazon Lex chatbot that can conduct a conversation based on data in a sample business intelligence database. We then explore ways that this chatbot could be adapted to your own datasets.

## AIM345: Build accurate models with automatic model tuning 

> In many cases, what separates good models from great ones is the choice of hyperparameters. For example, how many layers you should use? What should the learning rate be? And what should the regularization parameters be? In this chalk talk, we dive deep into the automatic model tuning feature of Amazon SageMaker. Automatic model tuning lets you skip the tedious trial-and-error process of manually adjusting model parameters and instead performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. You save days or even weeks of time.

## AIM346-R1: Personalized user engagement with machine learning 

> In this chalk talk, we discuss how to use Amazon Personalize and Amazon Pinpoint to provide a personalized, omni-channel experience starting in your mobile application. We discuss best practices for real-time updates, personalized notifications (push), and messaging (email and text) that drives user engagement and product discovery. We also demonstrate how other mobile services can be used to facilitate rapid prototyping.

## AIM347: Time-series prediction using GluonTS and Amazon SageMaker 

> Time-series prediction-whether it is regression, classification, or anomaly detection-has experienced a renaissance in the past three years thanks to the application of neural models. In turn, AWS has released an open-source Gluon-based toolkit, GluonTS, for time-series prediction. In this session we provide you with different models that are implemented as part of GluonTS. We also provide guidance as to where and how to apply each model.

## AIM348: Deploying and managing machine learning models at scale 

> In this workshop, we dive into the deploy module of Amazon SageMaker. Amazon SageMaker offers one-click deployment onto auto-scaling Amazon ML instances across multiple Availability Zones. We explain how Amazon SageMaker manages your production compute infrastructure on your behalf to perform health checks, apply security patches, and conduct other routine maintenance. Then we explore the batch transform feature, which enables you to run predictions on large or small batch data. Finally, we explore inference pipelines, which let you pass raw input data and execute preprocessing, predictions, and post-processing. After the workshop, you will be ready to scale ML.

## AIM350-R1: Identifying product mentions in customer reviews using ML 

> In recent years, we have seen the ascent of conversational AI, the rise of chatbots, and an exhaustive amount of data from customer calls, emails, and Tweets. Natural language processing (NLP) is at the core of all of these innovations. In this hands-on session, learn how Amazon Comprehend, and NLP service, enables you to train your own custom-named entity without needing to be skilled in machine learning (ML). Learn how to group support emails by department, social media posts by product, and analyst reports by business unit. Please bring your laptop.

## AIM353-R1: Identify and mask health data in images or text 

> Many companies in the Healthcare industry generate large amounts of data that's used in a variety of applications, such as population health management and electronic health records. Developers need to find ways to use the valuable health-related data in these applications while meeting their compliance obligations around sensitive data, such as protected health information (PHI). Join us in this builders session to learn how to use a pre-built solution from AWS, AI-Powered Health Data Masking, to identify and mask health-related data in images or text. Please bring your laptop.

## AIM356-R1: Smarter text analytics with Amazon ES & Amazon Comprehend 

> In this session, learn how to use Amazon Elasticsearch Service (Amazon ES) and Amazon Comprehend to extract and visualize insights from text. Learn how to index and analyze news and Twitter feeds, and create live dashboards to visualize extracted entities, key phrases, and sentiment. Please bring your laptop.

## AIM357: Build an ETL pipeline to analyze customer data 

Machine learning involves more than just training models; you need to source and prepare data, engineer features, select algorithms, train and tune models, and then deploy those models and monitor their performance in production. Learn how to set up an ETL pipeline to analyze customer data using Amazon SageMaker, AWS Glue, and AWS Step Functions.

## AIM358: Prepare data for ML using Amazon SageMaker 

High-quality datasets are the foundation of machine learning. In this chalk talk, we explain how to use Amazon SageMaker to prepare data. We show you how to create data inference pipelines so you can pass raw input data and execute preprocessing, predictions, and post-processing on real-time and batch inference requests. We also show you how to build data processing and feature engineering pipelines with a suite of feature transformers available in the SparkML and Scikit-learn framework containers in Amazon SageMaker.

## AIM359-R1: Build a fraud detection system with Amazon SageMaker 

In this workshop, we will explore the new AWS Fraud Detection Solution. We show you how to build, train, and deploy a fraud detection machine learning model. The fraud detection model recognizes fraud patterns, and is self-learning which enables it to adapt to new, unknown fraud patterns. We will show you how to execute automated transaction processing, and how to the Fraud Detection solution flags that activity for review. The solution comes with an implementation guide and accompanying AWS CloudFormation template.

## AIM360: Build a predictive maintenance system with Amazon SageMaker 

In this workshop, we explore the new AWS Predictive Maintenance Using Machine Learning solution. This solution deploys a machine learning model and an example dataset of turbofan degradation simulation data to train the model to recognize potential equipment failures. You can use this solution to automate the detection of potential equipment failures and provide recommended actions to take. We walk through the solution's implementation guide and accompanying AWS CloudFormation template.

## AIM361-R1: [NEW LAUNCH!] Optimizing Your Machine Learning Models on Amazon SageMaker 

In this code-level workshop, you'll learn how to use hyperparameter optimization (HPO) and AutoML on Amazon SageMaker, in order to quickly and easily build highly accurate machine learning models. Using a real-life dataset, you'll first use HPO to tune models built with the popular XGBoost algorithm. Then, you'll use the newly released AutoML capability in Amazon SageMaker to automatically figure out the algorithm, the parameters, and the data preprocessing steps. Finally, you'll use HPO again to perform architecture search on a Keras neural network. Prerequisites: familiarity with Python, Jupyter, Amazon SageMaker and basic machine learning concepts.

## AIM362-R1: [NEW LAUNCH!] Build, train & debug, and deploy & monitor with Amazon SageMaker 

Amazon SageMaker is a fully managed service that removes the heavy lifting from each step of the machine learning (ML) workflow and provides every developer and data scientist with the ability to build, train, and deploy ML models quickly. In this interactive workshop, we work on the different aspects of the ML workflow to build, train, and deploy a model using all the capabilities of Amazon SageMaker, including the ones that we announced at re:Invent this week. We use Amazon SageMaker to build and share notebooks, train and debug models with Amazon SageMaker Debugger, and deploy and monitor with Amazon SageMaker Model Monitor. Let's build together!

## AIM363: How to use NLP for domain-specific data 

Market segments like finance, insurance, or manufacturing all have documents and data that are very specific to their business. In this chalk talk, we discuss how you can utilize Amazon Comprehend custom entity recognition and classification, and AutoML features, to build state-of-the-art custom models to extract domain-specific terms and classifiers completely automatically.

## AIM364: How to deploy Amazon SageMaker to data science teams 

In this session, we share best practices for DevOps teams that can help them run Amazon SageMaker more effectively. Join us, and learn how these best practices enable machine learning scientists to carry out experimentation in their organizations in a collaborative fashion, without having to worry about security, resource management, or cost overruns.

## AIM365-R2: Build a custom model for object and logo detection 

In this discussion, we look at how you can use machine learning to automatically detect your logo or product, allowing you to track where your assets are being seen and used. Explore how this capability empowers marketers and decision makers with data on impressions, digital brand engagement, and the online tracking of their assets.

## AIM366-R1: SpaceNet: ML to solve mapping challenges 

SpaceNet, a nonprofit LLC focusing on solving geospatial problems such as mapping road network routes after a natural disaster, has open-sourced more than 6,500 square kilometers of high-resolution satellite imagery with approximately 800,000 building footprint labels and 8,000 square kilometers of road network labels. Join us for a discussion on how to use this data to train machine learning algorithms that help disseminate timely information in the aftermath of natural disasters.

## AIM367-S: Data is out, knowing is in: Applying AI to automate cloud operations 

With firefighting, manual operations, and troubleshooting, it is an exciting time to monitor applications in the cloud. In this session, renowned DevOps and digital evangelists Andi Grabner and Dave Anderson provide practical advice on how to save time monitoring your cloud applications. Learn how to automate your operations, use AI for assisted intelligence, and enable complete automation. In addition, learn about auto-remediation and how to always know the status of your applications, no matter how complex your hybrid cloud. Also hear from one customer about how a vision can become a reality. This presentation is brought to you by Dynatrace, an APN Partner.

## AIM368: Experience the real-world ML lifecycle with Amazon SageMaker 

In this workshop, you get hands-on experience taking custom machine learning (ML) solutions from prototype to production. You use Amazon SageMaker to build, train, and deploy ML models for a real-world Amazon Robotics use case. You learn about the human-robot interactions that happen hundreds of times every second to power the Amazon fulfillment network. You craft your own ML models based on millions of anonymized data points, and you deploy your models to serve warehouses across the globe with regional endpoints that scale automatically.

## AIM369: Changing the game with ML: How AI, ML, and IoT are transforming sports   

If you are a sports fan interested in machine learning, regardless of industry, this talk is for you. See how some of the world's top sports organizations are innovating with machine learning on AWS and how some of them got started on their journey working with the Amazon ML Solutions Lab. From Formula 1's 1M data points per second to the NFL's 3TB of data per game week to the use of Amazon SageMaker to build, train, and deploy predictive real-time models, leave this session with a better understanding of what's behind the curtain and how you can get started.

## AIM401-R1: Distributed training, tuning, and inference with TensorFlow in Amazon SageMaker 

The TensorFlow deep learning framework is widely used in academia and industry. Using Amazon SageMaker, organizations can quickly begin a fully managed TensorFlow experience. In this workshop, we train and deploy TensorFlow models using key Amazon SageMaker features for an efficient workflow. Specifically, we prototype training and inference code locally before moving to full-scale training and production deployment; compare and contrast Amazon SageMaker's support for distributed training with parameter servers and Horovod; apply automatic model tuning to improve TensorFlow models; and make predictions in production using either real-time endpoints backed by TensorFlow Serving or highly performant batch transform jobs at scale.

## AIM402-R1: Deep learning with PyTorch 

PyTorch is a deep-learning framework that is becoming popular, especially for rapid prototyping of new models. You can get started easily with PyTorch using Amazon SageMaker, a fully managed service, to build, train, and deploy machine learning models at scale. In this workshop, we build a natural-language-processing model to analyze text.

## AIM403-R1: Deep learning with Apache MXNet 

In this workshop, learn how to get started with the Apache MXNet deep learning framework using Amazon SageMaker, a fully managed service, to build, train, and deploy machine learning models at scale. Learn how to build a computer-vision model using MXNet to extract insights from an image dataset. Once the model is built, learn how to quickly train it to get the best possible results and then easily deploy it to production using Amazon SageMaker.

## AIM404-R1: Amazon SageMaker RL: Solving business problems with RL and bandits 

In reinforcement learning (RL), an RL agent learns in an interactive environment by trial and error using feedback from its own actions, and can make sophisticated multi-step decisions. As a result, RL has broad applicability in robotics, industrial control, finance, HVAC, dialog systems, online advertising, and more. This workshop provides practitioners with hands-on experience building and deploying RL agents from scratch. We use examples from two scenarios: one where the environment can be simulated (computer games, resource allocation simulators, etc.) and one where it cannot be and the agent learns in a live environment (recommender systems, trading bots, etc.).

## AIM405: Optimize deep learning models for edge deployments with AWS DeepLens 

In this workshop, learn how to optimize your computer vision pipelines for edge deployments with AWS DeepLens and Amazon SageMaker Neo. Also learn how to build a sample object detection model with Amazon SageMaker and deploy it to AWS DeepLens. Finally, learn how to optimize your deep learning models and code to achieve faster performance for use cases where speed matters.

## AIM407-R1: Amazon SageMaker and PyTorch: Tips & tricks 

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this builders session, learn how to build, train, and deploy PyTorch deep learning models in Amazon SageMaker. Please bring your laptop.

## AIM409-R1: Amazon SageMaker: Bring your own framework 

In this builders session, we show you how to set up your own machine learning environments and workflows on Amazon SageMaker together with AWS Deep Learning AMIs. First we explain how to use the prepackaged, optimized Amazon Machine Images (AMIs). Then we show you how to use these custom environments on Amazon SageMaker using AWS Deep Learning Containers, which provide Docker images preinstalled and tested with popular deep learning frameworks, so you can skip the complicated process of building and optimizing your environments from scratch. Come away understanding how to integrate custom algorithms into Amazon SageMaker. Please bring your laptop.

## AIM410-R: Deep learning applications with TensorFlow, featuring Mobileye   

TensorFlow is one of several open-source deep learning frameworks used in machine learning development that is currently popular among developers. But it can be challenging to scale TensorFlow model training and inference. Amazon SageMaker provides several features that solve these challenges. In this session, learn about these features, including distributed training, cost-effective inference, and workflow management. Then, hear from Mobileye, an Intel company focused on developing and delivering driving assist and autonomous vehicles solutions, about how they migrated their training workloads to Amazon SageMaker to reduce development cycle time from weeks to days.

## AIM410-R1: Deep learning applications with TensorFlow, featuring Fannie Mae 

TensorFlow is one of several currently popular open-source deep learning frameworks used in machine learning development. But it can be challenging to scale TensorFlow model training and inference. Amazon SageMaker provides several features that solve these challenges. In this session, learn about these features, including distributed training, cost-effective inference, and workflow management. Then, hear from Fannie Mae about how it developed its TensorFlow-based home appraisal models using Amazon SageMaker for scalability, security, and ease of management.

## AIM411-R1: Deep learning applications using Apache MXNet   

The Apache MXNet deep learning framework is used for developing, training, and deploying diverse artificial intelligence (AI) applications, including computer vision, speech recognition, and natural language processing (NLP). In this session, learn how to develop deep learning models with MXNet on Amazon SageMaker. Hear from the BBC about how it built a BERT-based NLP application to allow its website users to find relevant clips from recorded shows. We use the BBC's NLP application to demonstrate how to leverage MXNet's GluonNLP library to quickly build, train, and deploy deep learning models.

## AIM412-R: Deep learning applications using PyTorch, featuring Autodesk   

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this session, hear from the PyTorch team on the latest features and library releases. Also learn how to develop with PyTorch using Amazon SageMaker for key use cases such as using a BERT model for natural language processing (NLP) and instance segmentation for fine-grain computer vision. Lastly, take away best practices from Autodesk based on its experience with PyTorch on Amazon SageMaker for a range of NLP use cases.

## AIM412-R1: Deep learning applications with PyTorch, featuring Freshworks 

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this session, hear from the PyTorch team on the latest features and library releases. Also learn how to develop with PyTorch using Amazon SageMaker for key use cases such as using a BERT model for natural language processing (NLP) and instance segmentation for fine-grain computer vision. Lastly, hear from Freshworks about how it reduced the time to train 20,000+ models from 15 hours to 30 minutes using PyTorch and Amazon SageMaker.

## AIM413: Deep dive on Project Jupyter   

Amazon SageMaker offers fully managed Jupyter notebooks that you can use in the cloud so you can explore and visualize data and develop your machine learning model. In this session, we explain why we picked Jupyter notebooks, and how and why AWS is contributing to Project Jupyter. We dive deep into our overall strategy for Jupyter and explain different use cases for Jupyter, including data science, analytics, and simulation.

## AIM414: Containerizing deep learning workflows 

Deep learning software stacks can be complex to build, optimize, and maintain. With different versions of frameworks, libraries, runtimes, and drivers for CPUs and GPUs, developers and data scientists spend much time ensuring that the full software stack works well together during upgrades and system changes. Join us for a discussion on how container technologies can address these challenges by providing training and inference environments that are lightweight, portable, consistent, and scalable.

## AIM415-R1: Build fraud detection systems with Amazon SageMaker 

Fraud is an expensive problem that can damage customer trust. Many companies use a rule-based approach to detect fraudulent activity. But implementing and maintaining rules can be a complex process because fraud is constantly evolving, rules require that fraud patterns be known, and rules can lead to false positives or negatives. In this session, learn how machine learning (ML) can provide a more flexible approach. We dive deep on an ML solution using Amazon SageMaker, where the ML models don't use rules. Instead, they're trained to recognize fraud patterns, and they're self-learning, enabling them to adapt.

## AIM416: Deploy an ML model on the cloud and at the edge 

In this workshop, learn how to use Amazon SageMaker Neo deep learning compiler to compile your trained TensorFlow models and deploy them on the cloud or on edge devices using AWS IoT Greengrass. Learn how Neo deep learning compiler optimizes the trained models by improving efficiency and reducing the memory footprint of the compiled model and how Neo runtime abstracts the underlying hardware and allows running a compiled model on the target hardware platform. Explore how to reduce your inference costs by up to 75 percent using Amazon Elastic Inference to attach elastic GPU acceleration to your Amazon SageMaker instances.

## AIM417: Reinforcement learning with Amazon SageMaker 

Many applications, like personalized web services, are continuously faced with decisions based on contextual information. These services strive to adapt to individual users by making use of context. Despite advances, the problem remains challenging. First, systems should adapt to dynamically changing environments like evolving user interests. Second, because of the partial feedback that the system receives, decisions must be scrutinized to avoid introducing bias and a"self-fulfilling prophecy." Contextual bandits can be very effective in solving these problems; they adapt to dynamic environments while continuously balancing exploration with exploitation. In this session, we discuss building a scalable bandit model.

## AIM418: Distributed deep learning with Horovod 

> One of the main challenges customers face with deep learning is running efficient model training over multiple nodes. In this chalk talk, we discuss how to use Horovod, a distributed training framework, to speed up deep learning training for multiple frameworks including TensorFlow, PyTorch, and Apache MXNet. We also discuss how to run Horovod in Amazon SageMaker.

## AIM419-R1: [NEW LAUNCH!] Easily implement human review workflows for ML applications 

> Amazon Augmented AI (A2I) is a service that makes it easy to build the workflows required for human review of machine learning (ML) predictions. Come join us for a demo and discussion of how to use Amazon A2I for the most common ML use cases, such as content moderation, text extraction, and image classification.

## AIM420: Build state-of-the-art NLP models with Amazon SageMaker and GluonNLP 

> Implementing natural language processing (NLP) models just got simpler and faster. In this chalk talk, we introduce BERT (Bidirectional Encoder Representation from Transformers), a state-of-the-art (SOTA) NLP model, and demonstrate how it can be used for various NLP tasks. Learn how to implement NLP models using Apache MXNet and the GluonNLP toolkit to quickly prototype products, validate new ideas, and learn SOTA NLP. We also show how you can use GluonNLP and Amazon SageMaker to fine-tune BERT for a text classification use case and deploy the trained model. Come join us to train your NLP model onsite.

## AIM421-R1: How to use unsupervised ML to find patterns, meaning, and anomalies 

> Unsupervised machine learning algorithms infer patterns from a dataset without reference to known or labeled outcomes. Unsupervised learning is used for discovering the underlying structure of data. In this chalk talk, we discuss how to use unsupervised learning and Amazon SageMaker for anomaly detection to automatically discover unusual data points in your dataset. This is useful to detect fraudulent transactions, faulty hardware, or outliers caused by human errors during data entry. We also discuss the intricacies of unsupervised algorithms, including clustering with k-means and anomaly detection with Amazon SageMaker Random Cut Forest (RCF).

## AIM422: Machine learning at the edge with Amazon SageMaker Neo 

> Video-based tools have enabled advancements in computer vision, such as in-vehicle use cases for AI. However, it is not always possible to send this data to the cloud to be processed. In this chalk talk, learn how to train machine learning models using Amazon SageMaker and deploy them to an edge device using AWS Greengrass, enabling you to process data quickly at the edge, even when there is no connectivity.

## AIM423-R1: Improve your logistic operations with accurate forecasting 

> One of biggest challenges of logistics is building highly accurate forecasts that impact all downstream operations. With accurate demand forecasting, you can align your resources and workforce and realize cost efficiencies. Being able to estimate peak demand allows you to differentiate your customer experience to improve satisfaction. In this builders session, we discuss how to incorporate large volumes of historical demand and contextual data to build forecasts for increased decision accuracy and logistic improvements.

## AIM424-R1: Accelerate experimentation with personalization models 

> In this builders session, you work with an AWS solutions architect to learn how to integrate such techniques as A/B testing, multi-armed bandit, and interleaved recommendation testing into applications to measure the effectiveness of personalization. You use Amazon Personalize to build an end-to-end solution for deploying recommendation models that integrates with measurement techniques and can be applied to the customer experience in ecommerce or other marketing channels. Please bring your laptop.

## AIM425-R1: Understanding a large amount of text by modeling & visualizing topics 

> What's needed to describe and understand the themes and trends of 5,000 articles in a foreign language? You can spend a few years learning the language and reading through each article, or you can use a few lines of code with Amazon Translate and Amazon Comprehend in under an hour. To learn how to do the latter, come to this hands-on session. We cover topic modeling, a powerful unsupervised learning technique for understanding a large text corpus. Please bring your laptop.

## AIM426-R1: Worker safety with AWS DeepLens and Amazon Rekognition 

> There are many practical applications for computer vision systems, and AWS AI services make it easy for developers to add visual recognition capabilities to their programs. In this builders session, you learn how to use AWS DeepLens and Amazon Rekognition to build an application that helps identify whether a person at a construction site is wearing the correct safety gear, in this case, a hard hat. Please bring your laptop.

## AIM427-R1: Take an ML model from idea to production using Amazon SageMaker 

> Come build the most accurate text-classification model possible with Amazon SageMaker. This service lets you build, train, and deploy ML models using built-in or custom algorithms. In this workshop, learn how to leverage Keras/TensorFlow deep-learning frameworks to build a text-classification solution using custom algorithms on Amazon SageMaker. We walk you through packaging custom training code in a Docker container, testing it locally, and then using Amazon SageMaker to train a deep-learning model. You then try to iteratively improve the model to achieve high accuracy. Finally, you deploy the model in production so applications can leverage the classification service.

## AIM428: [NEW LAUNCH!] AWS DeepRacer multi-car racing: An advanced RL driving course 

> This technical deep dive is suitable for advanced machine learning developers looking to learn more complex reinforcement learning (RL) concepts using AWS DeepRacer and Amazon SageMaker RL. AWS data scientists help you build models capable of avoiding objects and overtaking other cars using innovations in neural network architecture and expanded algorithms.


# Analytics

ANT308-R1: Deep dive into running Apache Spark on Amazon EMR   

> Amazon EMR enables customers to run ETL, machine learning, real-time processing, data science, and low-latency SQL at petabyte scale. We focus this session on running Apache Spark on Amazon EMR. We introduce design patterns such as using Amazon S3 instead of HDFS, running long- and short-lived clusters, using notebooks, and performance-related enhancements. We discuss lowering cost with auto scaling and Spot Instances, and security with encryption and fine-grained access control with AWS Lake Formation.

## ANT333: How Woot.com built a serverless data lake with AWS analytics   

> Woot.com designed and developed a data lake as a replacement for their legacy data warehouse to deliver powerful analytics capabilities across multiple business areas. In this session, learn how it used Amazon EMR, Amazon Athena, AWS Glue, and Amazon QuickSight to build an automated process to ingest and centralize data from external and internal sources for immediate analysis.

## ANT334-R: Migrate your data warehouse to the cloud in record time, featuring Fannie Mae 

> Modern data warehousing blends and analyzes all your data-in your data warehouse and in your data lake-without needing to move the data. In this session, a representative from Fannie Mae explains how they migrated from a leading on-premises data warehouse to Amazon Redshift in record time. See how the company uses AWS Database Migration Service (AWS DMS), AWS Schema Conversion Tool, AWS Glue, and Amazon Redshift to provide timely analytics across the organization.

## ANT334-R1: Migrate your data warehouse to the cloud in record time, featuring Nielsen   

> Modern data warehousing blends and analyzes all your data-in your data warehouse and in your data lake-without needing to move the data. In this session, a representative from Nielsen explains how they migrated from a leading on-premises data warehouse to Amazon Redshift in record time. See how the company uses AWS Database Migration Service (AWS DMS), AWS Schema Conversion Tool, AWS Glue, and Amazon Redshift to provide timely analytics across the organization.

## ANT335-R: How to build your data analytics stack at scale with Amazon Redshift   

> Modern cloud data warehouses must be able to scale up and scale out as needed to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more.

## ANT335-R1: How to scale data analytics with Amazon Redshift, featuring Warner Bros. 

> Modern cloud data warehouses must be able to scale up and out to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more. Additionally, Warner Brothers discusses how it has seen improvements to its analytics performance with Amazon Redshift.

## ANT335-R2: How to scale data analytics with Amazon Redshift 

> Modern cloud data warehouses must be able to scale up and out to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more.

## ANT336-R1: Rapidly evaluate AWS analytics solutions with Amazon Redshift 

> Amazon Redshift's pace of innovation continues to increase year-over-year, putting price-performance at an all-time high. Whether you're looking to modernize an existing Amazon Redshift footprint, migrate from an on-premises data warehouse, or get hands-on with AWS's popular cloud data warehouse, this session equips you for success. The Amazon Redshift engineering team guides you through a comprehensive evaluation of modern Amazon Redshift features by using the Amazon Redshift gold standards framework, a robust analytics architecture, managed datasets, and a suite of benchmarking and demonstration tools. The discussions and hands-on labs will rapidly onboard you on the latest features of Amazon Redshift.

## ANT337-R1: Stored procedures in Amazon Redshift 

> In this session, we show you how to make the best use of stored procedures in Amazon Redshift to encapsulate business logic in a secure manner. With PL/pgSQL stored procedures, you can easily migrate existing workloads from legacy, on-premises data warehouses to Amazon Redshift. We show how, using the security definer functionality in our stored procedures, an administrator can allow users to perform specific administrative actions without the added risk of security exposure that comes from giving them broad access to database objects.

## ANT338-R1: Best practices for using popular BI tools with Amazon Redshift 

> Popular business intelligence (BI) tools like Tableau, Looker, MicroStrategy, Amazon QuickSight, and others are used with Amazon Redshift to visualize analytical results. In this session, we discuss tips and best practices to optimize Amazon Redshift with popular BI tools. We show how tight integration can yield considerable performance gains, shorten development cycles, and make queries more efficient.

## ANT339: How Cerner built a healthcare ML ecosystem with AWS analytics 

> Cerner deployed a platform that enables developers to build analytics and predictive healthcare models using big data architecture and machine learning. This accelerates innovation and creates a common strategy to deploy models to the market faster. In this chalk talk, learn how to create an ecosystem allowing data scientists and engineers to collaborate, deploy, and monitor machine learning models and data transformation jobs on both batch and stream data powered by a data lake architecture.

## ANT340-R1: How Equinox Fitness built serverless data applications with AWS 

> Equinox Fitness members perform millions of user actions daily, both online and onsite. In this talk, learn how the team at Equinox leveraged services like Amazon Redshift, Amazon EMR, AWS Lambda, and Amazon DynamoDB to deploy fully serverless data applications and platforms in a matter of months and can now provide better personalization and accelerate ideation. Come learn how to create an environment that allows data scientists and engineers to collaborate, deploy, and monitor machine learning models and data transformation jobs.

## ANT341: Integrating Amazon SageMaker and Amazon QuickSight 

> Today, customers using traditional business intelligence tools spend too much time sifting through numerous dashboards to manually interpret charts and tables. Amazon QuickSight now applies the power of machine learning and natural language to proactively discover and deliver insights to every user in your organization. In this chalk talk, we show you how you can integrate Amazon QuickSight with Amazon SageMaker to build dashboards and make predictions using your own custom ML models.

## ANT342: [NEW LAUNCH!] Scalable, secure, interactive log analytics using Amazon ES 

With the rapid growth in machine generated data, customers are looking for ways to securely and cost-effectively analyze this constantly growing data in real time. In this talk, we will discuss how to use Amazon Elasticsearch Service to build a secure and scalable log analytics solution to interactively analyze your log data and get valuable operational intelligence for application monitoring, log forensics, clickstream analytics, SIEM, and more.

## ANT343: [NEW LAUNCH!] Create a retail data product on AWS Data Exchange 

AWS Data Exchange makes it easy to securely list retail data products for sharing with AWS customers. In this builders session, you see how easy it is to prepare and package a data product, list it with terms and pricing, and make revisions and alert your customers. You also learn how to bring over existing customers' subscriptions and deliver data without all the hassle. Be sure to bring your laptop.

## ANT344-R1: Augment business analytics with Amazon QuickSight & Amazon SageMaker 

This session covers a new integration between Amazon QuickSight and Amazon SageMaker that makes it easy to connect to and use your predictive analytics models from Amazon SageMaker with Amazon QuickSight dashboards and analyses. Please bring your laptop.

## ANT345-S: Tableau Server on AWS enables analytics agility for Capital One 

As a financial institution, Capital One must be compliant with internal and external policies and regulations. One of these is to regularly replace its Tableau infrastructure, which enables the company to always have the latest security updates and patches in place. To meet this requirement, Capital One chose Tableau Server on AWS and devised a one-click deployment pattern that reduced time and errors while increasing flexibility. In this session, representatives from Capital One discuss some key principles to be aware of as you start or grow your own Tableau deployment. This presentation is brought to you by Tableau, an APN Partner.

## ANT347-S: Build reliable data lakes with Delta Lake & Databricks   

Enterprises need secure and reliable data storage to drive successful analytics programs. Data lakes are a key architectural element of modern data platforms, yet they can suffer from reliability challenges. In this session, you learn about the key data reliability challenges that data lakes face and how you can use open-source Delta Lake to apply schema enforcement, ACID transactions, and versioning to your data lake, making it usable for analytics. This presentation is brought to you by Databricks, an APN Partner.

## ANT401-R1: Build real-time analytics for a ride-sharing app 

In this session, we walk through how to perform real-time analytics on ride-sharing and taxi data, and we explore how to build a reliable, scalable, and highly available streaming architecture based on managed services. You learn how to deploy, operate, and scale an Apache Flink application with Amazon Kinesis Data Analytics for Java applications. Leave this workshop knowing how to build an end-to-end streaming analytics pipeline, starting with ingesting data into a Kinesis data stream, writing and deploying a Flink application to perform basic stream transformations and aggregations, and persisting the results to Amazon Elasticsearch Service to be visualized from Kibana.

## ANT402-R2: Lift and shift an Apache Kafka cluster to Amazon MSK 

Bring your Apache Kafka cluster to Amazon Managed Streaming for Kafka. Amazon MSK is a fully managed service that makes it easy to build and run applications that use Apache Kafka to process streaming data. Apache Kafka is an open-source platform for building real-time streaming data pipelines and applications. In this session, we show how to lift and shift your self-managed Apache Kafka cluster using MirrorMaker 2.0. We cover topics like running hot/hot Apache Kafka clusters and walk through migrating a live Apache Kafka cluster.

## ANT404-R1: Build a single query to analyze data across Amazon Redshift & Amazon S3 

Amazon Redshift offers a common query interface against data stored in fast, local storage (Amazon Redshift) and data stored in high-capacity, inexpensive storage (Amazon S3). This workshop covers the basics of this tiered storage model and outlines design patterns that you can leverage to get the most from large volumes of data. Learn how to build out your own Amazon Redshift cluster with multiple data sets to illustrate the trade-offs between the storage systems. Learn how to distribute your data and design your DDL to deliver the best data warehouse for your business.

## ANT406-R1: Build a single query to analyze data across Amazon Redshift and Amazon S3 

All organizations have dark data that is not loaded into their data warehouse for analysis. When that data is needed, ETL setup and data loading can take days or weeks, delaying time to insight. This session shows you how to mine your Amazon S3 data lake with Amazon Redshift without the need for data movement. Learn how to write a single query that analyzes open data formats stored in your Amazon S3 data lake and data stored in Amazon Redshift. Please bring your laptop.

## ANT407-R1: Real-time apps with Amazon Kinesis Data Analytics and Apache Flink 

Building production-ready streaming applications can be complex, and maintaining them once they go live can be expensive and require dedicated resources and time. By using Amazon Kinesis fully managed streaming services, you can build, deploy, and maintain real-time applications that are highly available, durable, secure, and cost effective. In this session, we walk through how to build an application with Java leveraging Apache Flink, and share best practices for building and maintaining live applications. A foundational understanding of Apache Flink and Java is recommended for this session. Please come prepared with an active AWS account. Please bring your laptop.

## ANT408-R1: Amazon ES sizing and capacity planning 

How many instances? How many shards? What can I monitor? Whether you're new to Amazon Elasticsearch Service (Amazon ES) or a veteran, you need to understand where to start with capacity planning and how to adjust based on monitoring your domain. In this session, we address all of your questions on sizing, explaining the drivers and key metrics along the way.

## ANT409-R1: Getting started with streaming data and Amazon Kinesis 

In this session, we walk through how to build a simple, end-to-end streaming architecture using Amazon Kinesis and AWS Lambda. We cover how continuous, serverless processing works, and the best practices for taking a simple app and getting it into production. Please bring your laptop.

## ANT411-R1: Learn how to make ETL and ELT easy with Amazon Redshift 

Loading data into your data warehouse quickly and reliably is a big pain point for many organizations. In this session, we show you how to generate the schema for your semi-structured data; create ETL code to transform, flatten, and enrich the data; and load it into Amazon Redshift on a recurring basis. You learn best practices to make your data pipeline performant and efficient. Please bring your laptop.

## ANT412-R1: Modernize your data warehouse with Amazon Redshift 

Migrating an on-premises data warehouse to the cloud is often perceived as complex, but it doesn't have to be. In this builders session, we go over the steps you should take to correctly collect your requirements. We also cover AWS services that can assist you in migrating your data to Amazon Redshift, such as AWS Database Migration Service (AWS DMS), AWS Snowball, and AWS Snowmobile. We then dive into targeted use cases based on the needs of the participants in the room. Please bring your laptop.

## ANT413-R1: How to tame unpredictable analytics workloads with Amazon Redshift 

Scaling a traditional data warehouse can be complex, time consuming, and expensive. In this session, we show you how to deploy Amazon Redshift in minutes and automate most administrative tasks. Learn how to manage, monitor, and scale your data warehouse quickly and easily. You also learn how to deploy and scale multiple independent clusters, and scale each independently to address different workload scenarios. Please bring your laptop.

## ANT414-R1: Build great Kibana visualizations 

In this session, we walk you through how to visualize your data in Kibana. You start by learning how to create a visualization and then bring those visualizations together under an overarching dashboard. We cover visualizations such as mapping latitude and longitude, heat maps, bar charts, lines, and newer tools such as Vega. Please bring your laptop.

## ANT415-R1: Learn how to quickly ingest data into Amazon S3 

Want to quickly get data into Amazon Simple Storage Service (Amazon S3) without a large number of small objects? Learn how you can use streaming data to capture, buffer, and deliver data to Amazon S3 in an optimal manner using Amazon Kinesis. Use this pattern to more easily and quickly take advantage of services that process data from Amazon S3, including Amazon Redshift and Amazon Athena. Please come prepared with an active AWS account and your laptop.

## ANT416-R: Performance and elasticity in Amazon Redshift 

This session dives deep into the capabilities of Amazon Redshift. See how Amazon Redshift achieves its state-of-the-art performance and learn about all aspects of elasticity, from the compute and data elasticity within a single cluster to elasticity across multiple clusters.

## ANT416-R1: Performance and elasticity in Amazon Redshift 

This session dives deep into the capabilities of Amazon Redshift. See how Amazon Redshift achieves its state-of-the-art performance and learn about all aspects of elasticity, from the compute and data elasticity within a single cluster to elasticity across multiple clusters.

## ANT417: Accelerating performance with materialized views 

Amazon Redshift materialized views enable a dramatic reduction in query latency. This session explains how to get faster query results, either automatically or by having the queries explicitly refer to the materialized views. Materialized views also enable the acceleration of ETL pipelines by automatically and incrementally propagating changes from the base table data into the derived data of the materialized views, thus providing a superior alternative to the CTAS commands that recompute the derived data.

## ANT418: Deep dive and best practices for Amazon Redshift   

In this session, we take an in-depth look at best practices for data warehousing with Amazon Redshift. We show you the best way to analyze all your data, inside and outside your data warehouse, without moving the data, which helps you gain deeper insights for running your business. We also cover best practices for how to design optimal schemas, load data efficiently, and optimize your queries to deliver high throughput and performance.


# Application Integration

## API201: Accelerating app migration using Amazon MQ 

A managed message broker like Amazon MQ is essential to connect applications with messaging. In this workshop, learn how to set up an Amazon MQ broker and use the supporting protocols. We dive deep into the security and monitoring features of Amazon MQ and show you how Amazon MQ works across multiple Availability Zones to provide high availability to your systems. You'll leave with a deeper understanding of how to use Amazon MQ to migrate your enterprise applications to the cloud.

## API202-R1: Building a bridge solution from IBM MQ to Amazon MQ 

Increasingly, customers want to move from commercial brokers to open-source brokers on the cloud. The challenge they face is that these message brokers are tightly integrated with several of their mission-critical applications. Amazon MQ is a managed ActiveMQ service running on AWS. In this session, we explore an approach to building a bridge solution from IBM MQ to Amazon MQ. The solution provides a phased nondisruptive approach that customers can adopt to migrate their applications to the cloud and use Amazon MQ as the message broker. We also explore options on benchmarking performance of Amazon MQ broker based on customer requirements. Please bring your laptop.

## API301: Securing data in serverless applications and messaging services 

In this chalk talk, we walk you through the process of designing a serverless application that secures customer data sent to the cloud. The design uses features recently introduced by Amazon Simple Notification Service (Amazon SNS) and Amazon Simple Queue Service (Amazon SQS), including AWS Key Management Service (AWS KMS) keys for encrypting messages at rest and Amazon Virtual Private Cloud (Amazon VPC) endpoints powered by AWS PrivateLink for sending messages without traversing the public internet. These techniques are security best practices for systems that deal with private data, such as e-commerce orders, candidate resumes, or employee information.

## API304: Scalable serverless event-driven applications using Amazon SQS & Lambda 

Event-driven integration patterns emerged to enable integration between serverless applications at scale. Join this session to learn best practices for integrating serverless applications using Amazon Simple Queue Service (Amazon SQS) triggers. We dive deep into the architecture of Amazon SQS triggers to AWS Lambda and how it was engineered to autoscale your Lambda functions. Explore how to tune Lambda and Amazon SQS to scale your existing applications without having to worry about provisioning capacity.

## API305-R1: Building serverless machine-learning workflows 

Modern machine-learning workflows leverage AWS services such as Amazon Transcribe and Amazon Comprehend to extract, validate, mutate, and enrich your data. Some drive transactional systems that use ML to generate metadata, others derive insights by visualizing customer-interaction sentiment. All share a common challenge: orchestrating a combination of sequential and parallel steps fulfilled by independent microservices. Join us as we examine how workflows can be used to manage that orchestration in a way that's scalable, reliable, and easy to maintain and run. We contrast two approaches for creating such workflows: a traditional monolithic approach and a serverless approach utilizing AWS Step Functions.

## API306-R1: Building event-driven architectures 

Many customers choose to build event-driven application architectures, in which subscriber or target services automatically perform in response to events triggered by publisher or source services. This pattern can help development teams operate more independently so they can release new features faster and make their applications more scalable. In this session, we cover the basics of event-driven design, using examples involving Amazon Simple Notification Service (Amazon SNS), Amazon Simple Queue Service (Amazon SQS), AWS Lambda, Amazon EventBridge, and more. You also learn how to choose the right AWS service for the job, and how to optimize for cost and performance.

## API307: Build efficient and scalable distributed applications using Amazon MQ 

In this session, we demonstrate the features of the Amazon MQ network of brokers, availability, and performance tuning (to reduce cost of ownership and mitigate risk).

## API308: Monolith to serverless SaaS: Migrating to multi-tenant architecture 

Many organizations begin their journey to SaaS with a single-tenant monolithic architecture. Their goal is to transform these systems into modern, multi-tenant serverless systems that can realize all of the cost, scale, and agility benefits that SaaS environments demand. In this session, we dig into the details of this transformation, exploring approaches to incrementally decompose your monolith into serverless microservices. We also look at how tenancy is introduced into your new microservices, pushing tenant for logging, metrics, data partitioning, and tenant isolation into Lambda layers. The goal is to outline an evolutionary approach that guides your path to a serverless SaaS model.

## API309: Durable serverless architecture: Working with dead-letter queues 

Dead-letter queues (DLQs) are useful for debugging and increasing the durability of your applications and messaging systems because they let you isolate problematic messages to determine why they haven't been successfully processed. In this chalk talk, we walk you through DLQs for AWS Lambda, Amazon Simple Queue Service (Amazon SQS), and Amazon Simple Notification Service (Amazon SNS) and how each one addresses a different failure mode. As part of the session, we design a serverless architecture that benefits from DLQs to address all of these failure modes.

## API310-R1: How to refactor a monolith to serverless in 8 steps 

Refactoring a monolith to serverless can be intimidating, but there are discrete steps that you can take to simplify the process. In this chalk talk, we outline eight steps for successfully refactoring your monolith and highlight key decision points such as language and tooling choices. Through real-world examples of successful migrations, we uncover common mistakes, useful techniques for identifying components for migration and service boundaries, and processes for migrating large amounts of data without downtime. Bring your refactoring challenges to this interactive session to see how these techniques can be applied in the context of your own application.

## API311: Managing business processes using AWS Step Functions 

iRobot uses AWS Step Functions to manage a broad range of business processes, from regulatory compliance to firmware rollouts. Step Functions has eliminated the need for burdensome and expensive long-running compute resources to manage these processes and replaced it with an accessible, declarative language that can glue together a broad suite of AWS services. In this session, we present several business use cases for Step Functions, along with implementation patterns, including decoupling, eternal processes, and approval emails.

## API312: How to select the right application-integration service 

Sometimes, architects are unsure about the right application-integration tool or protocol for their use case. To begin with, there is messaging vs. streaming. But even when we're clear about that, there are several different protocols and tools for each category. In this chalk talk, we introduce a decision tree to help you select the right messaging or streaming tool for your architecture. We also discuss real-world scenarios provided by the audience. Bring your challenges and leave this session with a solid understanding of when to use what in messaging and streaming.

## API313: Nondisruptive strategies for application migration 

Many companies want to refactor applications to increase agility, but they face the challenge of migrating on-premises workloads to the cloud first. This is especially challenging for mission-critical applications, where any downtime has a major customer or business impact. In this session, we dive into common application-migration challenges and nondisruptive approaches, including hybrid architectures, that minimize the impact that migration has on existing applications. We review common on-premises message-broker vendors, like IBM MQ and RabbitMQ, and the benefits of using a managed broker like Amazon MQ as part of a migration strategy.

## API315-R3: Application integration patterns for microservices 

One of the implications of applying the microservices architectural style is that a lot of communication between components is done over the network. In order to achieve the promises of microservices, this communication needs to happen in a loosely coupled manner. In this session, we discuss some fundamental application integration patterns mostly based on messaging and connect them to real-world use cases in a microservices scenario. We also point out some benefits that asynchronous messaging can have over REST APIs for communication between microservices.

## API320-R1: [NEW LAUNCH!] Building event-driven architectures faster than ever with Amazon EventBridge 

Companies are increasingly opting to build applications using event-driven architectures to improve application scalability and reliability. In this session we'll review the basics of event-driven architectures, and reveal how new features in Amazon EventBridge can dramatically reduce the time and code required to build applications that react to events. EventBridge can now discover the available events and automatically generate code from their structure and contents. Through use cases and examples, we'll review how to simplify the process of ingesting, routing, and processing events from your own apps, AWS services, or SaaS apps. With the launch of schema registry, Amazon EventBridge can now discover the available events and automatically generate code from their structure and contents.

## API321: [NEW LAUNCH!] Event-Processing Workflows at Scale with AWS Step Functions 

> Event-Processing Workflows at Scale with AWS Step Functions In this session, learn how to leverage AWS Step Functions Express Workflows and AWS Lambda to build and run event-processing applications. We will explore real-world examples including IoT data ingestion, streaming data transformation, and mobile app backends. Expect to leave this session with a practical understanding of how to use event-processing workflows to scale your application seamlessly, and express your business logic more productively.


# Architecture

ARC201-R1: Comparing serverless and containers 

Microservices are a great way to segment your application into well-defined, self-contained units of functionality. Come join us in this chalk talk as we discuss two common architectures for deploying microservices: containers and serverless.

ARC202-R2: Architecting for the cloud 

Bring your ideas, war stories, and 'aha moments' to this interactive session with an AWS solutions architect, where we discuss cloud architecture best practices. We highlight specific discoveries and insights from AWS customers, as the cloud has redefined how they think about scalability, designing for failure, constrained thinking, elasticity, parallel processing, loose coupling, and more. Come with your own story or an interest in learning how AWS forever changed the way your colleagues think about the IT world.

ARC203: Innovation at speed   

What does it take to innovate quickly? In this session, we address how blockers to innovation, such as culture, skills, antiquated processes, and board-level concerns, can stand in the way of business agility. We map out a pathway to digital transformation, including new metrics for success, integration of real-world best practices from enterprises, and the most effective organizational patterns, as we integrate the business with development and operations.

ARC204-R2: Cost optimizing a workload 

In this hands-on session, we guide you through the AWS tools, services, and design decisions for architecting cost-optimized applications. Whether you run cloud-native applications or legacy monolithic applications, we show you tricks and techniques to run your workload at the lowest cost possible. Once the workload is optimized, we set up an enterprise cost-optimization dashboard to measure and report on workload efficiency utilizing Amazon Athena and Amazon QuickSight.

ARC206-S: Meredith delivers media content to all with AWS and Rubrik 

Meredith Corporation is America's largest media company of iconic magazine brands, television stations, and radio stations, including PEOPLE, Better Homes & Gardens, InStyle, and Allrecipes. Delivering that content online and in print requires Meredith's IT department to maintain a robust and highly available hybrid infrastructure on premises and on AWS. Join Meredith and its cloud data management partner, Rubrik, to learn how Meredith keeps up with the growing demand for more media by leveraging different AWS services to run its production workloads. Additionally, you'll learn how Rubrik protects Meredith's media assets on premises and in the cloud. This presentation is brought to you by Rubrik, an APN Partner.

ARC207-S: Migrating applications to serverless Apache Kafka + KSQL 

You were using Apache Kafka on premises a few years ago and have been happily building applications with it since then. But now it's well past time to move to the cloud, and you'd like to refactor your first application to something that feels more native to the cloud. In this talk, we demonstrate doing this with a fictional application, migrating the data from on premises to Confluent Cloud and converting the previous on-premises monolith to a set of stateless microservices fed by real-time, continuous KSQL queries. Leave this session with a clear understanding of how to do the same in your own stack. This presentation is brought to you by Confluent, an APN Partner.

ARC209-R1: Running lean architectures: How to be cost-effective on AWS   

Everybody can save money on AWS by optimizing your architecture! This session reviews a wide range of cost-optimization strategies, featuring real-world examples. In addition to Reserved Instances, we have a special focus on Spot Instances to get a discount of up to 90 percent. We also talk about leveraging AWS Auto Scaling, caching and offloading content to Amazon CloudFront to reduce backend load, and much more. Running serverless? Learn how to cut costs on serverless through minimizing AWS Lambda execution time and maximizing networking throughput. Additionally, we cover optimizing training and inference costs for machine learning on AWS.

ARC212-R1: Cox Automotive: AWS Well-Architected Results on 200+ platforms   

How do you know if you and your team are following cloud architecture best practices? How do you assess your potential risks? This session shows how the AWS Well-Architected Framework provides prescriptive architectural advice, and how the AWS Well-Architected Tool allows you to improve your technology portfolio. Hear executives from Cox Automotive explain how the company uses AWS Well-Architected as part of a scorecard across more than 200 platforms to health-check the Cox Automotive products. Learn how the scorecard works to drive resource and investment decisions, and how it helps measure profitability, technology risk, and engineering maturity.

ARC213-R2: Architecture patterns for multi-region active-active   

With global business, there is an ever-growing need to be able to implement multi-region active-active architecture. However, this requires first-order thinking and attention not just to app and database design but also to DNS, monitoring, traffic shaping, and so on. Furthermore, architecture complexity can increase rapidly, so multiple design trade-offs need to be made. In this session, we discuss challenges and solutions using various AWS services, like Amazon DynamoDB global tables, as well as open source products.

ARC214-R1: Data lake DevOps on AWS 

Standing up a data lake solution is greatly simplified using services like Amazon Kinesis, Amazon S3, AWS Glue, Amazon Redshift, Amazon EMR, and Amazon QuickSight. However, customers also need to deploy changes to data models, ETL scripts, programs, and other artifacts from time to time. This can be complex if not automated and can cause delays or failures in getting insights from data. In this chalk talk, learn how to provision a data lake on AWS and add CI/CD capability to it using AWS DevOps services such as AWS CodeCommit, AWS CodeBuild, AWS CodeDeploy, and AWS CodePipeline.

ARC215-R1: Deconstruct a serverless analytics application 

In this chalk talk, we use an analytics application use case to dive deep into architectural layers of a serverless application on AWS. This session reviews the recommended design principles for a well-architected serverless application, maps AWS services to each architectural layer, and establishes design patterns based on best practices.

ARC216-R1: AI-powered virtual classroom for employee education 

This chalk talk discusses how an interactive virtual classroom training can be developed using AWS services. It shows how to easily build scenes for virtual classrooms using Amazon Sumerian, make it interactive using AI services (Amazon Polly and Amazon Lex), and make it dynamic using AWS Lambda. We then discuss how the solution can be expanded to understand user sentiment using Amazon Comprehend and how to add security using Amazon Cognito. Key takeaways are understanding how AWS media and AI/ML services can be used to build an end-to-end virtual training application.

ARC217-R1: Operating and managing hybrid cloud on AWS 

Operating in a hybrid architecture is a necessary component of an enterprise cloud adoption journey. Security, provisioning, change management, and monitoring are all key aspects of managing any hybrid cloud environment. This session covers the AWS services, open source tools, and AWS partners that can provide enterprises with a secure, well-governed, performant, reliable, and well-operated hybrid cloud environment. We cover infrastructure and application continuous delivery and improvement solutions, along with best practices to automate hybrid cloud provisioning and operations activities.

ARC218-L: Leadership session: AWS architecture   

The skills required to be a successful architect are changing at a rapid pace, and this change shows no signs of slowing down. In this session, we reflect on the evolving role of the architect in organizations large and small. We recap the most impactful announcements from the week for architects, review some key tools designed to make life easier for architects building on AWS, and discuss industry changes that will impact future architectures.

ARC219-R1: AWS Cost Management tools for cost & usage optimization 

This is a hands-on session that guides you through the AWS tools and services used to drive cost optimization throughout your business. We look at the core AWS tools, such as AWS Identity and Access Management (IAM) policies, AWS Budgets, and Cost Explorer, to perform advanced billing analysis with Amazon Athena. Lastly, we create visualizations of cost usage using Amazon QuickSight.

ARC220-S: Dell Technologies cloud-enabled infrastructure   

For customers with data stores on-premises, Dell Technologies cloud-enabled infrastructure makes it possible to access AWS compute and analytics services. Additionally, it supports moving VMware workloads between on-premises and VMware Cloud on AWS. Join us in this session to learn more about how Dell Technologies cloud-enabled infrastructure can connect your on-premises data and workloads with your AWS environment for compute purposes, analytics services, disaster recovery scenarios, and regular access to your remote and branch offices. This presentation is brought to you by Dell, an APN Partner.

ARC222-S: Chesapeake Energy: Transforming oil and gas production with AWS 

Using IoT data and machine learning-based predictive maintenance models, Chesapeake is maximizing the uptime of oil and gas wells. Join this session to learn about the architecture behind this effort, which uses AWS services like Amazon EC2, Amazon S3, AWS Batch, and AWS Lambda as the data warehouse, while Control-M serves as the orchestration engine. This presentation is brought to you by BMC Software, an APN Partner.

ARC223-S: Reimagine SME banking: OpenDATA-enabled innovation at Rabobank   

Banks face unprecedented challenges as customer needs evolve, regulations change, and fintech disrupts the market. Come learn how Rabobank, enabled by Deloitte's OpenDATA platform, launched an SME lending solution in just 13 weeks, allowing customers to receive loan offers in less than 15 minutes based on machine learning and artificial intelligence models. Hear how this end-to-end platform powered by AWS acts as a toolkit to kick-start rapid innovation and delivery through an integrated set of cloud services and accelerators. This session details Rabobank's journey, including how the OpenDATA platform can enable incumbent financial services players to build and launch winning products in an open banking world. This presentation is brought to you by Deloitte, an APN Partner.

ARC224-S: How rapid growth accelerated Zipwhip's move to AWS   

Zipwhip is an SMS and MMS texting provider that has seen a 280-percent message growth over the past year. To support this growth and effectively deal with aging on-premises infrastructure, Zipwhip required a drastic migration to the cloud. Come learn how three engineers redesigned Zipwhip's infrastructure over nine months and began leveraging AWS services, including Amazon EKS and Nitro-based Amazon EC2 instances. Hear how they used F5 Network's BIG-IP Virtual Edition (VE) and NGINX (Kubernetes ingress controllers) to optimize application performance, visibility, and security throughout this migration. Finally, learn how with AWS, they increased performance, scalability, and resiliency while optimizing costs over traditional infrastructure. This presentation is brought to you by F5 Networks, an APN Partner.

ARC301-R3: Architecture patterns: Serverless stream processing at scale 

Streaming application architectures are commonly used to solve real-time analytics requirements. Serverless architectures are a great fit for stream-processing applications because they enable you to lower operational costs and pay per execution, and they can seamlessly scale as your stream data rates vary. In this workshop, learn how to create serverless stream-processing architectures that can seamlessly scale as your needs grow. Get hands-on experience using Amazon Kinesis Data Streams, Amazon Kinesis Data Firehose, Amazon Kinesis Data Analytics, and AWS Lambda to create real-time analytics pipelines. Learn how to ingest streaming data at scale and process it to generate real-time insights. Please bring your laptop.

ARC302-R1: Patterns for hosting ML models in low latency microservices 

Deploying deep learning models in a low latency microservices environment is challenging. However, without this, we wouldn't have many of the AI applications that we have today, such as voice response systems, fast image and video analytics, responsive visual search engines, and real-time predictions for business transactions, such as for ride-hailing apps. These challenges are due to the high amount of compute involved, latencies of models and costs, difficulties in deployment, A/B testing, and monitoring performance. In this session, we demonstrate Amazon Elastic Inference, Amazon SageMaker Neo and batch inference, AWS Inferentia, and AWS X-Ray, and we discuss how to use these services to overcome these challenges.

ARC303-R2: Failing successfully: The AWS approach to resilient design 

AWS global infrastructure provides the tools customers need to design resilient and reliable services. In this session, we explore how to get the most out of these tools. We discuss achieving continued stability and availability in the face of impaired dependencies. We also cover AWS tools and best practices you can use to design applications and services that avoid overload.

ARC304-R3: From one to many: Diving deeper into evolving VPC design 

In this session, we discuss a customer's evolution from a single regional VPC to multi-VPC, multi-region designs with diverse connectivity into on-premises systems and infrastructure. We review ways to manage multi-tenant VPCs and investigate creative solutions for scaling and securing outbound VPC traffic, securing private access to AWS public services, such as Amazon S3, Amazon SNS, and Amazon SQS. We explore AWS Transit Gateway and the architectures that reduce the complexity of establishing global VPC networks with integration points to the AWS Direct Connect gateway in multiple Regions. Lastly, we explore global routing solutions that complement globally distributed environments.

ARC305-R1: Migrating single-tenant applications to multi-tenant SaaS 

The appeal of SaaS has many ISVs interested in the value of delivering their solutions in a SaaS model. Moving a single-tenant application to a multi-tenant environment can be daunting. In this session, we look at many obstacles that ISVs face as they consider the move to a SaaS model. We explore a range of patterns from lift-and-shift to an incremental cutover to multi-tenant-aware microservices, data, and infrastructure. We highlight the challenges and technical considerations, including onboarding, identity, billing, metering, analytics, that shape your solution and allow you to better align your transformed solution with SaaS best practices.

ARC307-R3: Serverless architectural patterns and best practices   

As serverless architectures become more popular, customers need a framework of patterns to help them to identify how to leverage AWS to deploy their workloads without managing servers or operating systems. In this session, we describe reusable serverless patterns while considering costs. For each pattern, we provide operational, security, and reliability best practices and discuss potential challenges. We also demonstrate the implementation of some of the patterns in a reference solution. This session can help you recognize services and applications for serverless architectures in your own organization and understand areas of potential savings and increased agility and reliability.

ARC308-R1: Hands-on SaaS: Constructing a multi-tenant solution on AWS 

SaaS presents developers with unique architectural challenges. Supporting a multi-tenant model often means rethinking your approach to almost every layer of your architecture. Onboarding, security, data partitioning, tenant isolation, identity-these are areas that must be factored into how you design, build, and deploy your SaaS solution. In this workshop, we expose you to core concepts of SaaS architecture through a brief lecture and then dive into a reference SaaS architecture through a series of hands-on activities, where you explore a functional solution and then use code and configuration to extend the capabilities of this SaaS environment.

ARC309-R1: Hands-on: Building a multi-region active-active solution 

Do you need a highly available global application? Join us to build a global, multi-region resilient architecture with containers and serverless with polyglot persistence databases. You must bring your own laptop and have an AWS account for this hands-on session. This workshop includes using an Amazon Route 53 domain, Amazon API Gateway, Amazon Cognito, AWS Lambda, Amazon DynamoDB, AWS Fargate, Amazon Aurora with AWS code services, and AWS Cloud9.

ARC310-R1: Serverless data lake patterns for voice, vision, and ML 

Industry 4.0 demands greater insight into data to bring people, processes, and equipment together. In this workshop, we illustrate how to gain business insights from video and voice data sources, highlighting the data pipeline. We ingest source feeds, efficiently store the data, and perform advanced analytics using AWS ML services and analysis tools. Typical applications include anomaly detection (detecting spills or hazardous objects and predictive maintenance) and voice-sentiment analysis (customer service insights). By the end of the session, you will be able to quickly analyze data for uncommon characteristics using those detections to initiate a wide variety of actions.

## ARC313-R1: Architecting global storage with AWS Lambda 

Companies are searching for ways to synchronize their assets to their production facilities around the world, both on-premises and in the cloud, using best practices with AWS technologies. In this session learn how you can use AWS Lambda, Amazon API Gateway, Amazon Simple Storage Service (Amazon S3), AWS Storage Gateway, AWS Directory Service, and AWS Fargate to build a serverless global storage platform to enable employee collaboration around the world.

## ARC314-R2: Decoupled microservices: Building scalable applications 

Often, when the microservices architecture style is applied, much of the communication between components is done over the network. In order to achieve the promises of microservices, this communication needs to happen in a loosely coupled manner. One frequently used option is to have all services expose an API following the REST architectural style. However, there is another option that provides even looser coupling: asynchronous messaging. In this workshop, you learn how to use AWS messaging services to build decoupled microservices architectures to achieve massive scale.

## ARC315-R1: Build end-to-end governance with AWS Control Tower 

As you build and deploy an AWS landing zone solution leveraging AWS Control Tower, a common next step is to build out networking configurations for connecting to other AWS accounts and on-premises networks and federated access. In this session, you learn how to build, deploy, and test a transit gateway, as well as Okta integration for federated access on an AWS Control Tower-configured environment.

## ARC316-R1: Deploy and monitor a serverless application 

When building serverless applications, you need to know the design tradeoffs for improving performance in addition to how well your application is performing. What are the bottlenecks, time sinks, and bugs? Amazon Elasticsearch Service-with its ability to ingest, correlate search, and visualize data in near real time from different sources-is an ideal solution. In this workshop, you build on a bookstore application and add detailed monitoring and tracing across the stack. You'll flow data from Amazon DynamoDB and AWS Lambda (via AWS X-Ray) to Amazon ES, build visualizations, identify performance problems, and implement performance improvements to the application.

## ARC318-R3: Automated ML model development life cycle 

The machine-learning workflow is an iterative cross-functional process. In this session, you integrate a machine-learning model into a data pipeline. Learn how to automate data preparation, feature engineering, and periodic model tuning. Then see how to incorporate your model into a production workload and monitor model performance. Finally, integrate the model into a continuous deployment system to complete the model development life cycle (MDLC). Please bring your laptop.

## ARC319-R5: Security vulnerability identification and remediation 

In this session, learn how to monitor, alert, and remediate security events in your AWS environments. You use an AWS CloudFormation template to introduce a number of issues into accounts, including unencrypted and public S3 buckets, open security groups, and AWS Identity and Access Management (IAM) accounts without MFA enabled. You then practice monitoring, alerting, and automatic remediation for these issues using AWS Config, AWS Security Hub, and AWS Lambda. Please bring your laptop.

## ARC320-R2: Build self-service registration with facial recognition 

In this session, we build a modern web application that uses machine learning technologies for self-service registration. Your guests will be able to register for your event via this application and then check in using facial recognition on a smart webcam. You will leave with a fully functional application that was used for an actual AWS event. Please bring your laptop.

## ARC321-R2: Enabling AWS PrivateLink with the AWS Cloud Development Kit 

AWS PrivateLink provides private network access to AWS services and your own SaaS-style services. In this session, learn how to use the AWS Cloud Development Kit (CDK) to create a reusable component that sets up a proxy layer for resources that don't natively support AWS PrivateLink. Please bring your laptop.

## ARC322-R3: Enterprise messaging patterns 

Messaging applications are widely used to integrate different types of applications and decouple complex designs. In this session, learn how to use Apache Camel and Amazon MQ to implement common integration patterns for routing, message transformation, and integration with other AWS services. As an added bonus, we also explore how to scale Apache Camel using Amazon Elastic Kubernetes Service (Amazon EKS). The knowledge gained in this session can be applied to migrating to Amazon MQ from common legacy messaging service providers like IBM MQ and TIBCO. Please bring your laptop.

## ARC333-R2: Orchestrating Operations to Manage AWS Resources 

With the advent of virtualization and the cloud, IT staff face increasingly complex management challenges as systems scale. In this session, we'll review the architecture of the AWS Operations Conductor Solution, which automates a number of management tasks, such as archiving, data backup and recovery, resource selection and scheduling, and configuration management. Attendees will learn how to utilize relevant services, such as AWS Systems Manager and Amazon CloudWatch, to extend the Operations Conductor Solution or create automation applications for their own organization.

## ARC334-R2: From one to many: Evolving VPC design   

As more customers adopt Amazon VPC architectures, the features and flexibility of the service are encountering the obstacles of evolving design requirements. In this session, we follow the evolution of a single regional VPC to a multi-VPC, multi-region design with diverse connectivity into on-premises systems and infrastructure. Along the way, we investigate creative customer solutions for scaling and securing outbound VPC traffic, securing private access to Amazon Simple Storage Service (Amazon S3), managing multi-tenant VPCs, integrating existing customer networks through AWS Direct Connect, and building a full VPC mesh network across global regions.

## ARC335-R1: Designing for failure: Architecting resilient systems on AWS   

Customers moving mission-critical applications to the cloud are seeking guidance to replicate and improve the resiliency of their Tier 1 systems while simultaneously meeting compliance and regulatory requirements. Natural disasters, internet disruptions, or hardware or software failure can lead to events requiring customers to invoke disaster recovery (DR) plans. Join us in this session to learn how to design for failure and remain resilient in the event of disaster by designing applications using highly resilient components and service features.

## ARC336-R1: CLP Innovation: Increasing agility with cloud-native architectures   

In today's tech-driven world, an organization's architecture is a competitive differentiator. A key piece of this advantage lies in the ability to move fast. In this session, we dive into how cloud-native architecture patterns are changing the way businesses think about speed and cost of innovation. We hear from CLP Innovation Enterprises Ltd. on why it made the decision to reinvent with cloud-native services, what it learned, and benefits it has gained along its journey to modern application development.

## ARC337-R1: Baking the best security layer cake 

It's not enough to fix a bug or issue, we also have to dig in and find a deeper kind of fix that eliminates most bugs of that entire class. Failsafe design and defense in depth are nothing new, but in security, the tendency to add layers can backfire. Each new layer brings its own potential bugs, risks, costs, and challenges. In this talk, we take a look at just how effective some of the simplest mitigations are and how modern verification techniques can provide run-time assurance without run-time risk.

## ARC338-R1: How Goldman Sachs minimizes the impact of managing events 

The operational excellence pillar of the AWS Well-Architected Framework includes guidance and best practices on operating in the cloud. Join our talk as representatives from Goldman Sachs share how the company applied these best practices to reduce the impact of events and the level of effort they extended to manage them. They also discuss how they enabled their operations teams to safely do more by establishing the standards for operations that enable them to scale as new projects enter the cloud. Learn how AWS Systems Manager OpsCenter can support your situational awareness and event response, enabling you to view, investigate, and remediate operational issues presented with contextually relevant data.

## ARC339-R1: Best practices for IoT architecture using AWS smart product solution   

As more consumer products are embedded with sensors that allow communication and data transfer between the product and the manufacturer, customers need architecture to onboard, protect, and monitor device fleets. In this session, we cover best practices for creating this architecture and use the decisions that were made when creating the AWS smart product solution as a guide. The architecture incorporates AWS IoT Core, as well as AWS Lambda for backend microservices, AWS IoT Analytics with Amazon QuickSight to analyze telemetry data, and AWS IoT Device Defender to audit device configurations. We also show you how to use AWS CDK to create customized deployments.

## ARC340-R1: Amazon.com automating machine learning deployments at scale   

Machine learning involves more than just training models; you need to source and prepare data, engineer features, select algorithms, train and tune models, and then deploy those models and monitor their performance in production. Learn how Amazon Consumer Payments uses Amazon SageMaker, AWS Glue, AWS Step Functions, Amazon API Gateway, AWS Lambda, AWS Batch, Amazon Elastic Container Registry (Amazon ECR), and AWS CloudFormation to automate a CI/CD framework for business-critical machine learning workloads at scale.

## ARC341-R1: Automation safety: How to avoid breaking things at scale 

In this chalk talk, learn how automation can benefit your operations activities, the risks of doing it badly, and how to do it safely. Through real-world examples that highlight what can go wrong, learn the automation safety best practices that can help you reduce your risk. We discuss default automation behaviors, tagging, permissions, blast radius, circuit breakers, back-off, runbooks, playbooks, and more. We also discuss AWS tools that can help you implement automation safety, and we take your questions about automation and automation safety on AWS.

## ARC342-R1: Cell-based architectures for global, well-architected apps 

In this chalk talk, we discuss patterns and practices for cell-based architectures (compartmentalization) and how they can help you build and migrate applications to the cloud. SaaS providers leverage cells for multi-tenant systems, and web, mobile, IoT, and almost any company can benefit from cells for better scale while maintaining higher availability, better operational management, and more secure and robust platforms.

## ARC343-R2: Modernizing legacy applications during your cloud migration 

This chalk talk covers the journey of a real-world customer as they migrate their legacy application stack to the cloud. The existing tech stack was a mix of .NET, Java-based applications using SQL server, and the target platform was a combination of AWS container services like AWS Fargate, AWS Elastic Beanstalk, Amazon RDS for SQL Server for the database services, and Amazon Cognito for application authentication.

## ARC344-R1: Understanding the landing zone journey 

Wondering how your organization can benefit from a landing zone? What is the thought process and journey? In this session, we talk about the multi-account strategy. Additionally, we discuss the story behind AWS Landing Zone; AWS Control Tower versus AWS Landing Zone; and Account Vending Machine versus Account Factory.

## ARC345-R1: Architecting data lakes with AWS data and analytics services 

Customers with disparate data sources (databases, flat files, enterprise systems) have difficulty architecting a central data lake that can provide users a single source of truth and drive business outcomes. During this chalk talk, we discuss how to architect a secure data lake using Amazon S3, AWS Database Migration Service (AWS DMS), AWS Lake Formation, AWS Glue, and Amazon Athena. By the end of this session, you will be able to: understand key architecture tenets around data ingestion patterns, make design decisions to securely store data, apply granular security policies for access, and catalog/transform your data for end-user access and consumption.

## ARC346-R1: AWS ML at the edge: Building production-intended solutions 

Machine learning and IoT have become commonplace words in the enterprise workplace. Even in our homes we have ML-enabled IoT devices (we're looking at you, Amazon Alexa). But what does it look like to combine ML and IoT at the edge in a production environment? Join us in a discussion about how we built scalable production-intended ML solutions at the edge for many AWS customers. From detecting cracks in wheels on heavy machinery to automated inventory tracking in factories, we show you the results of our experiments and best practices learned the hard way, all while leveraging existing AWS services.

## ARC347-R1: Reinventing the Andon Cord: Amazon Virtual Andon solution 

The Amazon Virtual Andon solution was built for Amazon fulfillment centers as an issue and notification system, and it is now publicly available as an AWS solution. In this session, we go behind the scenes of the creation of this solution and explain how we incorporated AWS IoT Core to monitor and connect to devices on the floor. We also discuss how we used IoT Rules Engine and Amazon SNS to send event notifications and AWS AppSync to perform complex queries and aggregations using GraphQL.

## ARC348-R1: Protecting your web applications from common attack vectors 

A web application that is unable to fend off attacks leads to an erosion of customer trust, and in the worst case, it leads to customer privacy issues. In this workshop, you learn best practices for architecting web applications to block common attack patterns that affect application availability and security. We take a compromised web application and use tools such as the AWS WAF Security Automations solution, and we build, train, and deploy a machine learning model to identify abnormal behaviors. We also build an application that automates security assessments and operational tasks, identifies anomalies in data, and monitors your AWS environment.

## ARC349-R1: Beyond five 9s: Lessons from our highest available data planes   

Every AWS service is designed to be highly available, but a small number of what we call Tier 0 services get extra-special attention. Come hear lessons from how AWS has built and architected Amazon Route 53 and the AWS authentication system, designed to survive cataclysmic failures, enormous load increases, and more. We cover our approach to redundancy and resilience at the infrastructure, software, and team levels, and we get into how the teams tasked with keeping the internet running manage themselves and still keep up with the pace of change that AWS customers demand.

## ARC401-R5: Scale up a web application 

In this session, you use an automated test suite to bombard an application with an increasing number of concurrent users. You then identify the bottlenecks and refactor the application. Find out how many concurrent users you can scale up to. Please bring your laptop.

## ARC402-R1: Connecting many VPCs: Network design patterns at scale 

In this session, we show you how to design connectivity between many VPCs and how new services interact with network architectures. We review common design patterns, such as shared services VPCs, transit VPCs, private links, firewalls, and more. We also cover solutions to common challenges, such as VPN sprawl, keeping up with VPC automation, sharing services, and network segmentation at scale for hundreds of VPCs.

## ARC404-R1: Resiliency testing: Verifying your system is as reliable as you think 

In this workshop, we illustrate how to set up your own resiliency testing. We set up a simple three-tier architecture and explore the failure modes with Bash and Python scripts. To participate, you need an account that can run AWS CloudFormation, AWS Step Functions, AWS Lambda, Application Load Balancers, Amazon Elastic Compute Cloud (Amazon EC2), Amazon Relational Database Service (Amazon RDS) for MySQL, AWS Database Migration Service (AWS DMS), and Amazon Route 53.

## ARC405-R2: Building multi-tenant-aware SaaS microservices 

As you move to an SaaS model, you must create an experience for your developers that lets them focus on functionality rather than the details of your multi-tenant policies. In this session, you look at strategies that simplify multi-tenant microservice development, streamlining and standardizing your model for logging, recording metrics, accessing tenant-partitioned data, and authorizing access to your services. You use AWS Lambda layers, Amazon Cognito, and Amazon API Gateway to develop reusable components. Please bring your laptop.

## ARC406-R2: Building multi-region microservices 

In this session, participate in a hands-on exercise where you create, verify, and test a serverless solution across multiple regions using AWS Lambda and Amazon DynamoDB global tables. Please bring your laptop.

## ARC407-R2: Object detection at the edge 

Many applications for machine learning run in environments with low-power devices and intermittent network connectivity. In this session, build an object detection model that counts animals in a video frame. You will then deploy your application to an IoT device and run it on example input data. Please bring your laptop.

## ARC409-R2: Near-zero-downtime migrations to AWS 

> Migrating workloads to AWS requires detailed analysis of the workloads and strategies to avoid data loss and downtime. In this session, you use CloudEndure to analyze and migrate sample workloads often found in large-scale data center migrations, like web applications, databases, and Active Directory. Then, you explore options for rehosting and replatforming. Please bring your laptop.

## ARC411-R1: Reducing blast radius with cell-based architectures 

> One thing we've learned is that failures come in many forms, some expected and some unexpected. A core consideration is how to minimize the blast radius of any failures. In this talk, we focus on cell-based architectures; system, cell, and router properties; and how we designed for failure on AWS leveraging serverless technologies like AWS Lambda, Amazon Kinesis, Amazon Simple Storage Service (Amazon S3), and Amazon Simple Queue Service (Amazon SQS). This cell-based architecture processes 28 petabytes of data with 1 billion transactions a month.

## ARC413-R1: SaaS metrics deep dive: A look inside multi-tenant analytics 

> Metrics are at the core of every SaaS business. Having your finger on the pulse of tenant and system activity is essential to achieving and maintaining scale, agility, and innovation. These metrics directly shape both business and technical strategy. In this chalk talk, we move beyond the concepts of metrics and dig into specific metrics implementation strategies that can be used across all the moving parts of your SaaS architecture. The goal is to provide concrete examples of how systems are instruments, how the data is aggregated, and how it's surfaced to various business and technical consumers.

## ARC414-S: Accelerated analytics: Building the next-gen data platform for Hertz   

> Hertz is undertaking a massive digital transformation to evolve its technology landscape. This move provides an opportunity to extract valuable insights from a large amount of data produced by the new systems. In this session, learn how Deloitte collaborated with Hertz to build a next-generation data platform, which includes an integration hub, a unified reporting layer, and an ecosystem of tools used to build advanced analytics models. Discover how the solution leveraged all native AWS services, such as Amazon S3, Amazon Kinesis, Amazon EMR, and AWS Lambda, to enable cross-functional insights and accelerate the cloud journey in under 12 months. This presentation is brought to you by Deloitte, an APN Partner.

## ARC415-S: Building modern applications with data on Heroku, Salesforce, and AWS 

> Modern application development requires distributed architectures, multi-directional application and data workflows, and multi-disciplinary teams. These are complex interactions in isolation, but they are even more complex when the demands of infrastructure, architecture, and people are intertwined. Data is the lifeblood of this effort, and the ability of data to move across these three boundaries is critical to delivering value. In this session, you learn how Heroku helps developers and enterprises solve these challenges. This presentation is brought to you by Salesforce, an APN Partner.



# Automotive

## AUT301: Building predictive vehicle maintenance models on AWS 

Automobiles are among the most complex mechanisms that exist, made from tens of thousands of parts, expected to perform over a 10-year life span. Whether they're for personal use or in mobility fleets, the ability to predict maintenance to avoid failure can have a significant impact on customer satisfaction, vehicle uptime, safety, and cost. In this session, we introduce AWS solutions for predictive maintenance, and connected vehicles, and show how deep learning can be used for automotive prognostics and vehicle health. Attendees learn how to combine these solutions and their domain expertise to build their own predictive models.

## AUT302: Running autonomous driving simulations at large scale in AWS 

Autonomous driving development requires that developers virtually drive millions of miles per day in thousands of scenarios and their"what-if" variants before deploying autonomous software on physical vehicles. Providing quick feedback to developers on how their software performs requires running those driving simulations at massive scale. However, massive does not mean easy, and we learned a few hard lessons along the way. During this session we provide insights on the challenges of scaling autonomous vehicle (AV) workloads, have an open discussion on architectures for AV, and share tips to prepare your application to run at scale.

## AUT303: How race teams gain a competitive advantage with AWS 

In motorsports, one-tenth of a second can be the difference between first and sixth place-and millions in prize money. In this session, we provide two architectures that race teams use to automatically analyze images and video in real time to gain a competitive advantage. We discuss how to balance built-in machine learning with a custom rules engine to minimize hands-on data science without sacrificing accuracy. We also discuss how to iterate quickly and match the right cloud technology to the challenge as scale increases. Amazon SageMaker and Amazon Rekognition are featured in this session for builders and enthusiasts.

## AUT304: Device provisioning and management for connected vehicles 

One important task in building any connected IoT solution is to have a scalable and secure device management platform. In this chalk talk, we dive deep into areas of building a multi-tenant system that takes care of automated device provisioning, certificate and asset management, over-the-air (OTA) updates, and remote command capabilities. We also show how to provide secure vehicle connectivity to the AWS Cloud along with capabilities for sophisticated event rules, data processing, and storage. Participants have the opportunity to interact with AWS experts and discuss how to use this framework to solve their business problems.

## AUT306: Creating a data-driven, cloud-native ecosystem at BMW Group 

Data is the lifeblood fueling BMW Group's digital transformation. It drives BMW's personalized customer experiences, connected mobility solutions, and analytical insights. This session starts by outlining different archetypes of data platforms and then walking through the journey of building BMW Group's cloud data hub. Learn about the architectural fundamentals and how to unlock and harness the potential of various data sources, including vehicle sensory and relational data. We also present use cases that help shape the overall strategy and conclude with a combination of lessons learned and design decisions.

## AUT307: Navigating the winding road toward driverless mobility 

Autonomous vehicles (AVs) are becoming a reality, as evidenced by the variety of advanced driver assistance systems (ADAS) and growing number of AV test programs on the road. Mobileye, a global leader in the development of technologies for ADAS and autonomous driving solutions, has been an integral part of this technology revolution. In this session, Mobileye discusses some of its technological innovations and how it leverages AWS to accelerate development across sensing, mapping, and planning. We also discuss the AWS AV reference architecture and key services used to enable ADAS and AV development at the cloud and edge.

## AUT401: Building AR/AI automotive owner applications with AWS 

Augmented reality (AR), AI, and IoT services can be used to jointly create both visual and aural owner applications, such as an interactive owner's manual. This session is dedicated to selecting and applying the appropriate AWS tools and services to build interactive owner applications for increasing after-market sales, personalization/localization of services, next-generation design, advertising, and media distribution. Developers and UX designers learn how to easily create applications that reinvent the way we interact with our vehicles in both the physical and digital worlds. Please bring your laptop.

## AUT402: Creating connected vehicle shadows using AWS IoT 

The connected vehicle market continues to grow at a rapid pace, driven by new business models and innovative customer applications. As vehicles become more connected and the complexity of the features increases, the need for a digital representation of a vehicle grows. In this session, you learn to build a digital twin using HTML/CSS and the AWS IoT Core device shadow in order to allow two-way communication with the vehicle over WebSocket and Alexa, giving you the ability to execute remote commands (e.g., open trunk). Please bring your laptop.

## AUT403: Hands-on with the new AWS connected vehicle solution 

Automotive companies are building next-generation platforms on AWS to take advantage of device management, lifecycle security, advanced analytics, and scalability features. In this hands-on session, we walk through the new features and use cases of the latest version of the AWS connected vehicle solution, including device registration, provisioning, anomaly detection, and trip aggregation. In this session, you deploy the solution using an AWS CloudFormation template, provision devices, and work with data collected from a vehicle simulator, which you install. You should have an understanding of device lifecycle management and connected vehicle solutions, and you should bring your laptop prepared with the AWS CLI.

## AUT404: Deep dive: AWS ML stack for autonomous vehicle model building 

Training and deploying autonomous vehicle algorithms relies heavily on machine learning. In this hands-on session, we show you how to use AWS ML stack and tools such as Amazon SageMaker to quickly build, train, and deploy machine learning models for autonomous driving. Please bring your laptop.


# Blockchain

## BLC201: Building your first blockchain application with Managed Blockchain 

Learn how to set up a blockchain network and deploy your first application using Amazon Managed Blockchain. In this hands-on workshop, we show you how to build a blockchain network for a nonprofit organization to allow it to distribute funds without an intermediary, ensuring immutable transactions and full transparency to donors. Using Hyperledger Fabric on Managed Blockchain, you then create a peer node and connect it to the nonprofit blockchain network. In this example, donors register their profiles, review the causes the nonprofit supports, and donate funds. Using smart contracts, the nonprofit distributes the funds, and the network tracks how each donation is allocated.

## BLC202: Amazon QLDB fundamentals 

In this workshop, learn how to use the features and core functionality of Amazon Quantum Ledger Database (Amazon QLDB), including writing queries to track your data's complete history, cryptographically verifying documents, and designing a data model. You also learn about the new open-source PartiQL and the Amazon Ion format. No prior experience required.

## BLC203: Why you need a ledger database: BMW, DVLA, and Sage discuss their use cases 

Why do you need an immutable ledger database? In this session, we dive into the problems that Amazon Quantum Ledger Database (Amazon QLDB) can solve, and we answer your questions about when and why you would use a ledger database. Customers BMW, the UK government organization Driver and Vehicle Licensing Agency, and Sage share their use cases for maintaining data integrity with Amazon QLDB.

## BLC205: Using Amazon QLDB as a system of record 

Data is a strategic asset for organizations. However, as customer data is increasingly getting dispersed across cloud and enterprise applications, the need for a trusted system of record is becoming paramount. In this chalk talk, we show you how to take advantage of Amazon Quantum Ledger Database (Amazon QLDB) to build system-of-record applications.

## BLC206: Smart supply chain management systems based on blockchain, IoT & AI 

A variety of business use cases based on blockchain are being showcased on top of cryptocurrency. Particularly, blockchain is used for supply chain management (SCM) in Retail, CPG, Manufacturing, and more. Retail food companies run improved SCM based on Amazon Managed Blockchain. In this session, we talk about the background of service adoption from a customer business perspective and its reference architecture, which consists of not only Amazon Managed Blockchain but also other services like AWS Lambda, AWS IoT core, and more. We also discuss the future of SCM, leveraging AI, IoT, and automation-related services.

## BLC207-R1: Trade finance goes high tech using Amazon Managed Blockchain 

Buyers and sellers around the world conduct complex trades with each other using a contract mechanism called letter of credit. This process requires cooperation not just between buyer and seller but also banks and third parties. Learn how Amazon Managed Blockchain allows our customers to focus on improving these complex distributed transactions while spending less time on the complexity of the blockchain network itself.

## BLC301-R1: Dive deep into Managed Blockchain 

Building enterprise blockchain applications on your own infrastructure is often expensive, complicated, and time-consuming. Amazon Managed Blockchain makes it easy to build scalable blockchain applications by eliminating the need to set up and manage infrastructure, allowing you to focus on writing applications for your business. In this technical session, you get an in-depth look at Managed Blockchain's features, APIs, the Hyperledger Fabric SDK, and how to add new members and join fabric channels. We also show how to build an application on Managed Blockchain with the help of demo applications and sample code.

## BLC302: Build an interbank asset-transfer application with blockchain 

Blockchain networks afford us the ability to build decentralized applications that can be cheaper, faster, and more trustworthy than traditional centralized architectures. Amazon Managed Blockchain allows us to deploy managed, scalable Hyperledger Fabric networks that can help foster decentralized applications from experimentation to production. In this workshop, we create our own banks and build a consortium to provide interbank transfers and other services in a decentralized fashion. We explore the concepts behind blockchain and examine the features that you can leverage to build effective decentralized applications.



International

CHN202: AWS China Gateway: Power your business in China by working with AWS   

The AWS China Gateway provides information that helps customers of all sizes get started in using AWS to grow their businesses in China. The AWS China (Beijing) Region and the AWS China (Ningxia) Region are located within mainland China. To provide the best experience for customers in China, as well as to comply with China's legal and regulatory requirements, AWS works with Chinese partners that possess telecom licenses required for delivering cloud services in China. Join this session to learn more about using the AWS China Region.

Compute

CMP202-R1: Better, faster, cheaper compute: Cost-optimizing Amazon EC2   

It's easier than ever to grow your compute capacity and enable new types of cloud computing applications while maintaining the lowest TCO by blending Amazon EC2 Spot, On-Demand, and Reserved Instance purchase models. In this session, learn how to use the power of Amazon EC2 with other AWS services and features such as Auto Scaling, Amazon ECS, Amazon EKS, Amazon EMR, and AWS Batch to programmatically optimize costs while maintaining high performance and availability- all without breaking a sweat.

CMP203: Studio in the cloud: Content production on AWS   

In this session, learn how AWS Thinkbox and our partners are helping studios work with the best talent to scale their VFX and CG pipelines and produce some of the most popular and award-winning content. We cover several in-depth post-production topics around real-world VFX studio pipelines, and we focus on virtual workstations and rendering workloads, combining Amazon EC2 and AWS Thinkbox Deadline for scalable, cost-effective computing. Learn how real customers working on Hollywood productions integrate their pipelines with AWS to realize the elasticity and scale provided by Amazon EC2 and how they intend to leverage AWS in the future.

CMP204-R1: HPC on AWS: Innovating without infrastructure constraints   

High-performance computing (HPC) has always been about solving the most complex problems. But for far too long, HPC applications and workloads have been constrained by infrastructure capacity. In this session, we highlight how virtually unlimited capacity and scale, accessed instantly on the cloud, can create a paradigm shift in the way researchers and engineers approach innovation. Learn how Formula 1 uses AWS to run complex computational fluid dynamics (CFD) simulations as part of its 2021 car design. And hear about the migration of Morgan Stanley's grid computing workloads to AWS.

CMP207-R1: Manage, control, and optimize costs with native AWS products, ft. Intuit 

In this interactive chalk talk, learn about how AWS creates your cost and usage data and dive into how you can use native AWS products to manage your spend. We look at AWS Billing and Cost Management data, AWS Cost Explorer, AWS Cost and Usage reports, and AWS Budgets.

CMP208-S: Achieving unparalleled elasticity on AWS at the lowest cost   

Selecting the optimal cloud resources for your applications can be challenging since there are many ways that your cloud instances can be configured. Cloud engineers and architects are facing this challenge every day, trying to manually find the perfect match and avoid potential operational risks. In this session, join the VP of technical sales at Densify to learn how one line of code (e.g., Terraform) can unlock workload elasticity by precisely and automatically aligning your application demands with the right AWS resources, giving you better performance with reduced operational risk. This presentation is brought to you by Densify, an APN Partner.

CMP210-R1: Dive deep on how to save with AWS Savings Plans   

Savings Plans is a new flexible pricing model that provides savings of up to 72 percent on Amazon EC2 and AWS Fargate usage. Savings Plans offers significant savings over On Demand, just like Reserved Instances, but automatically reduces your bills on compute usage across any AWS Region, even as your usage changes. Savings Plans provides you the flexibility to use the compute option that best suits your needs and continues to save money, all without having to perform exchanges or modifications. Attend this session to learn how you can easily save money on your compute spend. We walk you through a demo of Savings Plans recommendations in AWS Cost Explorer and different considerations for signing up for Savings Plans.

CMP211-R2: Amazon EC2 foundations   

Amazon EC2 provides resizable compute capacity in the cloud and makes web-scale computing easier for customers. It offers a wide variety of compute instances and is well-suited to every imaginable use case, from static websites to supercomputing on-demand, all available via highly flexible pricing options. This session covers the latest EC2 capabilities, including recent instance families available in Amazon EC2, the differences among their hardware types and capabilities, and their optimal use cases.

CMP212-R1: [NEW LAUNCH!] Intro to AWS Wavelength: Run applications with ultra-low latency requirements at the 5G network edge   

In this session, come see how AWS Wavelength brings services such as Amazon EC2 and Amazon ECS to the edge of 5G mobile networks. This enables developers to build applications that reach 5G connected devices with single-digit millisecond latencies using familiar AWS APIs and development processes. This session provides an overview of typical application architectures that benefit from low-latency compute. We also dive deep into how Bethesda Softworks, a video game publisher best known for iconic franchises like The Elder Scrolls, Fallout, and DOOM, is using AWS Wavelength to greatly enhance the experience of streaming video games. You learn how to use AWS in the 5G network edge to build applications that require ultra low-latency such as game streaming, AR/VR, IoT, and analytics.

CMP213-R: [NEW LAUNCH!] Introducing quantum computing with AWS   

Quantum computing has the potential to solve computational problems that are beyond the reach of classical computers. Amazon Braket and the Amazon Quantum Solutions Lab help customers explore quantum computing, evaluate its potential, and develop expertise. Amazon Braket is a managed service that provides customers access to quantum computing resources and makes it easy to build, simulate, and test quantum computing applications. The Quantum Solutions Lab connects customers with quantum experts for education and collaboration. In this session, learn about the potential of quantum computing and how you can get started with the Amazon Braket service and the Quantum Solutions Lab.

CMP214-R1: [NEW LAUNCH!] EC2 Image Builder: Building virtual machine images made easy   

In this session, learn about EC2 Image Builder, a new capability that makes it easier and faster to build and maintain secure images. Keeping server images up-to-date can be time-consuming, resource-intensive, and error-prone. Currently, customers either manually update and snapshot VMs or have teams that build automation scripts to maintain images. Learn how EC2 Image Builder simplifies the creation, patching, testing, distribution, and sharing of Linux or Windows Server images.

CMP302-R1: AWS Outposts: Extend the AWS experience to on-premises environments   

AWS Outposts extends AWS to your on-premises and connected edge environments to support applications with latency and local data processing requirements. Attend this session to learn more about how it works and about key customer use cases.

CMP302-R2: AWS Outposts: Extend the AWS experience to on-premises environments 

AWS Outposts extends AWS to your on-premises and connected edge environments to support applications with latency and local data processing requirements. Attend this session to learn more about how it works and about key customer use cases.

CMP303-R2: Powering next-gen Amazon EC2: Deep dive into the Nitro system   

The Nitro system is a rich collection of building block technologies that include AWS-built hardware offload and security components; it is powering the next generation of Amazon EC2 instances with an ever-broadening selection of compute, storage, memory, and networking options. In this session, we deep-dive into the Nitro system, explore its design and architecture, discover how it enables innovative new EC2 instances, and see how it has made the seemingly impossible possible.

CMP304-R1: AWS infrastructure for large-scale distributed training at Facebook AI   

In this session, the Facebook AI team discusses its major machine learning models and workloads and the infrastructure challenges it faced with large-scale distributed training. They share details of how they tested these ML workloads on AWS infrastructure and the results of this benchmarking. Then we discuss how the deep breadth of AWS infrastructure for ML workloads in compute, networking, and storage helps address large-scale ML challenges. Specifically, we dive deep into the AWS machine learning stack to choose the right Amazon EC2 platform to fit your ML workload while leveraging 100 Gbps networking and high-performance file systems to efficiently scale from a single GPU to hundreds or thousands.

CMP306: Getting started with Arm-based Amazon EC2 instances 

Amazon EC2 A1 instances are the first EC2 instances powered by Arm-based AWS Graviton processors. They deliver significant cost savings for scale-out and Arm-based applications, such as web servers and containerized microservices. In this chalk talk, you learn about EC2 A1 instances, hear customer success stories, and experience how easy it can be to run your workloads on Arm-based EC2 instances and lower your costs.

CMP307-R2: Optimize ML training and inferencing using Amazon EC2 

In this workshop, you gain hands-on experience with Amazon EC2 instances that offer the highest-performing GPU-based instances in the cloud for efficient model training and cost-effective inference. This workshop walks you through the entire machine learning application development life cycle and focuses specifically on how to optimize training and inference by leveraging the power of EC2.

CMP309-R2: Easily deploy and scale a cloud app with Amazon Lightsail 

In this workshop, we start by deploying a monolithic web app into an Amazon Lightsail instance. From there, we separate out the components and use technologies like load balancers and snapshots to show you how to deploy your application at scale. By the end of this session, you'll understand: the benefits of Lightsail; when to choose Lightsail or Amazon EC2; best practices for deploying your application onto Lightsail's preconfigured blueprints; how to use an OS-only blueprint to deploy virtually any software package; and how to leverage snapshots and load balancers to scale applications.

CMP311-R1: How NextRoll leverages AWS Batch for daily business operations 

The Digital Marketing industry generates petabytes of event data per day. In this session, learn how NextRoll, a marketing technology provider and platform, uses AWS Batch to process these petabytes of data in a stable and efficient way. We review how NextRoll manages its compute environment provisioning, job scheduling, and jobs management, and how it performs data-transformation and business analytics calculations in the batch environment.

CMP312-R2: Optimizing Amazon EBS for performance 

Key techniques and practices while using Amazon EBS can help push performance and optimize spend. In this session, learn how to optimize storage performance and costs for Amazon EBS using tools such as Amazon CloudWatch and AWS Trusted Advisor, and third-party tools such as Cloudability.

CMP313-R1: Save by using multiple purchase options with Amazon EC2 Auto Scaling 

Amazon EC2 Auto Scaling makes it easy to mix multiple purchase options and instance types in the same Auto Scaling group. Now, with the introduction of instance type weights, you can configure your group to make scaling decisions based on the number of cores, amount of memory, or whatever instance type specifications your service uses, giving you more flexibility to use a wider range of instance types. In this chalk talk, we show you how to set up these Auto Scaling groups and discuss the different combinations that you can configure that best suit your use case for lowering cost and improving availability.

CMP314: Accelerate applications using Amazon EC2 F1 FPGA instances 

Amazon EC2 F1 instances with field programmable gate arrays (FPGAs), combined with optimized cloud-based FPGA programming tools, provide researchers, application developers, and startups with a well-tested, standardized, and accessible platform for custom hardware-accelerated computing. In this session, we update you on the latest EC2 F1 features, and guest speakers from Valtix dive deep on how they are using F1 instances to accelerate native network security in the cloud.

CMP315-R1: Multi-node deep learning training in the cloud 

The key barriers to the wider adoption of deep neural networks on industrial-sized datasets are the time and resources required to train them. Data scientists and machine learning engineers continue to demand shorter training times, as this provides them with increased agility to try new algorithms and optimization techniques. In this chalk talk, we show how to optimize AWS infrastructure to minimize deep learning training times by using distributed/multi-node training using Amazon EC2 P3dn instances.

CMP316: How GE Aviation accelerates CFD simulations on AWS 

General Electric is one of the world's largest manufacturing companies, and GE Avio is among the top aircraft engine suppliers, offering engines for the majority of commercial aircraft. Aircraft engine engineers need to run hundreds of computational fluid dynamics (CFD) simulations in order to optimize the turbine air flow. By moving these simulations to AWS, the customer has been able to run them four times faster and drastically reduce the time-to-market.

CMP317-R2: Building a static site on Amazon Lightsail 

In the earliest days of the web, almost all sites were static. But as time progressed, content management systems such as WordPress and Drupal gained popularity. Today static sites are becoming increasingly popular again. Based on the latest web technologies, static sites offer increased speed and security while being incredibly easy to deploy. In this chalk talk, we walk through how you can architect and deploy static websites-from a simple"brochure" site to more complex progressive web apps. You come away with a better idea of both when to choose a static website and how to easily deploy it using Amazon Lightsail.

CMP318-R1: Kubernetes on Spot Instances: Optimize for scale and cost 

> Containers are usually stateless and fault-tolerant, and Amazon EC2 Spot Instances are a great match for powering container workloads. Attend this workshop to learn how to provision, manage, and maintain your Amazon Kubernetes clusters with Amazon EKS at any scale on Spot Instances while architecting to optimize cost and scale. We dive deep using hands-on material to provision and scale worker nodes, handle interruptions, and design for fault tolerance. We also demonstrate successfully managing a suddenly spiky workload. This workshop is designed to help architects, engineers, and developers understand how to run a containerized environment on Spot Instances.

CMP319-R1: Deploy graphics desktops for content production on AWS 

> Cloud-based GPU desktops enable companies to hire the best talent regardless of location or time zone. In this hands-on session, you explore the technical schema and underlying architecture of several solutions, including Amazon AppStream and managed Amazon WorkSpaces, and then individually build a working Windows and Linux graphics desktop based on the new Amazon EC2 G4 GPU instance type using Teradici Cloud Access Software.

CMP322-R1: Deep dive on Arm-based EC2 instances powered by AWS Graviton   

AWS Graviton processors feature 64-bit Arm Neoverse cores and custom silicon designed by AWS, delivering optimized performance and cost. AWS Graviton processors are built exclusively for the cloud, utilizing AWS and Annapurna Labs' expertise in running hyperscale cloud platforms and cloud applications. Amazon EC2 A1 instances are the first instances powered by the AWS Graviton processor. In this session, learn how you can optimize cost and performance for your scale-out and Arm-based workloads using EC2 instances based on AWS Graviton processors. We present use cases, software ecosystem, and customer adoption stories for EC2 A1 instances.

CMP324-R1: Deliver high performance ML inference with AWS Inferentia   

Customers across diverse industries are defining entirely new categories of products and experiences by running intelligent applications that use ML at the core. These applications are becoming more expensive to run in production. AWS Inferentia is a custom-built machine learning inference chip designed to provide high throughput, low latency inference performance at an extremely low cost. Each chip provides hundreds of TOPS of inference throughput to allow complex models to make fast predictions. Join this session to see the latest developments using AWS Inferentia and how they can lower your inference costs in the future.

CMP325-R1: Using Amazon EBS to build highly resilient applications 

Storage architecture is a central consideration for building highly available and fault-tolerant applications in the cloud. Proper configuration of Amazon EBS deployment enables organizations to achieve the high resiliency they need for their mission-critical applications that use block storage. In this chalk talk, we share example design patterns and key techniques for building application resiliency, such as asynchronous volume replication across availability zones and the use of CloudEndure for disaster recovery.

## CMP326-R1: Capacity management made easy with Amazon EC2 Auto Scaling   

> Amazon EC2 Auto Scaling offers a hands-free capacity management experience to help customers maintain a healthy fleet, improve application availability, and reduce costs. In this session, we deep-dive into how Amazon EC2 Auto Scaling works to simplify continuous fleet management and automatic scaling with changing load. Netflix delivers shows like Sacred Games, Stranger Things, Money Heist, and many more to more than 150 million subscribers across 190+ countries around the world. Netflix shares how Amazon EC2 Auto Scaling allows its infrastructure to automatically adapt to changing traffic patterns in order to keep its audience entertained and its costs on target.

## CMP327: Scale your SAP HANA workloads on EC2 High Memory instances 

> AWS provides a suite of SAP-certified Amazon EC2 instances for SAP HANA workloads with memory footprints ranging from 244GB to 24TB. EC2 High Memory instances are purpose-built to run large in-memory databases, including production deployments of the SAP HANA in-memory database, in the cloud. Join this session for a detailed look into EC2 High Memory instances, and learn how you can use these EC2 instances in your Amazon VPC together with Amazon EBS to run mission-critical SAP HANA workloads and realize greater speed and agility.

CMP328-R1: How Uber builds efficient & scalable autonomous vehicle simulations with AWS Batch   

> Learn how Uber uses AWS Batch to run hundreds of thousands of autonomous vehicle simulations across as many vCPUs every day. Hear the story of how the company built a highly performant and scalable simulation pipeline on native AWS services.

## CMP329-R: Build cost-effective web & containerized apps on EC2 Arm instances 

> In this chalk talk, learn how easy it can be to build and run various open-source applications on Amazon EC2 A1 Arm-based instances while lowering your costs. We discuss the software building blocks and toolchain support, as well as walk through example web, containerized application, and reference architectures that you can build on the Arm platform.Bruce Sun, a senior cloud solutions architect at NetEase Games, shares how the company uses EC2 A1 instances for its large-scale online gaming platform to achieve significant cost savings.

## CMP329-R1: Build cost-effective web & containerized apps on EC2 Arm instances 

> In this chalk talk, learn how easy it can be to build and run various open-source applications on Amazon EC2 A1 Arm-based instances while lowering your costs. We discuss the software building blocks and toolchain support, as well as walk through example web, containerized application, and reference architectures that you can build on the Arm platform.

## CMP330-R1: How AWS Outposts helps APN Partners build on-premises customer solutions 

> AWS Outposts brings AWS infrastructure, services, and operating models to virtually any customer data center or on-premises facility. Customers looking to leverage Outposts for their on-premises use cases can leverage our AWS Partner Network (APN) to build a broad range of solutions just like in the cloud. In this session, customers learn about Outposts and how to access the wide range of APN Partners and ISV solutions available to support their low-latency and local data processing workloads. APN Partners learn about the tool kits available to them to deliver a successful Outposts journey to their customers.

## CMP332: Simplifying Microsoft architectures with AWS services   

> In this session, learn how to architect Microsoft solutions on AWS to be both highly available and scalable. Find out how Microsoft solutions can leverage AWS services to achieve more resiliency, replace unnecessary complexity, and provide scalability. We explore hybrid architecture scenarios and common architecture patterns for Active Directory and productivity solutions like SharePoint. We also cover common design patterns for .NET applications, including approaches to CI/CD, DevOps, and containerizing .NET applications.

## CMP333: Amazon Linux 2: Stability, security, and high performance 

> In this session, learn about Amazon Linux 2, the latest Amazon Linux operating system that comes with five years of support. See what's new with Amazon Linux 2, learn how it's different from other distributions of Linux, and understand why it's rapidly becoming the go-to operating system for AWS customers.

## CMP334-R2: Deep-dive into 100G networking & Elastic Fabric Adapter on Amazon EC2 

> In this chalk talk, we discuss the various hardware and software Nitro components that are powering the 100Gbps network performance and Elastic Fabric Adapter (EFA) on next-generation Amazon EC2 instances. Come to learn the benefits and uses cases, and discuss case studies of Amazon EC2 customers leveraging high network performance on these EC2 instances for high-performance computing, machine learning, database, and big data workloads.

## CMP335: Streamlining Amazon EC2 instance provisioning and management 

> Provisioning and managing instances is fundamental to creating a secure, scalable environment for your application. This session guides you through recommended practices for selecting instance types, provisioning resources, connecting to instances, building automation and governance, and monitoring and optimizing instance usage for your workloads. Learn how to move seamlessly from a proof of concept to an automated production environment using launch templates and newly launched features. We also cover some best practices and share tips on how you can simplify your instance launch experience.

## CMP336-R1: Save on big data workloads like Apache Spark and Hadoop 

> Learn how you can save on big data workloads by running Spot Instances on Amazon EMR. Access significantly higher compute capacity and reduce the time to process big datasets at a fraction of the cost. With Amazon EMR you can optimize for the right instance mix across Spot and On-Demand and simplify the setup process. Finally, learn how to increase cluster resilience by configuring transient and long-running clusters for the right mix of On-Demand and Spot Instances.

## CMP337-R1: AWS Outposts: Build for low latency and local data processing 

> Some applications need to run on premises due to low latency or because of local data processing needs. In this session, learn how AWS Outposts extends AWS services to customer sites for a consistent AWS experience on premises. We share customer examples of how AWS Outposts enhances performance, reliability, and responsiveness for applications that remain on premises.

## CMP339-R1: Running high-throughput Oracle databases on Amazon EC2 

> This session is for organizations migrating high-transactional throughput and low-latency applications backed by Oracle databases to AWS. We present a design for deploying Oracle databases on EC2 I3 instances that meet high availability and durability requirements. We also discuss failure modes and ways to tune that design. Further, we present results of performance tests. Come learn how to set up Oracle on Amazon EC2 and get performance results that you can use to design your own solution.

## CMP343-S: Turbocharge your data center infrastructure with AMD   

> With the ever-increasing need for efficiency and better price performance, a balanced data center infrastructure is a crucial component of today's cloud solutions. Organizations seeking to maximize the value of their cloud and on-premises infrastructures now have a choice when selecting their compute and GPU platforms. In this session, a representative from AMD discusses how AMD EPYC processors and AMD GPUs can help you optimize your workload performance and security while providing significant cost savings. This presentation is brought to you by AMD, an APN Partner.

## CMP344-R3: Move your first application to the cloud with Amazon Lightsail 

> Come spend time with the Amazon Lightsail team, and move one of your applications to the cloud. This session is specifically designed for people who are wondering how to get started with AWS. We sit down with you and help you deploy a workload into AWS using Lightsail. Bring your own workload or use one of our demo examples, and get started today. Please bring your laptop.

## CMP345-R2: Getting started with containers on Amazon Lightsail 

> Have you heard about containers and services like Amazon Elastic Kubernetes Service (Amazon EKS), AWS Fargate, and Amazon Elastic Container Service (Amazon ECS), but you're unsure where to get started? In this builders session, we show you the basics and help you understand the underlying technology so you can start planning your container journey. Learn what containers are, how to build them from scratch, how to store them in Amazon Elastic Container Registry (Amazon ECR), and what your options are for deploying containerized applications into production. Please bring your laptop.

## CMP346-R3: Deploy & scale a multi-tier application in Amazon Lightsail 

> In this session, we show you how to scale an existing cloud workload. We look at using snapshots to replicate a web tier application and at how to use load balancers to provide both scalability and fault tolerance. You can bring your own workload or work through one of our provided examples. Please bring your laptop.

## CMP347-R2: Deploy a highly scalable WordPress site on Lightsail in less than an hour 

> In this builders session, we deploy a highly available WordPress site using Amazon Lightsail and Amazon Simple Storage Service (Amazon S3). Learn how to create the WordPress front end, scale that behind a load balancer, connect to a standalone database instance, and use Amazon S3 to offload your media assets. The end result will be a fault-tolerant, scalable WordPress site, all deployed in less than one hour. Please bring your laptop.

## CMP348-R2: Building a pocket platform as a service with Amazon Lightsail 

> With Amazon Lightsail, it's easier than ever to build your own pocket platform as a service for maximum control and flexibility for small projects. In this chalk talk, we show you how to turn a Lightsail instance into a docker host with subdomain routing, SSL termination, CI/CD pipeline, and more.

## CMP401-R1: Running EC2 workloads at scale 

> Join this workshop to get hands-on with the latest Amazon EC2 features, including Amazon EC2 Auto Scaling groups and Amazon EC2 launch templates, and AWS CodeDeploy. Learn how to utilize EC2 launch templates to power and deploy an EC2 Auto Scaling group using a combination of EC2 On-Demand and EC2 Spot Instances behind a load balancer. Next, configure the workload to handle peak demand with automatic scaling policies-while optimizing cost and performance.

## CMP401-R2: Running EC2 workloads at scale 

> Join this workshop to get hands-on with the latest Amazon EC2 features, including Amazon EC2 Auto Scaling groups and Amazon EC2 launch templates, and AWS CodeDeploy. Learn how to utilize EC2 launch templates to power and deploy an EC2 Auto Scaling group using a combination of EC2 On-Demand and EC2 Spot Instances behind a load balancer. Next, configure the workload to handle peak demand with automatic scaling policies-while optimizing cost and performance.

## CMP402-R1: Setting up and optimizing your HPC cluster on AWS 

> It's not hard to build your first HPC cluster on AWS. In this workshop, we take you through the basics in a step-by-step approach that you can easily follow along with. We cover everything from installation of the AWS ParallelCluster software suite to instance selection, Amazon EC2 Spot Instance enablement, and launching your first MPI"hello world" job from the command line.

## CMP404-R2: Running Big Data clusters on Amazon EMR with Spot Instances 

> Join this builders session to learn how to run Big Data frameworks such as Apache Spark, Hadoop, and Hive through Amazon EMR while maximizing for scale, performance, and deep cost savings with Spot Instances. Learn how to configure clusters and instance fleets for the right mix of On-Demand and Spot Instances for long-running and transient workloads. Please bring your laptop.

## CMP405-R1: Optimize SAP HANA workloads with EC2 High Memory instances 

> Running SAP HANA workloads on AWS requires special considerations to meet SAP's KPI and get best performance for your mission critical SAP applications. In this builder session, an AWS expert will guide you on the best practices of configuring your Amazon EC2 instances including EC2 High Memory instance type and Amazon EBS to ensure that your SAP HANA environment is production ready from the get go. During this session, you can build your own production ready Amazon EC2 instance for your SAP HANA workloads. AWS provides suite of Amazon EC2 instances that are certified by SAP for running Business Suite on HANA (SoH), the next-generation Business Suite S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA (BW), and SAP BW/4HANA in production environments. Please bring your laptop.

## CMP408-R2: Using Elastic Fabric Adapter to scale HPC workloads on AWS 

> In this builders session, we guide you through the process of using Elastic Fabric Adapter (EFA) to scale up your MPI-based HPC application on AWS. An AWS HPC expert answers your questions about benchmarking the performance of your HPC applications with EFA. Please bring your laptop.

## CMP412: Orchestrating complex genomics pipelines with AWS Batch 

> Learn how to simplify the process of orchestrating complex genomics pipelines using Nextflow-a popular open source data-driven computational pipeline tool that enables scalable and reproducible scientific workflows-and AWS Batch, a fully managed batch processing service that enables scientists and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. In this workshop, we walk through a genomics workflow integrating Nextflow with AWS Batch and experience firsthand how AWS Batch can dynamically expand or contract cloud resources to meet the needs of the genomics pipeline.

## CMP416-R2: Scale Kubernetes for less using Spot Instances 

> In this builders session on containers, we cover how to optimize your Kubernetes clusters with Amazon Elastic Kubernetes Service (Amazon EKS) using a mixed worker node group of Amazon EC2 On-Demand and Spot Instances. We cover concepts of provisioning instances, scaling, and handling interruptions. This session provides a hands-on guide for developers and operations managers to explore. Please bring your laptop.

## CMP420-R2: Amazon EBS: Security best practices 

> With increasing data regulation across industries, AWS customers running mission-critical workloads on Amazon EC2 need simple, cost-effective ways to secure data, control storage access, and maintain uptime while meeting compliance goals. In this hands-on session, we walk you through security capabilities of Amazon EBS and cover best practices for techniques such as encrypting your EBS resources, setting up resource-level permissions, and sharing resources within your environment. Please bring your laptop.

## CMP422-R2: Leveraging native AWS Cost Management suite to optimize costs 

> In this builders session, we dive deeper into AWS Cost Management resources and features such as Reserved Instance (RI) performance reporting, resource optimization recommendations, RI recommendations, and other features to help optimize your resources and costs through the native AWS Cost Management suite. Please bring your laptop.

## CMP423-R1: [NEW LAUNCH!] Hands-on deep learning inference with Amazon EC2 Inf1 instances 

> In this workshop, you gain hands-on experience with Amazon EC2 Inf1 instances, powered by custom AWS Inferentia chips. Amazon EC2 Inf1 instances offer low-latency, high-throughput, and cost-effective machine learning inference in the cloud. This workshop walks you through taking a trained deep learning model to deployment on Amazon EC2 Inf1 instances by using AWS Neuron, an SDK for optimizing inference using AWS Inferentia processors.
