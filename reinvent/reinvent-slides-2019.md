## Table of Contents
- [Artificial Intelligence & Machine Learning](#artificial-intelligence--machine-learning)
- [Analytics](#analytics)
- [Application Integration](#application-integration)

# Artificial Intelligence & Machine Learning

## [AIM201-S: Hot paths to anomaly detection with TIBCO data science, streaming on AWS](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Hot_paths_to_anomaly_detection_with_TIBCO_data_science%2C_streaming_on_AWS_AIM201-S.pdf)   

> Sensor data on the event stream can be voluminous. In NAND manufacturing, there are millions of columns of data that represent many measured and virtual metrics. These sensor data can arrive with considerable velocity. In this session, learn about developing cross-sectional and longitudinal analyses for anomaly detection and yield optimization using deep learning methods, as well as super-fast subsequence signature search on accumulated time-series data and methods for handling very wide data in Apache Spark on Amazon EMR. The trained models are developed in TIBCO Data Science and Amazon SageMaker and applied to event streams using services such as Amazon Kinesis to identify hot paths to anomaly detection. This presentation is brought to you by TIBCO Software, an APN Partner.

-  [Slides](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Hot_paths_to_anomaly_detection_with_TIBCO_data_science%2C_streaming_on_AWS_AIM201-S.pdf) , [Videos](https://www.youtube.com/watch?v=ZTI76iJCRjc)

## [AIM202-S: Artificial intelligence in Healthcare](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Artificial_intelligence_in_Healthcare_AIM202-S.pdf)

> SENTRI is an intelligent automation application platform built leveraging native AWS components to facilitate case processing in the Healthcare industry. PwC built an engine that can take in an adverse healthcare/level of service (HC/LS) event case, extract key information, provide an initial interpretation of severity, and triage the case for review. PwC performed analysis using a user-centric experience, which allowed the case processor to easily verify outputs and helped build trust and confidence in the machine's interpretation. In this session, learn how a PwC customer has been successfully using this system for over nine months. It used to take two hours to process a case. Now, it takes three seconds. This presentation is brought to you by PwC, an APN Partner.

-  [Slides](https://github.com/exajobs/aws-events-collection/blob/main/reinvent/reinvent-contents-2019/Artificial_intelligence_in_Healthcare_AIM202-S.pdf)

## AIM203-SR1: Take AI/ML from theory to practice with Intel technologies on AWS 

> The challenges associated with scalability have been removed in the cloud. Today, organizations deploy tons of artificial intelligence/machine learning (AI/ML) workloads on AWS. Learn about how easy and cost-effective it is to build customized, intelligent data models leveraging the full power of Intel Xeon Scalable processors. Additionally, learn how Footasylum, a leading UK leisurewear retailer, is globally optimizing its value chain. By utilizing the Peak AI ML solution powered by Intel on AWS, Footasylum is leveraging ML for long-term success in the modern retail climate. This presentation is brought to you by Intel, an APN Partner.

## AIM204-S: Discovering the value of a cloud data platform   

In this session, Discover Financial Services and Accenture discuss their work with moving Discover from an on-premises data infrastructure to the AWS Cloud, which offers advanced analytics. With an intelligent data strategy and fully optimized AWS Cloud data solution, Discover is transforming the customer experience and increasing shareholder value. Today, the bank leverages data from many sources-structured and unstructured, streaming and batch-and analyzes the data for insights. This strategy required a bold pivot from a legacy, on-premises architecture to a fully integrated data platform on the cloud. Learn how Discover is also successfully navigating the cultural changes of this type of transformation. This presentation is brought to you by Accenture, an APN Partner.

## AIM205-R1: Starting the enterprise ML journey, featuring ProSiebenSat.1 Media SE   

Amazon has been investing in machine learning for more than 20 years, innovating in areas such as fulfillment and logistics, personalization and recommendations, forecasting, fraud prevention, and supply chain optimization. During this session, we take this expertise and show you how to identify business problems that can be solved with machine learning. We discuss considerations including selecting the right use case for a machine learning pilot, nurturing skills, and measuring the success of such pilots. We dive into success stories from the Amazon ML Solutions Lab, and you can hear from ProSiebenSat.1 Media SE about how it moved from idea to production with machine learning.

## AIM207-R9: Get started with AWS DeepRacer 

Get behind the keyboard for an immersive experience with AWS DeepRacer. Developers with no prior machine learning experience learn new skills and apply their knowledge in a fun and exciting way. With the help of the AWS pit crew, build and train a reinforcement learning model that you can race on the tracks in the MGM Grand Garden Arena and win special AWS prizes!

## AIM208-R1: Transform the way you search and interact with enterprise data using AI   

How can you get the most intuitive and specific answer to a search query when the answer may be hidden within various enterprise filing or information systems? This session teaches you how to use natural language processing, a machine learning technique, to build an enterprise search solution that will give you straightforward answers to questions like,"How much is the cash reward on the corporate credit card?" Learn how this can improve cross-team knowledge sharing, enhance sales and customer support services, and make it much easier for end customers to find the information they need.

## AIM211-R1: AI document processing for business automation 

Millions of times per day, customers from the Finance, Healthcare, public, and other sectors rely on information that is locked in documents. Amazon Textract uses artificial intelligence to 'read' such documents as a person would, to extract not only text but also tables, forms, and other structured data without configuration, training, or custom code. In this session, we demonstrate how you can use Amazon Textract to automate business processes with AI. You also hear directly from our customers about how they accelerated their own business processes with Amazon Textract.

## AIM214-R1: [NEW LAUNCH!] Introducing Amazon SageMaker Studio, the first full IDE for ML   

Machine learning (ML) is a complex, iterative, often time-consuming process. One difficult aspect is the lack of integration between the workflow steps and the tools to accomplish them. Join us as we introduce Amazon SageMaker Studio, the first full integrated development environment (IDE) for ML that makes it easy to build, train, tune, debug, deploy, and monitor ML models at scale. It pulls together the ML workflow steps in a unified, visual interface-since they're performed and tracked within one environment, the non-linear and iterative nature of ML development is greatly simplified. You can quickly move between steps, compare results and adjust inputs and parameters, and iterate faster with Amazon SageMaker Studio.

## AIM215: [NEW LAUNCH!] Intro to Amazon SageMaker Autopilot: Auto-generate ML models 

Typical approaches to automatic ML don't provide insights into the data or logic used to create models, forcing you to compromise on accuracy. Join us as we introduce Amazon SageMaker Autopilot, an automated capability that generates ML models and provides complete control and visibility of them. Learn how Autopilot automatically inspects raw data, picks the best set of algorithms, trains multiple models, tunes them, and ranks them based on performance. The result is a recommendation for the best performing model and visibility into the logic and code for how the model was created and what's in it. Autopilot offers the best combination of automatic model creation with control and visibility.

## AIM216-R1: [NEW LAUNCH!] Intro to Amazon SageMaker Debugger: Get insights into ML model training 

During ML model training, it's challenging to ensure that models are progressively learning the correct values for different parameters and to analyze and debug model characteristics without building additional tools, making the process time-consuming and cumbersome. Come learn about Amazon SageMaker Debugger, a new capability that provides complete insights into the training process by automating data capture and analysis from training runs without code changes. Learn how you can analyze data using the Amazon SageMaker Studio visual interface and be alerted when anomalies and errors are detected, reducing the time needed to debug models from days to minutes. Amazon SageMaker Debugger helps you solve problems quickly, reduce troubleshooting time during training, and build high-quality models.

## AIM220-S: Farmers Insurance elevating customer experience with conversational AI 

As part of its digital transformation journey, Farmers, one of America's largest insurers, envisioned digitizing its customer and agent service experience. Join Farmers for this insightful session, and learn how it leveraged conversational artificial intelligence (AI), chatbots, and other next-generation AWS technologies to offer a seamless, personalized, and contextualized experience for agents and customers. Learn how Farmers improved customer experience and optimized resources while encouraging self-service with cloud-based services, automation, and AI. Also, gain insights on how to design, architect, and build a scalable conversational AI solution that caters to growing business demands. This presentation is brought to you by Cognizant, an APN Partner.

## AIM222-R1: Monetizing text-to-speech AI 

In this interactive session, we look at different options to monetize text-to-voice applications. We focus on Amazon Polly, a machine learning-powered service that produces lifelike speech. You learn to monetize this capability and generate a positive ROI when creating Amazon Polly applications. This chalk talk covers both business and technical considerations.

## AIM223-R12: [NEW LAUNCH!] AWS DeepComposer: Get started with generative AI 

Generative AI is one of the most fascinating advancements in artificial intelligence technology, and until now, developers interested in growing skills in this area haven't had an easy way to get started. In this workshop, you learn about generative AI and get hands-on with AWS DeepComposer, the world's first machine learning-enabled musical keyboard for developers, to create an original composition. You are also introduced to concepts that you can use in Amazon SageMaker to do even more with generative AI. Developers, make some noise!

## AIM224-R1: Use pretrained models and algorithms in AWS Marketplace 

You can cut down on development time for machine learning projects with third-party algorithms and models in a secure environment using Amazon SageMaker. Learn how in this chalk talk, as we walk through the subscription, evaluation, and deployment process for algorithms as well as pretrained models from AWS Marketplace.

## AIM225: How to build a car that does an 8.64-second lap with AWS DeepRacer 

Deep dive on AWS DeepRacer! In this chalk talk, learn how to build a race-winning model from a 2019 AWS Summit Circuit race winner and get tips on how you can excel in the AWS DeepRacer league in 2020.

## AIM226: How to successfully become a machine learning developer 

In this chalk talk, learn how to get started building, training, and deploying your first machine learning model. We then discuss tips, tricks, and best practices on starting your machine learning journey.

## AIM227-S: Powering global-scale predictive intelligence using HPC on AWS 

Learn how Maxar and Descartes Labs run complex, global-scale models on Amazon EC2 instances powered by Intel Xeon Scalable processors. Maxar discusses its experience setting up an operational HPC cluster to run global numerical weather prediction models, obtaining performance that eclipses the speed of the NOAA bare-metal supercomputer. Descartes Labs shows how its platform enables hyper-scale object detection on satellite imagery accelerated by Intel AVX-512 instructions. It also shares its experience deploying tightly coupled HPC applications that use spot blocks at many-thousand processor scale, using HPC clusters built on AWS instances and powered by Intel Xeon Scalable processors. This presentation is brought to you by Intel, an APN Partner.

## AIM229: Start using computer vision with AWS DeepLens 

If you're new to deep learning, this workshop is for you. Learn how to build and deploy computer-vision models using the AWS DeepLens deep-learning-enabled video camera. Also learn how to build a machine learning application and a model from scratch using Amazon SageMaker. Finally, learn to extend that model to Amazon SageMaker to build an end-to-end AI application.

## AIM230-R1: [NEW LAUNCH!] New Amazon SageMaker notebook experience: Share & collaborate at scale   

Typically, starting notebooks requires spinning up compute instances, and there was previously no easy way to share and collaborate without tracking dependencies and other restrictions. Join us as we introduce the new Amazon SageMaker notebooks experience, which allows you to access notebooks in seconds without spinning up compute instances. The elastic notebooks allow you to easily scale compute up or down, and the changes take place automatically without interrupting your work. You can share notebooks by automatically reproducing the environment and library dependencies without manually tracking them so others can reproduce the results with the same data. With this new experience, you can build models faster and collaborate at scale.

## AIM231-S: Think Forward Initiative: 100M people making better financial decisions 

Want to learn more about using technology to impact society? Join this session! Currently, 42 percent of Europeans face financial difficulties. As lead partners of the Think Forward Initiative (TFI), Deloitte, AWS, and ING aim to empower 100 million Europeans to make better financial decisions by translating the latest consumer behavior insights into easy applicable tools. In this session, you learn how TFI supports early stage scale-ups by using Amazon S3, Amazon API Gateway, AWS Lambda, Amazon Aurora, AWS CloudFormation, AWS Cloud9, Amazon Textract, and Amazon Personalize in an accelerator program. You also learn about the AWS Well-Architected Review and AWS Activate programs. This presentation is brought to you by Deloitte, an APN Partner.

## AIM232: Media discovery and compliance with Amazon Rekognition   

Searching through hundreds of hours of media assets and reviewing them for compliance daily is a tedious manual task in most media workflows today. Amazon Rekognition is a service that helps you add intelligent video and image analysis to your applications. In this session, learn how Amazon Rekognition and AWS media solutions can help you generate and manage rich video metadata for people, objects, and scenes, as well as detect any inappropriate content. Hear from our customers about how they achieved time and cost savings by using Amazon Rekognition and other AWS services.

## AIM301-R1: Creating high-quality training datasets with data labeling 

Amazon SageMaker Ground Truth makes it easy to quickly label high-quality, accurate training datasets. In this workshop, we set up labeling jobs for text and images to help you understand how to make the most of Amazon SageMaker Ground Truth. You learn how to explore and prepare the dataset and label it with object bounding boxes. Then, we use Amazon SageMaker to train a Single Shot MultiBox Detector (SSD) object-detection model based on the labeled dataset, use hyperparameter optimization to find the best model for deployment, and deploy the model to an endpoint for use in an application.

## AIM302-R1: Create a Q&A bot with Amazon Lex and Amazon Alexa 

A recent poll showed that 44 percent of customers would rather talk to a chatbot than to a human for customer support. In this workshop, we show you how to deploy a question-and-answer bot using two open-source projects: QnABot and Lex-Web-UI. You get started quickly using Amazon Lex, Amazon Alexa, and Amazon Elasticsearch Service (Amazon ES) to provide a conversational chatbot interface. You enhance this solution using AWS Lambda and integrate it with Amazon Connect.

## AIM303-R1: Stop guessing: Use AI to understand customer conversations 

You don't need to be a data scientist to build an AI application. In this workshop, we show you how to use AWS AI services to build a serverless application that you can use to understand your customer interactions. Analyze call-center recordings with the help of automatic speech recognition, translation, and natural language processing (NLP). Get hands-on by producing your own call recordings using Amazon Connect. In the last step of this workshop, set up a processing pipeline to automate transcription and NLP analysis, and run analytics and visualizations on the results.

## AIM304-R1: Build a content-recommendation engine with Amazon Personalize 

Machine learning is being used increasingly to improve customer engagement by powering personalized product and content recommendations. Amazon Personalize lets you easily build sophisticated personalization capabilities into your applications, using machine learning technology perfected from years of use on Amazon.com. In this workshop, you build your own recommendation engine by providing training data, building a model based on the algorithm of your choice, testing the model by deploying your Amazon Personalize campaign, and integrating it into your own application.

## AIM305-R1: Automate content moderation and compliance with AI 

Brand safety is a major concern as advertising becomes more automated. Issues with ad adjacency arise, contracts with brands or celebrities run out, and user-generated content can be difficult to manage. In this workshop, you learn how to use Amazon Rekognition, Amazon Textract, and Amazon Comprehend to detect inappropriate content or noncompliant use of content such as logos or celebrity faces. You leave with a scalable architecture that will save days of manual review in media moderation and compliance workflows.

## AIM306-R: How to build high-performance ML solutions at low cost, featuring Aramex   

Amazon SageMaker helps provide the best model performance for less cost. In this session, we walk through a TCO analysis of Amazon SageMaker, exploring its three modules-build, train, and deploy. Learn how Amazon SageMaker automatically configures and optimizes ML frameworks such as TensorFlow, MXNet, and PyTorch, and see how to use pre-built algorithms that are tuned for scale, speed, and accuracy. We explain how the automatic model tuning feature performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. Learn how to deploy your model with one click and how to lower inference costs using Amazon Elastic Inference. We end by showing how Aramex uses Amazon SageMaker.

## AIM306-R1: How to build high-performance ML solutions at low cost, featuring Siemens 

Amazon SageMaker helps provide the best model performance for less cost. In this session, we walk through a TCO analysis of Amazon SageMaker, exploring its three modules-build, train, and deploy. Learn how Amazon SageMaker automatically configures and optimizes ML frameworks such as TensorFlow, MXNet, and PyTorch, and see how to use pre-built algorithms that are tuned for scale, speed, and accuracy. We explain how the automatic model tuning feature performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. Learn how to deploy your model with one click and how to lower inference costs using Amazon Elastic Inference. We end by showing how Siemens uses Amazon SageMaker to manage costs.

## AIM307: Amazon SageMaker deep dive: A modular solution for machine learning   

Amazon SageMaker is a fully managed service that offers developers and data scientists the flexibility to build, train, and deploy machine learning models through modular capabilities. In this session, we dive deep into the technical details of each module so you understand how to label and prepare your data, choose an algorithm, train and optimize the model, and make predictions. We also discuss practical deployments of Amazon SageMaker through real-world customer examples.

## AIM308: Build accurate training datasets with Amazon SageMaker Ground Truth   

Successful machine learning models are built on high-quality training datasets. Typically, the task of data labeling is distributed across a large number of humans, adding significant overhead and cost. This session explains how Amazon SageMaker Ground Truth reduces cost and complexity using techniques designed to improve labeling accuracy and reduce human effort. We walk through best practices for building highly accurate training datasets and discuss how you can use Amazon SageMaker Ground Truth to implement them.

## AIM310-S: Why observability requires the marriage of AI, metrics, and logs 

The new digital world presents great opportunity as workloads move to the cloud and containers and companies benefit from serverless computing and an agile application delivery chain. However, these opportunities come with significant challenges. Site reliability engineers have been tasked with knitting together disparate platforms to build an observable stack, which is imperative for early detection of service degradation issues. We demonstrate a novel alternative that combines metrics, logs, and alerts into a comprehensive AIOps approach. Learn how to deliver an AI-enabled service that provides instant observability of your cloud application stack and how to combine logs and metrics into a single pane of glass. This presentation is brought to you by Moogsoft, an APN Partner.

## AIM311-R1: Choose the right instance type in Amazon SageMaker, with Texas Instruments   

Amazon SageMaker, a fully managed service for machine learning, offers several compute capabilities and instance types to meet the needs of your use case. In this session, we review the compute options available to you, including GPUs, CPUs, AWS Inferentia, Amazon SageMaker Neo, and Amazon Elastic Inference. We discuss best practices and key criteria to choose the right capabilities that meet the specific needs of your machine learning workload.

## AIM312: Predict future business outcomes using Amazon Forecast   

Based on the same technology used at Amazon.com, Amazon Forecast uses machine learning and time-series data to build accurate business forecasts. In this session, learn how machine learning can improve accuracy in demand forecasting, financial planning, and resource allocation while reducing your forecasting time from months to hours.

## AIM318-R2: Amazon SageMaker: Automatically tune hyperparameters 

Amazon SageMaker offers automatic model tuning so you can use machine learning to quickly tune your model to be as accurate as possible. This capability lets you skip the tedious trial-and-error process of manually adjusting model parameters. Instead, over multiple training runs, automatic model tuning performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. In this builders session, we show you how to configure and launch a hyperparameter tuning job. Please bring your laptop.

## AIM319-R2: Amazon SageMaker: Use prebuilt Jupyter notebooks 

In this builders session, we show you how to bring an existing Jupyter notebook from your local environment to Amazon SageMaker. Learn how to automate repository and package operations. Using script mode, you also learn how to migrate your code to built-in algorithms and frameworks in order to easily train and deploy at any scale on managed infrastructure. Please bring your laptop.

## AIM322-R1: Fraud: How to detect and prevent it using ML   

Looking to protect your company from anonymous activity and prevent bad-actor behavior? This session details how to implement a customized fraud detection and prevention solution using machine learning services, how to proactively identify these use cases, and how to implement changes to protect your enterprise and your customers.

## AIM325-R1: [NEW LAUNCH!] Intro to Amazon Augmented AI for human review of ML predictions, featuring Ripcord 

Many machine learning (ML) applications require humans to review for labeling or moderation of nuanced content, which can result in low confidence predictions to ensure the correct results. But building human review systems can be time-consuming and expensive. Amazon Augmented AI (A2I) makes it easy to build and manage human reviews for ML applications through built-in workflows for common ML use cases, such as content moderation (with Amazon Rekognition) and text extraction (with Amazon Textract). You can create workflows for custom ML models or those built on Amazon SageMaker. In this session, learn about Amazon A2I and how to use it. Then hear from Ripcord about how they plan to use Amazon A2I built-in integration with Amazon Textract to reduce the initial set up time for large and complex digitization projects.

## AIM326-R: Implement ML workflows with Kubernetes and Amazon SageMaker 

Until recently, data scientists have spent much time performing operational tasks, such as ensuring that frameworks, runtimes, and drivers for CPUs and GPUs work well together. In addition, data scientists needed to design and build end-to-end machine learning (ML) pipelines to orchestrate complex ML workflows for deploying ML models in production. With Amazon SageMaker, data scientists can now focus on creating the best possible models while enabling organizations to easily build and automate end-to-end ML pipelines. In this session, we dive deep into Amazon SageMaker and container technologies, and we discuss how easy it is to integrate such tasks as model training and deployment into Kubernetes and Kubeflow-based ML pipelines.

## AIM326-R1: Implement ML workflows with Kubernetes and Amazon SageMaker   

Until recently, data scientists have spent much time performing operational tasks, such as ensuring that frameworks, runtimes, and drivers for CPUs and GPUs work well together. In addition, data scientists needed to design and build end-to-end machine learning (ML) pipelines to orchestrate complex ML workflows for deploying ML models in production. With Amazon SageMaker, data scientists can now focus on creating the best possible models while enabling organizations to easily build and automate end-to-end ML pipelines. In this session, we dive deep into Amazon SageMaker and container technologies, and we discuss how easy it is to integrate such tasks as model training and deployment into Kubernetes and Kubeflow-based ML pipelines.

## AIM328: Build predictive maintenance systems with Amazon SageMaker 

Across a wide spectrum of industries, customers are starting to utilize prediction maintenance models to proactively fix problems before they impact production. The result is an optimized supply chain and improved working conditions. In this session, learn how to use data from equipment to build, train, and deploy predictive models. We dive deep into the architecture for using the turbofan degradation simulation dataset to train the model to recognize potential equipment failures and also how to provide recommended actions. Finally, we walk through an AWS CloudFormation template so you can get started quickly.

## AIM329: Using deep learning to track wildfires and air quality 

ALERTWildfire is a camera-based network infrastructure that captures satellite imagery of wildfires. In this chalk talk, we discuss deep-learning techniques that use this satellite imagery along with meteorological data to track wildfires and predict air quality in real time.

## AIM330: Build custom data labeling workflows with Amazon SageMaker 

In this chalk talk, we explain how to use customer pre- and post-Lambda functions to extend the functionality of Amazon SageMaker Ground Truth. We show you how to make a custom annotator UI and use AWS Lambda to provide custom pre- and post-processing of annotations.

## AIM331-R1: Choose the proper algorithm in Amazon SageMaker 

Amazon SageMaker gives you choices for the best algorithm to use to train your model. You get a 10x improvement in algorithm performance when using one of the build-in algorithms with Amazon SageMaker. However, it can be confusing to pick between the options. Commonly used ML algorithms are built-in and there are over 200 additional pre-trained models and algorithms available in AWS Marketplace. Plus you can also bring any other algorithm or framework by building it into a Docker container. During this chalk talk, we help you make sense of these choices to optimize performance.

## AIM333: How to design high-quality data-labeling pipelines 

Amazon SageMaker Ground Truth is a fully managed service for data labeling. In this chalk talk, we explore the tools and techniques available in Ground Truth to help generate high-quality labels, from audit and verification workflows to annotation consolidation and active learning. We also discuss how the structured output format lends itself to generating hierarchical taxonomies of data.

## AIM334-R1: Preparing data for use in AutoML scenarios 

AutoML takes care of the heavy lifting of selecting the most optimal algorithm, but as the saying goes 'garbage in, garbage out.' Prepping data for use in AutoML scenarios is one of the most challenging components, and the most prohibitive to a successful proof of concept. Join us to discuss best practices for data prep, and walk through examples of how to do this for sample datasets.

## AIM335-R1: Accelerate time-series forecasting with Amazon Forecast 

Based on the same technology used at Amazon.com, Amazon Forecast uses machine learning to combine time-series data with additional variables to build up to 50% more accurate forecasts. In this workshop, prepare a dataset, build models based on that dataset, evaluate a model's performance based on real observations, and learn how to evaluate the value of a forecast compared with another. Gain the skills to make decisions that will impact the bottom line of your business.

## AIM337-R1: Deep dive into Amazon SageMaker security features 

Customers manage highly sensitive data on behalf of their clients and customers. To apply machine learning techniques to highly sensitive data, they must maintain a high security bar to guard against data exfiltration or abuse of sensitive datasets. Join us for this chalk talk as we dive into the many features of Amazon SageMaker that enable customers to build highly secure data science environments and support stringent security requirements.

## AIM338: Machine learning with containers and Amazon SageMaker 

Data scientists and machine learning engineers use containers to create custom, lightweight environments to train and serve models at scale with deep learning frameworks, such as TensorFlow, Apache MXNet, and PyTorch, achieving consistency across development and deployment. In this chalk talk, we discuss how to use AWS Deep Learning Containers to train and serve models with Amazon SageMaker.

## AIM340-R1: Next-gen video: Transcription, translation & search, powered by ML 

Come discuss how machine learning can enhance your video files and generate searchable metadata in this chalk talk. The Media Analysis Solution on AWS uses Amazon Rekognition for facial recognition, Amazon Transcribe to create transcripts, Amazon Comprehend to run sentiment analysis on the transcripts, and Amazon Translate to make content available in multiple languages. By the end of this session, you will know how to upload your media files and work with the metadata that is automatically extracted through these services.

## AIM341: Deep learning on graphs 

Graph databases are being adopted in a wide range of business domains and can be used with deep learning to tackle many common business problems. In this chalk talk, we explain how to do deep learning on graphs with Amazon SageMaker. We explore three use cases, including how to detect fraudulent accounts on social networks, how to identify social groups for marketing, and how to judge the creditworthiness of individuals.

## AIM342-R1: Large-scale document processing with Amazon Textract 

Millions of mortgage applications and hundreds of millions of W-2 tax forms are processed each year-many times using manual data entry. In this chalk talk, we discuss how to architect a solution to extract text and data from these types of documents at scale for automatic processing. Learn how to build a serverless, highly available, highly scalable architecture that can easily handle spiky workloads.

## AIM343-R1: Build computer vision models with Amazon SageMaker 

Implementing computer vision (CV) models just got simpler and faster. In this chalk talk, learn how to implement CV models using Apache MXNet and the Gluon CV Toolkit, which provide implementations of state-of-the-art deep learning algorithms in computer vision to help engineers, researchers, and students quickly prototype products, validate new ideas, and learn computer vision.

## AIM344-R1: Crafting a conversational platform strategy 

In this chalk talk, we discuss how to build an Amazon Lex chatbot that can conduct a conversation based on data in a sample business intelligence database. We then explore ways that this chatbot could be adapted to your own datasets.

## AIM345: Build accurate models with automatic model tuning 

In many cases, what separates good models from great ones is the choice of hyperparameters. For example, how many layers you should use? What should the learning rate be? And what should the regularization parameters be? In this chalk talk, we dive deep into the automatic model tuning feature of Amazon SageMaker. Automatic model tuning lets you skip the tedious trial-and-error process of manually adjusting model parameters and instead performs hyperparameter optimization by discovering interesting features in your data and learning how those features interact to affect accuracy. You save days or even weeks of time.

## AIM346-R1: Personalized user engagement with machine learning 

In this chalk talk, we discuss how to use Amazon Personalize and Amazon Pinpoint to provide a personalized, omni-channel experience starting in your mobile application. We discuss best practices for real-time updates, personalized notifications (push), and messaging (email and text) that drives user engagement and product discovery. We also demonstrate how other mobile services can be used to facilitate rapid prototyping.

## AIM347: Time-series prediction using GluonTS and Amazon SageMaker 

Time-series prediction-whether it is regression, classification, or anomaly detection-has experienced a renaissance in the past three years thanks to the application of neural models. In turn, AWS has released an open-source Gluon-based toolkit, GluonTS, for time-series prediction. In this session we provide you with different models that are implemented as part of GluonTS. We also provide guidance as to where and how to apply each model.

## AIM348: Deploying and managing machine learning models at scale 

In this workshop, we dive into the deploy module of Amazon SageMaker. Amazon SageMaker offers one-click deployment onto auto-scaling Amazon ML instances across multiple Availability Zones. We explain how Amazon SageMaker manages your production compute infrastructure on your behalf to perform health checks, apply security patches, and conduct other routine maintenance. Then we explore the batch transform feature, which enables you to run predictions on large or small batch data. Finally, we explore inference pipelines, which let you pass raw input data and execute preprocessing, predictions, and post-processing. After the workshop, you will be ready to scale ML.

## AIM350-R1: Identifying product mentions in customer reviews using ML 

In recent years, we have seen the ascent of conversational AI, the rise of chatbots, and an exhaustive amount of data from customer calls, emails, and Tweets. Natural language processing (NLP) is at the core of all of these innovations. In this hands-on session, learn how Amazon Comprehend, and NLP service, enables you to train your own custom-named entity without needing to be skilled in machine learning (ML). Learn how to group support emails by department, social media posts by product, and analyst reports by business unit. Please bring your laptop.

## AIM353-R1: Identify and mask health data in images or text 

Many companies in the Healthcare industry generate large amounts of data that's used in a variety of applications, such as population health management and electronic health records. Developers need to find ways to use the valuable health-related data in these applications while meeting their compliance obligations around sensitive data, such as protected health information (PHI). Join us in this builders session to learn how to use a pre-built solution from AWS, AI-Powered Health Data Masking, to identify and mask health-related data in images or text. Please bring your laptop.

## AIM356-R1: Smarter text analytics with Amazon ES & Amazon Comprehend 

In this session, learn how to use Amazon Elasticsearch Service (Amazon ES) and Amazon Comprehend to extract and visualize insights from text. Learn how to index and analyze news and Twitter feeds, and create live dashboards to visualize extracted entities, key phrases, and sentiment. Please bring your laptop.

## AIM357: Build an ETL pipeline to analyze customer data 

Machine learning involves more than just training models; you need to source and prepare data, engineer features, select algorithms, train and tune models, and then deploy those models and monitor their performance in production. Learn how to set up an ETL pipeline to analyze customer data using Amazon SageMaker, AWS Glue, and AWS Step Functions.

## AIM358: Prepare data for ML using Amazon SageMaker 

High-quality datasets are the foundation of machine learning. In this chalk talk, we explain how to use Amazon SageMaker to prepare data. We show you how to create data inference pipelines so you can pass raw input data and execute preprocessing, predictions, and post-processing on real-time and batch inference requests. We also show you how to build data processing and feature engineering pipelines with a suite of feature transformers available in the SparkML and Scikit-learn framework containers in Amazon SageMaker.

## AIM359-R1: Build a fraud detection system with Amazon SageMaker 

In this workshop, we will explore the new AWS Fraud Detection Solution. We show you how to build, train, and deploy a fraud detection machine learning model. The fraud detection model recognizes fraud patterns, and is self-learning which enables it to adapt to new, unknown fraud patterns. We will show you how to execute automated transaction processing, and how to the Fraud Detection solution flags that activity for review. The solution comes with an implementation guide and accompanying AWS CloudFormation template.

## AIM360: Build a predictive maintenance system with Amazon SageMaker 

In this workshop, we explore the new AWS Predictive Maintenance Using Machine Learning solution. This solution deploys a machine learning model and an example dataset of turbofan degradation simulation data to train the model to recognize potential equipment failures. You can use this solution to automate the detection of potential equipment failures and provide recommended actions to take. We walk through the solution's implementation guide and accompanying AWS CloudFormation template.

## AIM361-R1: [NEW LAUNCH!] Optimizing Your Machine Learning Models on Amazon SageMaker 

In this code-level workshop, you'll learn how to use hyperparameter optimization (HPO) and AutoML on Amazon SageMaker, in order to quickly and easily build highly accurate machine learning models. Using a real-life dataset, you'll first use HPO to tune models built with the popular XGBoost algorithm. Then, you'll use the newly released AutoML capability in Amazon SageMaker to automatically figure out the algorithm, the parameters, and the data preprocessing steps. Finally, you'll use HPO again to perform architecture search on a Keras neural network. Prerequisites: familiarity with Python, Jupyter, Amazon SageMaker and basic machine learning concepts.

## AIM362-R1: [NEW LAUNCH!] Build, train & debug, and deploy & monitor with Amazon SageMaker 

Amazon SageMaker is a fully managed service that removes the heavy lifting from each step of the machine learning (ML) workflow and provides every developer and data scientist with the ability to build, train, and deploy ML models quickly. In this interactive workshop, we work on the different aspects of the ML workflow to build, train, and deploy a model using all the capabilities of Amazon SageMaker, including the ones that we announced at re:Invent this week. We use Amazon SageMaker to build and share notebooks, train and debug models with Amazon SageMaker Debugger, and deploy and monitor with Amazon SageMaker Model Monitor. Let's build together!

## AIM363: How to use NLP for domain-specific data 

Market segments like finance, insurance, or manufacturing all have documents and data that are very specific to their business. In this chalk talk, we discuss how you can utilize Amazon Comprehend custom entity recognition and classification, and AutoML features, to build state-of-the-art custom models to extract domain-specific terms and classifiers completely automatically.

## AIM364: How to deploy Amazon SageMaker to data science teams 

In this session, we share best practices for DevOps teams that can help them run Amazon SageMaker more effectively. Join us, and learn how these best practices enable machine learning scientists to carry out experimentation in their organizations in a collaborative fashion, without having to worry about security, resource management, or cost overruns.

## AIM365-R2: Build a custom model for object and logo detection 

In this discussion, we look at how you can use machine learning to automatically detect your logo or product, allowing you to track where your assets are being seen and used. Explore how this capability empowers marketers and decision makers with data on impressions, digital brand engagement, and the online tracking of their assets.

## AIM366-R1: SpaceNet: ML to solve mapping challenges 

SpaceNet, a nonprofit LLC focusing on solving geospatial problems such as mapping road network routes after a natural disaster, has open-sourced more than 6,500 square kilometers of high-resolution satellite imagery with approximately 800,000 building footprint labels and 8,000 square kilometers of road network labels. Join us for a discussion on how to use this data to train machine learning algorithms that help disseminate timely information in the aftermath of natural disasters.

## AIM367-S: Data is out, knowing is in: Applying AI to automate cloud operations 

With firefighting, manual operations, and troubleshooting, it is an exciting time to monitor applications in the cloud. In this session, renowned DevOps and digital evangelists Andi Grabner and Dave Anderson provide practical advice on how to save time monitoring your cloud applications. Learn how to automate your operations, use AI for assisted intelligence, and enable complete automation. In addition, learn about auto-remediation and how to always know the status of your applications, no matter how complex your hybrid cloud. Also hear from one customer about how a vision can become a reality. This presentation is brought to you by Dynatrace, an APN Partner.

## AIM368: Experience the real-world ML lifecycle with Amazon SageMaker 

In this workshop, you get hands-on experience taking custom machine learning (ML) solutions from prototype to production. You use Amazon SageMaker to build, train, and deploy ML models for a real-world Amazon Robotics use case. You learn about the human-robot interactions that happen hundreds of times every second to power the Amazon fulfillment network. You craft your own ML models based on millions of anonymized data points, and you deploy your models to serve warehouses across the globe with regional endpoints that scale automatically.

## AIM369: Changing the game with ML: How AI, ML, and IoT are transforming sports   

If you are a sports fan interested in machine learning, regardless of industry, this talk is for you. See how some of the world's top sports organizations are innovating with machine learning on AWS and how some of them got started on their journey working with the Amazon ML Solutions Lab. From Formula 1's 1M data points per second to the NFL's 3TB of data per game week to the use of Amazon SageMaker to build, train, and deploy predictive real-time models, leave this session with a better understanding of what's behind the curtain and how you can get started.

## AIM401-R1: Distributed training, tuning, and inference with TensorFlow in Amazon SageMaker 

The TensorFlow deep learning framework is widely used in academia and industry. Using Amazon SageMaker, organizations can quickly begin a fully managed TensorFlow experience. In this workshop, we train and deploy TensorFlow models using key Amazon SageMaker features for an efficient workflow. Specifically, we prototype training and inference code locally before moving to full-scale training and production deployment; compare and contrast Amazon SageMaker's support for distributed training with parameter servers and Horovod; apply automatic model tuning to improve TensorFlow models; and make predictions in production using either real-time endpoints backed by TensorFlow Serving or highly performant batch transform jobs at scale.

## AIM402-R1: Deep learning with PyTorch 

PyTorch is a deep-learning framework that is becoming popular, especially for rapid prototyping of new models. You can get started easily with PyTorch using Amazon SageMaker, a fully managed service, to build, train, and deploy machine learning models at scale. In this workshop, we build a natural-language-processing model to analyze text.

## AIM403-R1: Deep learning with Apache MXNet 

In this workshop, learn how to get started with the Apache MXNet deep learning framework using Amazon SageMaker, a fully managed service, to build, train, and deploy machine learning models at scale. Learn how to build a computer-vision model using MXNet to extract insights from an image dataset. Once the model is built, learn how to quickly train it to get the best possible results and then easily deploy it to production using Amazon SageMaker.

## AIM404-R1: Amazon SageMaker RL: Solving business problems with RL and bandits 

In reinforcement learning (RL), an RL agent learns in an interactive environment by trial and error using feedback from its own actions, and can make sophisticated multi-step decisions. As a result, RL has broad applicability in robotics, industrial control, finance, HVAC, dialog systems, online advertising, and more. This workshop provides practitioners with hands-on experience building and deploying RL agents from scratch. We use examples from two scenarios: one where the environment can be simulated (computer games, resource allocation simulators, etc.) and one where it cannot be and the agent learns in a live environment (recommender systems, trading bots, etc.).

## AIM405: Optimize deep learning models for edge deployments with AWS DeepLens 

In this workshop, learn how to optimize your computer vision pipelines for edge deployments with AWS DeepLens and Amazon SageMaker Neo. Also learn how to build a sample object detection model with Amazon SageMaker and deploy it to AWS DeepLens. Finally, learn how to optimize your deep learning models and code to achieve faster performance for use cases where speed matters.

## AIM407-R1: Amazon SageMaker and PyTorch: Tips & tricks 

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this builders session, learn how to build, train, and deploy PyTorch deep learning models in Amazon SageMaker. Please bring your laptop.

## AIM409-R1: Amazon SageMaker: Bring your own framework 

In this builders session, we show you how to set up your own machine learning environments and workflows on Amazon SageMaker together with AWS Deep Learning AMIs. First we explain how to use the prepackaged, optimized Amazon Machine Images (AMIs). Then we show you how to use these custom environments on Amazon SageMaker using AWS Deep Learning Containers, which provide Docker images preinstalled and tested with popular deep learning frameworks, so you can skip the complicated process of building and optimizing your environments from scratch. Come away understanding how to integrate custom algorithms into Amazon SageMaker. Please bring your laptop.

## AIM410-R: Deep learning applications with TensorFlow, featuring Mobileye   

TensorFlow is one of several open-source deep learning frameworks used in machine learning development that is currently popular among developers. But it can be challenging to scale TensorFlow model training and inference. Amazon SageMaker provides several features that solve these challenges. In this session, learn about these features, including distributed training, cost-effective inference, and workflow management. Then, hear from Mobileye, an Intel company focused on developing and delivering driving assist and autonomous vehicles solutions, about how they migrated their training workloads to Amazon SageMaker to reduce development cycle time from weeks to days.

## AIM410-R1: Deep learning applications with TensorFlow, featuring Fannie Mae 

TensorFlow is one of several currently popular open-source deep learning frameworks used in machine learning development. But it can be challenging to scale TensorFlow model training and inference. Amazon SageMaker provides several features that solve these challenges. In this session, learn about these features, including distributed training, cost-effective inference, and workflow management. Then, hear from Fannie Mae about how it developed its TensorFlow-based home appraisal models using Amazon SageMaker for scalability, security, and ease of management.

## AIM411-R1: Deep learning applications using Apache MXNet   

The Apache MXNet deep learning framework is used for developing, training, and deploying diverse artificial intelligence (AI) applications, including computer vision, speech recognition, and natural language processing (NLP). In this session, learn how to develop deep learning models with MXNet on Amazon SageMaker. Hear from the BBC about how it built a BERT-based NLP application to allow its website users to find relevant clips from recorded shows. We use the BBC's NLP application to demonstrate how to leverage MXNet's GluonNLP library to quickly build, train, and deploy deep learning models.

## AIM412-R: Deep learning applications using PyTorch, featuring Autodesk   

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this session, hear from the PyTorch team on the latest features and library releases. Also learn how to develop with PyTorch using Amazon SageMaker for key use cases such as using a BERT model for natural language processing (NLP) and instance segmentation for fine-grain computer vision. Lastly, take away best practices from Autodesk based on its experience with PyTorch on Amazon SageMaker for a range of NLP use cases.

## AIM412-R1: Deep learning applications with PyTorch, featuring Freshworks 

With support for PyTorch in Amazon SageMaker, you have a flexible deep learning framework combined with a fully managed machine learning solution to transition seamlessly from research prototyping to production deployment. In this session, hear from the PyTorch team on the latest features and library releases. Also learn how to develop with PyTorch using Amazon SageMaker for key use cases such as using a BERT model for natural language processing (NLP) and instance segmentation for fine-grain computer vision. Lastly, hear from Freshworks about how it reduced the time to train 20,000+ models from 15 hours to 30 minutes using PyTorch and Amazon SageMaker.

## AIM413: Deep dive on Project Jupyter   

Amazon SageMaker offers fully managed Jupyter notebooks that you can use in the cloud so you can explore and visualize data and develop your machine learning model. In this session, we explain why we picked Jupyter notebooks, and how and why AWS is contributing to Project Jupyter. We dive deep into our overall strategy for Jupyter and explain different use cases for Jupyter, including data science, analytics, and simulation.

## AIM414: Containerizing deep learning workflows 

Deep learning software stacks can be complex to build, optimize, and maintain. With different versions of frameworks, libraries, runtimes, and drivers for CPUs and GPUs, developers and data scientists spend much time ensuring that the full software stack works well together during upgrades and system changes. Join us for a discussion on how container technologies can address these challenges by providing training and inference environments that are lightweight, portable, consistent, and scalable.

## AIM415-R1: Build fraud detection systems with Amazon SageMaker 

Fraud is an expensive problem that can damage customer trust. Many companies use a rule-based approach to detect fraudulent activity. But implementing and maintaining rules can be a complex process because fraud is constantly evolving, rules require that fraud patterns be known, and rules can lead to false positives or negatives. In this session, learn how machine learning (ML) can provide a more flexible approach. We dive deep on an ML solution using Amazon SageMaker, where the ML models don't use rules. Instead, they're trained to recognize fraud patterns, and they're self-learning, enabling them to adapt.

## AIM416: Deploy an ML model on the cloud and at the edge 

In this workshop, learn how to use Amazon SageMaker Neo deep learning compiler to compile your trained TensorFlow models and deploy them on the cloud or on edge devices using AWS IoT Greengrass. Learn how Neo deep learning compiler optimizes the trained models by improving efficiency and reducing the memory footprint of the compiled model and how Neo runtime abstracts the underlying hardware and allows running a compiled model on the target hardware platform. Explore how to reduce your inference costs by up to 75 percent using Amazon Elastic Inference to attach elastic GPU acceleration to your Amazon SageMaker instances.

## AIM417: Reinforcement learning with Amazon SageMaker 

Many applications, like personalized web services, are continuously faced with decisions based on contextual information. These services strive to adapt to individual users by making use of context. Despite advances, the problem remains challenging. First, systems should adapt to dynamically changing environments like evolving user interests. Second, because of the partial feedback that the system receives, decisions must be scrutinized to avoid introducing bias and a"self-fulfilling prophecy." Contextual bandits can be very effective in solving these problems; they adapt to dynamic environments while continuously balancing exploration with exploitation. In this session, we discuss building a scalable bandit model.

## AIM418: Distributed deep learning with Horovod 

One of the main challenges customers face with deep learning is running efficient model training over multiple nodes. In this chalk talk, we discuss how to use Horovod, a distributed training framework, to speed up deep learning training for multiple frameworks including TensorFlow, PyTorch, and Apache MXNet. We also discuss how to run Horovod in Amazon SageMaker.

## AIM419-R1: [NEW LAUNCH!] Easily implement human review workflows for ML applications 

Amazon Augmented AI (A2I) is a service that makes it easy to build the workflows required for human review of machine learning (ML) predictions. Come join us for a demo and discussion of how to use Amazon A2I for the most common ML use cases, such as content moderation, text extraction, and image classification.

## AIM420: Build state-of-the-art NLP models with Amazon SageMaker and GluonNLP 

Implementing natural language processing (NLP) models just got simpler and faster. In this chalk talk, we introduce BERT (Bidirectional Encoder Representation from Transformers), a state-of-the-art (SOTA) NLP model, and demonstrate how it can be used for various NLP tasks. Learn how to implement NLP models using Apache MXNet and the GluonNLP toolkit to quickly prototype products, validate new ideas, and learn SOTA NLP. We also show how you can use GluonNLP and Amazon SageMaker to fine-tune BERT for a text classification use case and deploy the trained model. Come join us to train your NLP model onsite.

## AIM421-R1: How to use unsupervised ML to find patterns, meaning, and anomalies 

Unsupervised machine learning algorithms infer patterns from a dataset without reference to known or labeled outcomes. Unsupervised learning is used for discovering the underlying structure of data. In this chalk talk, we discuss how to use unsupervised learning and Amazon SageMaker for anomaly detection to automatically discover unusual data points in your dataset. This is useful to detect fraudulent transactions, faulty hardware, or outliers caused by human errors during data entry. We also discuss the intricacies of unsupervised algorithms, including clustering with k-means and anomaly detection with Amazon SageMaker Random Cut Forest (RCF).

## AIM422: Machine learning at the edge with Amazon SageMaker Neo 

Video-based tools have enabled advancements in computer vision, such as in-vehicle use cases for AI. However, it is not always possible to send this data to the cloud to be processed. In this chalk talk, learn how to train machine learning models using Amazon SageMaker and deploy them to an edge device using AWS Greengrass, enabling you to process data quickly at the edge, even when there is no connectivity.

## AIM423-R1: Improve your logistic operations with accurate forecasting 

One of biggest challenges of logistics is building highly accurate forecasts that impact all downstream operations. With accurate demand forecasting, you can align your resources and workforce and realize cost efficiencies. Being able to estimate peak demand allows you to differentiate your customer experience to improve satisfaction. In this builders session, we discuss how to incorporate large volumes of historical demand and contextual data to build forecasts for increased decision accuracy and logistic improvements.

## AIM424-R1: Accelerate experimentation with personalization models 

In this builders session, you work with an AWS solutions architect to learn how to integrate such techniques as A/B testing, multi-armed bandit, and interleaved recommendation testing into applications to measure the effectiveness of personalization. You use Amazon Personalize to build an end-to-end solution for deploying recommendation models that integrates with measurement techniques and can be applied to the customer experience in ecommerce or other marketing channels. Please bring your laptop.

## AIM425-R1: Understanding a large amount of text by modeling & visualizing topics 

What's needed to describe and understand the themes and trends of 5,000 articles in a foreign language? You can spend a few years learning the language and reading through each article, or you can use a few lines of code with Amazon Translate and Amazon Comprehend in under an hour. To learn how to do the latter, come to this hands-on session. We cover topic modeling, a powerful unsupervised learning technique for understanding a large text corpus. Please bring your laptop.

## AIM426-R1: Worker safety with AWS DeepLens and Amazon Rekognition 

There are many practical applications for computer vision systems, and AWS AI services make it easy for developers to add visual recognition capabilities to their programs. In this builders session, you learn how to use AWS DeepLens and Amazon Rekognition to build an application that helps identify whether a person at a construction site is wearing the correct safety gear, in this case, a hard hat. Please bring your laptop.

## AIM427-R1: Take an ML model from idea to production using Amazon SageMaker 

Come build the most accurate text-classification model possible with Amazon SageMaker. This service lets you build, train, and deploy ML models using built-in or custom algorithms. In this workshop, learn how to leverage Keras/TensorFlow deep-learning frameworks to build a text-classification solution using custom algorithms on Amazon SageMaker. We walk you through packaging custom training code in a Docker container, testing it locally, and then using Amazon SageMaker to train a deep-learning model. You then try to iteratively improve the model to achieve high accuracy. Finally, you deploy the model in production so applications can leverage the classification service.

## AIM428: [NEW LAUNCH!] AWS DeepRacer multi-car racing: An advanced RL driving course 

This technical deep dive is suitable for advanced machine learning developers looking to learn more complex reinforcement learning (RL) concepts using AWS DeepRacer and Amazon SageMaker RL. AWS data scientists help you build models capable of avoiding objects and overtaking other cars using innovations in neural network architecture and expanded algorithms.


# Analytics

ANT308-R1: Deep dive into running Apache Spark on Amazon EMR   

Amazon EMR enables customers to run ETL, machine learning, real-time processing, data science, and low-latency SQL at petabyte scale. We focus this session on running Apache Spark on Amazon EMR. We introduce design patterns such as using Amazon S3 instead of HDFS, running long- and short-lived clusters, using notebooks, and performance-related enhancements. We discuss lowering cost with auto scaling and Spot Instances, and security with encryption and fine-grained access control with AWS Lake Formation.

## ANT333: How Woot.com built a serverless data lake with AWS analytics   

Woot.com designed and developed a data lake as a replacement for their legacy data warehouse to deliver powerful analytics capabilities across multiple business areas. In this session, learn how it used Amazon EMR, Amazon Athena, AWS Glue, and Amazon QuickSight to build an automated process to ingest and centralize data from external and internal sources for immediate analysis.

## ANT334-R: Migrate your data warehouse to the cloud in record time, featuring Fannie Mae 

Modern data warehousing blends and analyzes all your data-in your data warehouse and in your data lake-without needing to move the data. In this session, a representative from Fannie Mae explains how they migrated from a leading on-premises data warehouse to Amazon Redshift in record time. See how the company uses AWS Database Migration Service (AWS DMS), AWS Schema Conversion Tool, AWS Glue, and Amazon Redshift to provide timely analytics across the organization.

## ANT334-R1: Migrate your data warehouse to the cloud in record time, featuring Nielsen   

Modern data warehousing blends and analyzes all your data-in your data warehouse and in your data lake-without needing to move the data. In this session, a representative from Nielsen explains how they migrated from a leading on-premises data warehouse to Amazon Redshift in record time. See how the company uses AWS Database Migration Service (AWS DMS), AWS Schema Conversion Tool, AWS Glue, and Amazon Redshift to provide timely analytics across the organization.

## ANT335-R: How to build your data analytics stack at scale with Amazon Redshift   

Modern cloud data warehouses must be able to scale up and scale out as needed to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more.

## ANT335-R1: How to scale data analytics with Amazon Redshift, featuring Warner Bros. 

Modern cloud data warehouses must be able to scale up and out to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more. Additionally, Warner Brothers discusses how it has seen improvements to its analytics performance with Amazon Redshift.

## ANT335-R2: How to scale data analytics with Amazon Redshift 

Modern cloud data warehouses must be able to scale up and out to handle variable analytics workloads. In this session, we discuss Amazon Redshift's ability to deliver top performance at the lowest and most predictable cost for any use case or workload. Learn how Amazon Redshift handles small datasets with large bursts of query activity, large datasets with complex queries, a mix of frequently queried data and infrequently accessed historical data, a mix of open file formats in an Amazon S3 data lake and structured data in Amazon Redshift, and more.¬†

## ANT336-R1: Rapidly evaluate AWS analytics solutions with Amazon Redshift 

Amazon Redshift's pace of innovation continues to increase year-over-year, putting price-performance at an all-time high. Whether you're looking to modernize an existing Amazon Redshift footprint, migrate from an on-premises data warehouse, or get hands-on with AWS's popular cloud data warehouse, this session equips you for success. The Amazon Redshift engineering team guides you through a comprehensive evaluation of modern Amazon Redshift features by using the Amazon Redshift gold standards framework, a robust analytics architecture, managed datasets, and a suite of benchmarking and demonstration tools. The discussions and hands-on labs will rapidly onboard you on the latest features of Amazon Redshift.

## ANT337-R1: Stored procedures in Amazon Redshift 

In this session, we show you how to make the best use of stored procedures in Amazon Redshift to encapsulate business logic in a secure manner. With PL/pgSQL stored procedures, you can easily migrate existing workloads from legacy, on-premises data warehouses to Amazon Redshift. We show how, using the security definer functionality in our stored procedures, an administrator can allow users to perform specific administrative actions without the added risk of security exposure that comes from giving them broad access to database objects.

## ANT338-R1: Best practices for using popular BI tools with Amazon Redshift 

Popular business intelligence (BI) tools like Tableau, Looker, MicroStrategy, Amazon QuickSight, and others are used with Amazon Redshift to visualize analytical results. In this session, we discuss tips and best practices to optimize Amazon Redshift with popular BI tools. We show how tight integration can yield considerable performance gains, shorten development cycles, and make queries more efficient.

## ANT339: How Cerner built a healthcare ML ecosystem with AWS analytics 

Cerner deployed a platform that enables developers to build analytics and predictive healthcare models using big data architecture and machine learning. This accelerates innovation and creates a common strategy to deploy models to the market faster. In this chalk talk, learn how to create an ecosystem allowing data scientists and engineers to collaborate, deploy, and monitor machine learning models and data transformation jobs on both batch and stream data powered by a data lake architecture.

## ANT340-R1: How Equinox Fitness built serverless data applications with AWS 

Equinox Fitness members perform millions of user actions daily, both online and onsite. In this talk, learn how the team at Equinox leveraged services like Amazon Redshift, Amazon EMR, AWS Lambda, and Amazon DynamoDB to deploy fully serverless data applications and platforms in a matter of months and can now provide better personalization and accelerate ideation. Come learn how to create an environment that allows data scientists and engineers to collaborate, deploy, and monitor machine learning models and data transformation jobs.

## ANT341: Integrating Amazon SageMaker and Amazon QuickSight 

Today, customers using traditional business intelligence tools spend too much time sifting through numerous dashboards to manually interpret charts and tables. Amazon QuickSight now applies the power of machine learning and natural language to proactively discover and deliver insights to every user in your organization. In this chalk talk, we show you how you can integrate Amazon QuickSight with Amazon SageMaker to build dashboards and make predictions using your own custom ML models.

## ANT342: [NEW LAUNCH!] Scalable, secure, interactive log analytics using Amazon ES 

With the rapid growth in machine generated data, customers are looking for ways to securely and cost-effectively analyze this constantly growing data in real time. In this talk, we will discuss how to use Amazon Elasticsearch Service to build a secure and scalable log analytics solution to interactively analyze your log data and get valuable operational intelligence for application monitoring, log forensics, clickstream analytics, SIEM, and more.

## ANT343: [NEW LAUNCH!] Create a retail data product on AWS Data Exchange 

AWS Data Exchange makes it easy to securely list retail data products for sharing with AWS customers. In this builders session, you see how easy it is to prepare and package a data product, list it with terms and pricing, and make revisions and alert your customers. You also learn how to bring over existing customers' subscriptions and deliver data without all the hassle. Be sure to bring your laptop.

## ANT344-R1: Augment business analytics with Amazon QuickSight & Amazon SageMaker 

This session covers a new integration between Amazon QuickSight and Amazon SageMaker that makes it easy to connect to and use your predictive analytics models from Amazon SageMaker with Amazon QuickSight dashboards and analyses. Please bring your laptop.

## ANT345-S: Tableau Server on AWS enables analytics agility for Capital One 

As a financial institution, Capital One must be compliant with internal and external policies and regulations. One of these is to regularly replace its Tableau infrastructure, which enables the company to always have the latest security updates and patches in place. To meet this requirement, Capital One chose Tableau Server on AWS and devised a one-click deployment pattern that reduced time and errors while increasing flexibility. In this session, representatives from Capital One discuss some key principles to be aware of as you start or grow your own Tableau deployment. This presentation is brought to you by Tableau, an APN Partner.

## ANT347-S: Build reliable data lakes with Delta Lake & Databricks   

Enterprises need secure and reliable data storage to drive successful analytics programs. Data lakes are a key architectural element of modern data platforms, yet they can suffer from reliability challenges. In this session, you learn about the key data reliability challenges that data lakes face and how you can use open-source Delta Lake to apply schema enforcement, ACID transactions, and versioning to your data lake, making it usable for analytics. This presentation is brought to you by Databricks, an APN Partner.

## ANT401-R1: Build real-time analytics for a ride-sharing app 

In this session, we walk through how to perform real-time analytics on ride-sharing and taxi data, and we explore how to build a reliable, scalable, and highly available streaming architecture based on managed services. You learn how to deploy, operate, and scale an Apache Flink application with Amazon Kinesis Data Analytics for Java applications. Leave this workshop knowing how to build an end-to-end streaming analytics pipeline, starting with ingesting data into a Kinesis data stream, writing and deploying a Flink application to perform basic stream transformations and aggregations, and persisting the results to Amazon Elasticsearch Service to be visualized from Kibana.

## ANT402-R2: Lift and shift an Apache Kafka cluster to Amazon MSK 

Bring your Apache Kafka cluster to Amazon Managed Streaming for Kafka. Amazon MSK is a fully managed service that makes it easy to build and run applications that use Apache Kafka to process streaming data. Apache Kafka is an open-source platform for building real-time streaming data pipelines and applications. In this session, we show how to lift and shift your self-managed Apache Kafka cluster using MirrorMaker 2.0. We cover topics like running hot/hot Apache Kafka clusters and walk through migrating a live Apache Kafka cluster.

## ANT404-R1: Build a single query to analyze data across Amazon Redshift & Amazon S3 

Amazon Redshift offers a common query interface against data stored in fast, local storage (Amazon Redshift) and data stored in high-capacity, inexpensive storage (Amazon S3). This workshop covers the basics of this tiered storage model and outlines design patterns that you can leverage to get the most from large volumes of data. Learn how to build out your own Amazon Redshift cluster with multiple data sets to illustrate the trade-offs between the storage systems. Learn how to distribute your data and design your DDL to deliver the best data warehouse for your business.

## ANT406-R1: Build a single query to analyze data across Amazon Redshift and Amazon S3 

All organizations have dark data that is not loaded into their data warehouse for analysis. When that data is needed, ETL setup and data loading can take days or weeks, delaying time to insight. This session shows you how to mine your Amazon S3 data lake with Amazon Redshift without the need for data movement. Learn how to write a single query that analyzes open data formats stored in your Amazon S3 data lake and data stored in Amazon Redshift. Please bring your laptop.

## ANT407-R1: Real-time apps with Amazon Kinesis Data Analytics and Apache Flink 

Building production-ready streaming applications can be complex, and maintaining them once they go live can be expensive and require dedicated resources and time. By using Amazon Kinesis fully managed streaming services, you can build, deploy, and maintain real-time applications that are highly available, durable, secure, and cost effective. In this session, we walk through how to build an application with Java leveraging Apache Flink, and share best practices for building and maintaining live applications. A foundational understanding of Apache Flink and Java is recommended for this session. Please come prepared with an active AWS account. Please bring your laptop.

## ANT408-R1: Amazon ES sizing and capacity planning 

How many instances? How many shards? What can I monitor? Whether you're new to Amazon Elasticsearch Service (Amazon ES) or a veteran, you need to understand where to start with capacity planning and how to adjust based on monitoring your domain. In this session, we address all of your questions on sizing, explaining the drivers and key metrics along the way.

## ANT409-R1: Getting started with streaming data and Amazon Kinesis 

In this session, we walk through how to build a simple, end-to-end streaming architecture using Amazon Kinesis and AWS Lambda. We cover how continuous, serverless processing works, and the best practices for taking a simple app and getting it into production. Please bring your laptop.

## ANT411-R1: Learn how to make ETL and ELT easy with Amazon Redshift 

Loading data into your data warehouse quickly and reliably is a big pain point for many organizations. In this session, we show you how to generate the schema for your semi-structured data; create ETL code to transform, flatten, and enrich the data; and load it into Amazon Redshift on a recurring basis. You learn best practices to make your data pipeline performant and efficient. Please bring your laptop.

## ANT412-R1: Modernize your data warehouse with Amazon Redshift 

Migrating an on-premises data warehouse to the cloud is often perceived as complex, but it doesn't have to be. In this builders session, we go over the steps you should take to correctly collect your requirements. We also cover AWS services that can assist you in migrating your data to Amazon Redshift, such as AWS Database Migration Service (AWS DMS), AWS Snowball, and AWS Snowmobile. We then dive into targeted use cases based on the needs of the participants in the room. Please bring your laptop.

## ANT413-R1: How to tame unpredictable analytics workloads with Amazon Redshift 

Scaling a traditional data warehouse can be complex, time consuming, and expensive. In this session, we show you how to deploy Amazon Redshift in minutes and automate most administrative tasks. Learn how to manage, monitor, and scale your data warehouse quickly and easily. You also learn how to deploy and scale multiple independent clusters, and scale each independently to address different workload scenarios. Please bring your laptop.

## ANT414-R1: Build great Kibana visualizations 

In this session, we walk you through how to visualize your data in Kibana. You start by learning how to create a visualization and then bring those visualizations together under an overarching dashboard. We cover visualizations such as mapping latitude and longitude, heat maps, bar charts, lines, and newer tools such as Vega. Please bring your laptop.

## ANT415-R1: Learn how to quickly ingest data into Amazon S3 

Want to quickly get data into Amazon Simple Storage Service (Amazon S3) without a large number of small objects? Learn how you can use streaming data to capture, buffer, and deliver data to Amazon S3 in an optimal manner using Amazon Kinesis. Use this pattern to more easily and quickly take advantage of services that process data from Amazon S3, including Amazon Redshift and Amazon Athena. Please come prepared with an active AWS account and your laptop.

## ANT416-R: Performance and elasticity in Amazon Redshift 

This session dives deep into the capabilities of Amazon Redshift. See how Amazon Redshift achieves its state-of-the-art performance and learn about all aspects of elasticity, from the compute and data elasticity within a single cluster to elasticity across multiple clusters.

## ANT416-R1: Performance and elasticity in Amazon Redshift 

This session dives deep into the capabilities of Amazon Redshift. See how Amazon Redshift achieves its state-of-the-art performance and learn about all aspects of elasticity, from the compute and data elasticity within a single cluster to elasticity across multiple clusters.

## ANT417: Accelerating performance with materialized views 

Amazon Redshift materialized views enable a dramatic reduction in query latency. This session explains how to get faster query results, either automatically or by having the queries explicitly refer to the materialized views. Materialized views also enable the acceleration of ETL pipelines by automatically and incrementally propagating changes from the base table data into the derived data of the materialized views, thus providing a superior alternative to the CTAS commands that recompute the derived data.

## ANT418: Deep dive and best practices for Amazon Redshift   

In this session, we take an in-depth look at best practices for data warehousing with Amazon Redshift. We show you the best way to analyze all your data, inside and outside your data warehouse, without moving the data, which helps you gain deeper insights for running your business. We also cover best practices for how to design optimal schemas, load data efficiently, and optimize your queries to deliver high throughput and performance.


# Application Integration

## API201: Accelerating app migration using Amazon MQ 

A managed message broker like Amazon MQ is essential to connect applications with messaging. In this workshop, learn how to set up an Amazon MQ broker and use the supporting protocols. We dive deep into the security and monitoring features of Amazon MQ and show you how Amazon MQ works across multiple Availability Zones to provide high availability to your systems. You'll leave with a deeper understanding of how to use Amazon MQ to migrate your enterprise applications to the cloud.

## API202-R1: Building a bridge solution from IBM MQ to Amazon MQ 

Increasingly, customers want to move from commercial brokers to open-source brokers on the cloud. The challenge they face is that these message brokers are tightly integrated with several of their mission-critical applications. Amazon MQ is a managed ActiveMQ service running on AWS. In this session, we explore an approach to building a bridge solution from IBM MQ to Amazon MQ. The solution provides a phased nondisruptive approach that customers can adopt to migrate their applications to the cloud and use Amazon MQ as the message broker. We also explore options on benchmarking performance of Amazon MQ broker based on customer requirements. Please bring your laptop.

## API301: Securing data in serverless applications and messaging services 

In this chalk talk, we walk you through the process of designing a serverless application that secures customer data sent to the cloud. The design uses features recently introduced by Amazon Simple Notification Service (Amazon SNS) and Amazon Simple Queue Service (Amazon SQS), including AWS Key Management Service (AWS KMS) keys for encrypting messages at rest and Amazon Virtual Private Cloud (Amazon VPC) endpoints powered by AWS PrivateLink for sending messages without traversing the public internet. These techniques are security best practices for systems that deal with private data, such as e-commerce orders, candidate resumes, or employee information.

## API304: Scalable serverless event-driven applications using Amazon SQS & Lambda 

Event-driven integration patterns emerged to enable integration between serverless applications at scale. Join this session to learn best practices for integrating serverless applications using Amazon Simple Queue Service (Amazon SQS) triggers. We dive deep into the architecture of Amazon SQS triggers to AWS Lambda and how it was engineered to autoscale your Lambda functions. Explore how to tune Lambda and Amazon SQS to scale your existing applications without having to worry about provisioning capacity.

## API305-R1: Building serverless machine-learning workflows 

Modern machine-learning workflows leverage AWS services such as Amazon Transcribe and Amazon Comprehend to extract, validate, mutate, and enrich your data. Some drive transactional systems that use ML to generate metadata, others derive insights by visualizing customer-interaction sentiment. All share a common challenge: orchestrating a combination of sequential and parallel steps fulfilled by independent microservices. Join us as we examine how workflows can be used to manage that orchestration in a way that's scalable, reliable, and easy to maintain and run. We contrast two approaches for creating such workflows: a traditional monolithic approach and a serverless approach utilizing AWS Step Functions.

## API306-R1: Building event-driven architectures 

Many customers choose to build event-driven application architectures, in which subscriber or target services automatically perform in response to events triggered by publisher or source services. This pattern can help development teams operate more independently so they can release new features faster and make their applications more scalable. In this session, we cover the basics of event-driven design, using examples involving Amazon Simple Notification Service (Amazon SNS), Amazon Simple Queue Service (Amazon SQS), AWS Lambda, Amazon EventBridge, and more. You also learn how to choose the right AWS service for the job, and how to optimize for cost and performance.

## API307: Build efficient and scalable distributed applications using Amazon MQ 

In this session, we demonstrate the features of the Amazon MQ network of brokers, availability, and performance tuning (to reduce cost of ownership and mitigate risk).

## API308: Monolith to serverless SaaS: Migrating to multi-tenant architecture 

Many organizations begin their journey to SaaS with a single-tenant monolithic architecture. Their goal is to transform these systems into modern, multi-tenant serverless systems that can realize all of the cost, scale, and agility benefits that SaaS environments demand. In this session, we dig into the details of this transformation, exploring approaches to incrementally decompose your monolith into serverless microservices. We also look at how tenancy is introduced into your new microservices, pushing tenant for logging, metrics, data partitioning, and tenant isolation into Lambda layers. The goal is to outline an evolutionary approach that guides your path to a serverless SaaS model.

## API309: Durable serverless architecture: Working with dead-letter queues 

Dead-letter queues (DLQs) are useful for debugging and increasing the durability of your applications and messaging systems because they let you isolate problematic messages to determine why they haven't been successfully processed. In this chalk talk, we walk you through DLQs for AWS Lambda, Amazon Simple Queue Service (Amazon SQS), and Amazon Simple Notification Service (Amazon SNS) and how each one addresses a different failure mode. As part of the session, we design a serverless architecture that benefits from DLQs to address all of these failure modes.

## API310-R1: How to refactor a monolith to serverless in 8 steps 

Refactoring a monolith to serverless can be intimidating, but there are discrete steps that you can take to simplify the process. In this chalk talk, we outline eight steps for successfully refactoring your monolith and highlight key decision points such as language and tooling choices. Through real-world examples of successful migrations, we uncover common mistakes, useful techniques for identifying components for migration and service boundaries, and processes for migrating large amounts of data without downtime. Bring your refactoring challenges to this interactive session to see how these techniques can be applied in the context of your own application.

## API311: Managing business processes using AWS Step Functions 

iRobot uses AWS Step Functions to manage a broad range of business processes, from regulatory compliance to firmware rollouts. Step Functions has eliminated the need for burdensome and expensive long-running compute resources to manage these processes and replaced it with an accessible, declarative language that can glue together a broad suite of AWS services. In this session, we present several business use cases for Step Functions, along with implementation patterns, including decoupling, eternal processes, and approval emails.

## API312: How to select the right application-integration service 

Sometimes, architects are unsure about the right application-integration tool or protocol for their use case. To begin with, there is messaging vs. streaming. But even when we're clear about that, there are several different protocols and tools for each category. In this chalk talk, we introduce a decision tree to help you select the right messaging or streaming tool for your architecture. We also discuss real-world scenarios provided by the audience. Bring your challenges and leave this session with a solid understanding of when to use what in messaging and streaming.

## API313: Nondisruptive strategies for application migration 

Many companies want to refactor applications to increase agility, but they face the challenge of migrating on-premises workloads to the cloud first. This is especially challenging for mission-critical applications, where any downtime has a major customer or business impact. In this session, we dive into common application-migration challenges and nondisruptive approaches, including hybrid architectures, that minimize the impact that migration has on existing applications. We review common on-premises message-broker vendors, like IBM MQ and RabbitMQ, and the benefits of using a managed broker like Amazon MQ as part of a migration strategy.

## API315-R3: Application integration patterns for microservices 

One of the implications of applying the microservices architectural style is that a lot of communication between components is done over the network. In order to achieve the promises of microservices, this communication needs to happen in a loosely coupled manner. In this session, we discuss some fundamental application integration patterns mostly based on messaging and connect them to real-world use cases in a microservices scenario. We also point out some benefits that asynchronous messaging can have over REST APIs for communication between microservices.

## API320-R1: [NEW LAUNCH!] Building event-driven architectures faster than ever with Amazon EventBridge 

Companies are increasingly opting to build applications using event-driven architectures to improve application scalability and reliability. In this session we'll review the basics of event-driven architectures, and reveal how new features in Amazon EventBridge can dramatically reduce the time and code required to build applications that react to events. EventBridge can now discover the available events and automatically generate code from their structure and contents. Through use cases and examples, we'll review how to simplify the process of ingesting, routing, and processing events from your own apps, AWS services, or SaaS apps. With the launch of schema registry, Amazon EventBridge can now discover the available events and automatically generate code from their structure and contents.

## API321: [NEW LAUNCH!] Event-Processing Workflows at Scale with AWS Step Functions 

> Event-Processing Workflows at Scale with AWS Step Functions In this session, learn how to leverage AWS Step Functions Express Workflows and AWS Lambda to build and run event-processing applications. We will explore real-world examples including IoT data ingestion, streaming data transformation, and mobile app backends. Expect to leave this session with a practical understanding of how to use event-processing workflows to scale your application seamlessly, and express your business logic more productively.


# Architecture


